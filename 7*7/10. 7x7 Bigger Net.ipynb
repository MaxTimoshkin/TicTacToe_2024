{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jas5z2XbgpIK"},"outputs":[],"source":["import numpy as np\n","from collections import deque\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1718789249602,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"eGa4uhXjfHDA","outputId":"c57fd24e-f452-423c-f6d0-3ebc485a502d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"Q9aoBPtbKYgm"},"source":["#Игра"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkV_S73IfMyq"},"outputs":[],"source":["# Игра крестики-нолики\n","class TicTacToe:\n","    def __init__(self, player_1, player_2, board_size=3, win_size=3):\n","        self.players = {-1: player_1,\n","                         1: player_2}\n","\n","        self.wins = {player_1.name: 0,\n","                     player_2.name: 0}\n","\n","        self.board_size=board_size\n","        self.win_size = win_size\n","        self._kernel = self._create_kernel()\n","\n","\n","    # Создает ядро свертки для расчета побед\n","    def _create_kernel(self):\n","        kernel = np.zeros((2 * self.win_size + 2, self.win_size, self.win_size))\n","        for i in range(self.win_size):\n","            kernel[i, i, :] = np.ones(self.win_size)\n","        for i in range(self.win_size, 2 * self.win_size):\n","            kernel[i, :, i - self.win_size] = np.ones(self.win_size).T\n","        kernel[2 * self.win_size] = np.eye(self.win_size)\n","        kernel[2 * self.win_size + 1] = np.fliplr(np.eye(self.win_size))\n","        return kernel\n","\n","\n","    # Проверяет победы для состояний states, в кот. ходы были совершены игроками turns, turn={-1, 1}\n","    def _test_win(self, state, turn):\n","        rows, cols, w_size = *state.shape, self.win_size\n","        expanded_states = np.lib.stride_tricks.as_strided(\n","            state,\n","            shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","            strides=(*state.strides, *state.strides),\n","            writeable=False,\n","        )\n","        feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","        return -turn * (feature_map == turn * w_size).any().astype(int)\n","\n","\n","    # Проигрывание нескольких полных эпизодов\n","    def play(self, num_games=1, visualize=False):\n","        transitions = []\n","        for t in range(num_games):\n","            next_turn = turn = -1\n","            state = (np.zeros((self.board_size, self.board_size)), turn) # Начальное состояние игры. state = (state2d, turn)\n","            if visualize:\n","                self.visualize_state(state, turn)\n","            while(next_turn != 0):\n","                state_2d, turn = state\n","                current_player = self.players[turn]\n","                action = current_player.get_action(state)\n","                next_state_2d, next_turn, reward = self.play_turn(state, action)\n","                transitions.append((turn * state_2d, action, reward, -turn * next_state_2d, next_turn == 0))   #state, action, reward, new_state, done\n","                if visualize:\n","                    self.visualize_state((next_state_2d, next_turn), turn)\n","                if next_turn == 0:\n","                    if visualize:\n","                        if (reward == 0): print('Ничья!\\n')\n","                        else: print(f'Победа ({self.players[reward * turn].name})!\\n')\n","                    if reward != 0:\n","                        self.wins[self.players[reward * turn].name] += 1\n","                    self.players = {-1: self.players[1], 1: self.players[-1]}\n","                state = next_state_2d, next_turn\n","        return transitions\n","\n","\n","    # Выполнение хода и проверка на некорректный ход (проигрышь) / выигрыш / ничью\n","    def play_turn(self, state, action): # next_state2d, next_turn, reward\n","        state2d, turn = state\n","        next_state2d = state2d.copy()\n","\n","        # Проверка корректности хода\n","        if (state2d[(action)] != 0):\n","            return next_state2d, 0, -1        # Игрок проиграл (# next_turn == 0 => Игра окончена)\n","\n","        # Совершение хода\n","        next_state2d[action] = turn\n","\n","        # Проверка победы\n","        if self._test_win(next_state2d, turn):\n","            return next_state2d, 0, 1         # Текущий игрок побеждает (next_turn == 0 => Игра окончена)\n","\n","        # Проверка ничьи\n","        if (next_state2d != 0).all():\n","            return next_state2d, 0, 0         # Ничья (next_turn == 0 => Игра окончена)\n","\n","        # Инчае, ход следующего игрока\n","        return next_state2d, -turn, 0         # next_turn == -turn => Смена хода\n","\n","\n","    # Выводит на экран состояние игры после хода игрока\n","    @staticmethod\n","    def visualize_state(next_state, turn):\n","        next_state2d, next_turn = next_state\n","        print(f\"player {turn}'s turn:\")\n","        if (next_state2d == 0).all() and turn == 0:\n","            print(\"[invalid state]\\n\\n\")\n","        else:\n","            print(str(next_state2d)\n","                  .replace(\".\", \"\")\n","                  .replace(\"[[\", \"\")\n","                  .replace(\" [\", \"\")\n","                  .replace(\"]]\", \"\")\n","                  .replace(\"]\", \"\")\n","                  .replace(\"-0\", \" .\")\n","                  .replace(\"0\", \".\")\n","                  .replace(\"-1\", \" X\")\n","                  .replace(\"1\", \"O\")\n","            )\n","\n","\n","    @staticmethod\n","    def print_transitions(transitions):\n","        states, actions, rewards, next_states, dones = zip(*transitions)\n","        for i in np.arange(len(states)):\n","            print(\"\\033[31m{}.\".format(i + 1), '\\033[30m')\n","            TicTacToe.visualize_state((next_states[i], -1), 1)\n","            print('\\naction = ', actions[i] + np.array([1, 1]), end='\\n')\n","            print('reward = ', rewards[i], end='\\n')\n","            if (dones[i]): print('Игра окончена', end='\\n\\n')\n","            else: print('Игра продолжается', end='\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"M3pr2-P0Ka5F"},"source":["#Игроки"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5rtWxp4hTVB"},"outputs":[],"source":["class Human:\n","    def __init__(self, name='Human'):\n","        self.name = name\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        print('Введите ваш ход (Строка, столбец)')\n","        row, col = map(int, input().split())\n","        while (state2d[row - 1, col - 1] != 0):\n","            print('Клетка занята!')\n","            print('Введите ваш ход (Строка, столбец)')\n","            row, col = map(int, input().split())\n","        return row - 1, col - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPVMOC0qTIlK"},"outputs":[],"source":["# Игрок Рандом с преимуществами:\n","# 1. Если есть возможность выиграть за один ход, он делает это (win = True)\n","# 2. Если у соперника есть возможность выиграть в следующем ходу, он блокирует этот ход (defense = True)\n","# 3. Если есть возможность построить четверку, он делает это (win_2 = True)\n","# 4. Если у соперника есть возможность построить четверку в следующем ходу, он блокирует этот ход (defense_2 = True)\n","# 5. Иначе, выбирает случайный ход из множества допустимых\n","class RandomPlus:\n","    def __init__(self, board_size=3, win_size=3, name='RandomPlus',\n","                 win=False, defense=False, win_2=False, defense_2=False):\n","        self.name = name\n","        self.board_size = board_size\n","        self.win_size = win_size\n","\n","        self.win = win\n","        self.defense = defense\n","\n","        self.win_2 = win_2\n","        self.defense_2 = defense_2\n","\n","        if win or defense:\n","            self._kernel = self._create_kernel(win_size)\n","\n","        if win_2 or defense_2:\n","            self._kernel_2 = self._create_kernel(win_size - 1)\n","\n","\n","    # Создает ядро свертки для расчета потенциальных побед\n","    def _create_kernel(self, win_size):\n","        kernel = np.zeros((2 * win_size + 2, win_size, win_size))\n","        for i in range(win_size):\n","            kernel[i, i, :] = np.ones(win_size)\n","        for i in range(win_size, 2 * win_size):\n","            kernel[i, :, i - win_size] = np.ones(win_size).T\n","        kernel[2 * win_size] = np.eye(win_size)\n","        kernel[2 * win_size + 1] = np.fliplr(np.eye(win_size))\n","        return kernel\n","\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        rows, cols, w_size = *state2d.shape, self.win_size\n","\n","        if self.win or self.defense:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","\n","            if self.win:\n","                wins = np.array(np.where(turn * feature_map == w_size - 1))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 1))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        if self.win_2 or self.defense_2:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 2, cols - w_size + 2, w_size - 1, w_size - 1),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel_2)\n","\n","            if self.win_2:\n","                wins = np.array(np.where(turn * feature_map == w_size - 2))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense_2:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 2))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRBw9v0hmVIi"},"outputs":[],"source":["class DQNAgent(nn.Module):\n","    def __init__(self, epsilon=0, name='DQNAgent', masking=False):\n","        super().__init__()\n","\n","        self.name = name\n","        self.epsilon = epsilon\n","        self.n_channels = 3\n","        self.masking = masking    # Маскирование (ВКЛЮЧАТЬ ТОЛЬКО ПРИ ИНФЕРЕНСЕ)\n","\n","        self.network = nn.Sequential(\n","            nn.Conv2d(self.n_channels, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 1, kernel_size=(3, 3), padding='same')\n","        )\n","\n","    def forward(self, x):\n","        x = torch.stack([x == 1, x == -1, x == 0], axis=1).float()\n","        return self.network(x).squeeze(1)\n","\n","    def greedy_action(self, state, device=device):\n","        state2d, turn = state\n","        state_t = torch.FloatTensor(turn * state2d).unsqueeze(0).to(device)\n","        q_values = self.forward(state_t).squeeze(0).detach().cpu().numpy()\n","        if self.masking:\n","            q_values[state2d != 0] = -float(\"Inf\")\n","        return np.unravel_index(q_values.argmax(), q_values.shape)\n","\n","    def random_action(self, state):\n","        state2d, turn = state\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])\n","\n","    def get_action(self, state):\n","        if random.random() < self.epsilon:\n","            action = self.random_action(state)\n","        else:\n","            action = self.greedy_action(state)\n","        return action"]},{"cell_type":"markdown","metadata":{"id":"03J3GWj6P8tj"},"source":["# Буферы"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ni-Mh6jE_-Xd"},"outputs":[],"source":["# Обычный буфер\n","class ReplayBuffer(object):\n","    def __init__(self, size):\n","        self._storage = deque(maxlen=size)\n","\n","    def __len__(self):\n","        return len(self._storage)\n","\n","    def add(self, transition):\n","        self._storage.append(transition)\n","\n","    def sample(self, batch_size, augmentation=False):\n","        batch = random.sample(self._storage, batch_size)\n","        states, actions, rewards, next_states, dones = zip(*batch)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            # ======== ДЛЯ ВСЕГО БАТЧА ОДИНАКОВАЯ АУГМЕНТАЦИЯ ========\n","            # n = states.shape[-1] - 1\n","            # k = np.random.randint(0, 4)\n","            # states = np.rot90(states, k, axes=(1,2)).copy()\n","            # next_states = np.rot90(next_states, k, axes=(1,2)).copy()\n","\n","            # i, j = actions[:, 0], actions[:, 1]\n","            # if k == 1: actions = np.column_stack((n - j, i))\n","            # if k == 2: actions = np.column_stack((n - i, n - j))\n","            # if k == 3: actions = np.column_stack((j, n - i))\n","\n","\n","            # ======== ДЛЯ КАЖДОГО ЭЛЕМЕНТА БАТЧА ОТДЕЛЬНО ========\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","\n","            # ======== УВЕЛИЧЕНИЕ X4 ========\n","            # n = states.shape[-1] - 1\n","            # i, j = actions[:, 0], actions[:, 1]\n","\n","            # states = np.concatenate([np.rot90(states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # next_states = np.concatenate([np.rot90(next_states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # actions = np.concatenate([actions,\n","            #                           np.column_stack((n - j, i)),\n","            #                           np.column_stack((n - i, n - j)),\n","            #                           np.column_stack((j, n - i))], axis=0)\n","            # rewards = np.tile(rewards, 4)\n","            # dones = np.tile(dones, 4)\n","\n","        return states, actions, rewards, next_states, dones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYidASkNW5XC"},"outputs":[],"source":["# =========== Prioritized Replay Buffer With Augmentation ===========\n","class PrioritizedBuffer(object):\n","    def __init__(self, capacity, prob_alpha=0.6):\n","        self.prob_alpha = prob_alpha\n","        self.capacity = capacity\n","        self.buffer = []\n","        self.pos = 0\n","        self.priorities = np.zeros((capacity,), dtype=np.float32)\n","\n","    def add(self, state, action, reward, next_state, done):\n","        max_prio = self.priorities.max() if self.buffer else 1.0\n","\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append((state, action, reward, next_state, done))\n","        else:\n","            self.buffer[self.pos] = (state, action, reward, next_state, done)\n","\n","        self.priorities[self.pos] = max_prio\n","        self.pos = (self.pos + 1) % self.capacity\n","\n","    def sample(self, batch_size, beta=0.4, augmentation=False):\n","        if len(self.buffer) == self.capacity:\n","            prios = self.priorities\n","        else:\n","            prios = self.priorities[:self.pos]\n","\n","        probs  = prios ** self.prob_alpha\n","        probs /= probs.sum()\n","\n","        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n","        samples = [self.buffer[idx] for idx in indices]\n","\n","        total    = len(self.buffer)\n","        weights  = (total * probs[indices]) ** (-beta)\n","        weights /= weights.max()\n","        weights  = np.array(weights, dtype=np.float32)\n","\n","        states, actions, rewards, next_states, dones = zip(*samples)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","        return states, actions, rewards, next_states, dones, indices, weights\n","\n","    def update_priorities(self, batch_indices, batch_priorities):\n","        for idx, prio in zip(batch_indices, batch_priorities):\n","            self.priorities[idx] = prio\n","\n","    def __len__(self):\n","        return len(self.buffer)"]},{"cell_type":"markdown","metadata":{"id":"32ujexFHKgAU"},"source":["#Функции и гиперпараметры для обучения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWj7D_iuy3oT"},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRFnHMHaC7um"},"outputs":[],"source":["board_size = 7\n","win_size = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_gPKyIB504V"},"outputs":[],"source":["# Гиперпараметры метода DQN\n","\n","batch_size = 128        # 512 - много\n","total_steps = 90_000\n","\n","decay_steps = 60_000\n","init_epsilon = 1\n","final_epsilon = 0.25     # 0.02 - мало; 0.1 - мало\n","\n","loss_freq = 100\n","refresh_target_network_freq = 100    # 1000 - много, 50 - мало\n","\n","eval_freq = 500\n","n_eval_games = 100\n","\n","max_grad_norm = 50\n","\n","gamma = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuZM4BiVn_8X"},"outputs":[],"source":["agent = DQNAgent(init_epsilon).to(device)\n","\n","target_network = DQNAgent(init_epsilon).to(device)\n","target_network.load_state_dict(agent.state_dict())\n","\n","optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n","exp_replay = PrioritizedBuffer(16_000) #ReplayBuffer(16_000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718789256792,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"-ZJT-NWjTE9g","outputId":"9f26c6de-f437-4e0f-b6d4-b92f91a050e8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1775105"]},"metadata":{},"execution_count":13}],"source":["sum([p.numel() for p in agent.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKGcoDrQCzXi"},"outputs":[],"source":["# Возвращает temporal difference loss\n","def compute_td_loss(states, actions, rewards, next_states, dones,\n","                    agent, target_network, weights=None, indices=None,    #exp_replay\n","                    gamma=0.9, device=device, prioritized=False):\n","\n","    states = torch.tensor(states, device=device, dtype=torch.float32)                # shape: [batch_size, state_dim]\n","    actions = torch.tensor(actions, device=device, dtype=torch.int64)                # shape: [batch_size]\n","    rewards = torch.tensor(rewards, device=device, dtype=torch.float32)              # shape: [batch_size]\n","    next_states = torch.tensor(next_states, device=device, dtype=torch.float32)      # shape: [batch_size, state_dim]\n","    dones = torch.tensor(dones, device=device, dtype=torch.int64)                    # shape: [batch_size]\n","\n","    predicted_qvalues = agent(states)                                                # shape: [batch_size, n_actions]\n","    predicted_next_qvalues = target_network(next_states)                             # shape: [batch_size, n_actions]\n","    predicted_qvalues_for_actions = predicted_qvalues[range(len(actions)), actions[:, 0], actions[:, 1]]  # shape: [batch_size]\n","    next_state_values = predicted_next_qvalues.view(dones.shape[0], -1).max(axis=1).values\n","    target_qvalues_for_actions = rewards - (1 - dones) * gamma * next_state_values\n","\n","    if prioritized:   #[Prioterized DQN]\n","        weights = torch.tensor(weights, device=device, dtype=torch.float32)\n","        loss = weights * (predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2\n","        prios = (loss + 1e-5).data.cpu().numpy()  # Обновление приоритетов\n","        loss = torch.mean(loss)\n","        exp_replay.update_priorities(indices, prios)\n","        return loss\n","    else:\n","        return torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)  #loss\n","\n","# Рассчитывает epsilon на текущем шаге step\n","def linear_decay(init_epsilon, final_epsilon, step, decay_steps):\n","    return max(init_epsilon - step * (init_epsilon - final_epsilon) / decay_steps, final_epsilon)"]},{"cell_type":"markdown","metadata":{"id":"e73vABV6cKH2"},"source":["# Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33823,"status":"ok","timestamp":1718789290610,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"IigXAGYNdoU7","outputId":"2c7229fd-ff71-49e3-d073-b82be3cc341f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVtRXPFnZ1ug"},"outputs":[],"source":["main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4mXgvfVsN-2"},"outputs":[],"source":["PATH = f'/content/drive/MyDrive/TicTacToe_10/'\n","\n","loss = None\n","loss_values = []\n","reward_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0C5lrTuAUGmp","outputId":"c81eadac-b1a4-44b5-c51e-e023d4a8df1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 0    \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 100  \t loss = 0.0001400406181346625\t eps = 0.9988\n","t = 200  \t loss = 0.0011216223938390613\t eps = 0.9975\n","t = 300  \t loss = 0.002111040288582444\t eps = 0.9962\n","t = 400  \t loss = 0.0016430187970399857\t eps = 0.995\n","t = 500  \t loss = 0.002185105113312602\t eps = 0.9938\n","t = 500  \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 600  \t loss = 0.002207183977589011\t eps = 0.9925\n","t = 700  \t loss = 0.001879225135780871\t eps = 0.9912\n","t = 800  \t loss = 0.0012359556276351213\t eps = 0.99\n","t = 900  \t loss = 0.0023581241257488728\t eps = 0.9888\n","t = 1000 \t loss = 0.0024229567497968674\t eps = 0.9875\n","t = 1000 \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 1100 \t loss = 0.0014549789484590292\t eps = 0.9862\n","t = 1200 \t loss = 0.001642267918214202\t eps = 0.985\n","t = 1300 \t loss = 0.0032500899396836758\t eps = 0.9838\n","t = 1400 \t loss = 0.0017823234666138887\t eps = 0.9825\n","t = 1500 \t loss = 0.002298464998602867\t eps = 0.9812\n","t = 1500 \t reward = -0.98\t{'DQNAgent': 1, 'RandomPlus': 99}\n","\n","t = 1600 \t loss = 0.000990936765447259\t eps = 0.98\n","t = 1700 \t loss = 0.0014295702567324042\t eps = 0.9788\n","t = 1800 \t loss = 0.002448450308293104\t eps = 0.9775\n","t = 1900 \t loss = 0.00290758372284472\t eps = 0.9762\n","t = 2000 \t loss = 0.001994648715481162\t eps = 0.975\n","t = 2000 \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 2100 \t loss = 0.002228174125775695\t eps = 0.9738\n","t = 2200 \t loss = 0.0014571683714166284\t eps = 0.9725\n","t = 2300 \t loss = 0.0016101220389828086\t eps = 0.9712\n","t = 2400 \t loss = 0.0016332734376192093\t eps = 0.97\n","t = 2500 \t loss = 0.001208305824548006\t eps = 0.9688\n","t = 2500 \t reward = -0.96\t{'DQNAgent': 2, 'RandomPlus': 98}\n","\n","t = 2600 \t loss = 0.0009082059841603041\t eps = 0.9675\n","t = 2700 \t loss = 0.002412149216979742\t eps = 0.9663\n","t = 2800 \t loss = 0.0008991449140012264\t eps = 0.965\n","t = 2900 \t loss = 0.0005410453886725008\t eps = 0.9637\n","t = 3000 \t loss = 0.0013959016650915146\t eps = 0.9625\n","t = 3000 \t reward = -0.9\t{'DQNAgent': 5, 'RandomPlus': 95}\n","\n","t = 3100 \t loss = 0.0019722890574485064\t eps = 0.9613\n","t = 3200 \t loss = 0.0008625366608612239\t eps = 0.96\n","t = 3300 \t loss = 0.000972616602666676\t eps = 0.9587\n","t = 3400 \t loss = 0.0013060129713267088\t eps = 0.9575\n","t = 3500 \t loss = 0.0013334325049072504\t eps = 0.9563\n","t = 3500 \t reward = -0.94\t{'DQNAgent': 3, 'RandomPlus': 97}\n","\n","t = 3600 \t loss = 0.0005029161693528295\t eps = 0.955\n","t = 3700 \t loss = 0.0015831681666895747\t eps = 0.9537\n","t = 3800 \t loss = 0.0012262396048754454\t eps = 0.9525\n","t = 3900 \t loss = 0.0008160959696397185\t eps = 0.9513\n","t = 4000 \t loss = 0.0009641355136409402\t eps = 0.95\n","t = 4000 \t reward = -0.74\t{'DQNAgent': 13, 'RandomPlus': 87}\n","\n","t = 4100 \t loss = 0.0008682329207658768\t eps = 0.9487\n","t = 4200 \t loss = 0.0008576814434491098\t eps = 0.9475\n","t = 4300 \t loss = 0.0013987062266096473\t eps = 0.9463\n","t = 4400 \t loss = 0.00113460305146873\t eps = 0.945\n","t = 4500 \t loss = 0.0010975130135193467\t eps = 0.9437\n","t = 4500 \t reward = -0.42\t{'DQNAgent': 29, 'RandomPlus': 71}\n","\n","t = 4600 \t loss = 0.001495448173955083\t eps = 0.9425\n","t = 4700 \t loss = 0.0010924082016572356\t eps = 0.9413\n","t = 4800 \t loss = 0.00046899644075892866\t eps = 0.94\n","t = 4900 \t loss = 0.0011956777889281511\t eps = 0.9387\n","t = 5000 \t loss = 0.0009344731224700809\t eps = 0.9375\n","t = 5000 \t reward = -0.5\t{'DQNAgent': 25, 'RandomPlus': 75}\n","\n","t = 5100 \t loss = 0.0007243428844958544\t eps = 0.9363\n","t = 5200 \t loss = 0.0016472646966576576\t eps = 0.935\n","t = 5300 \t loss = 0.0030168842058628798\t eps = 0.9337\n","t = 5400 \t loss = 0.0005781222134828568\t eps = 0.9325\n","t = 5500 \t loss = 0.002044497523456812\t eps = 0.9313\n","t = 5500 \t reward = -0.52\t{'DQNAgent': 24, 'RandomPlus': 76}\n","\n","t = 5600 \t loss = 0.0006136972806416452\t eps = 0.93\n","t = 5700 \t loss = 0.0012451354414224625\t eps = 0.9287\n","t = 5800 \t loss = 0.0021583554334938526\t eps = 0.9275\n","t = 5900 \t loss = 0.0008256604778580368\t eps = 0.9263\n","t = 6000 \t loss = 0.0006454051472246647\t eps = 0.925\n","t = 6000 \t reward = -0.36\t{'DQNAgent': 32, 'RandomPlus': 68}\n","\n","t = 6100 \t loss = 0.0006083906046114862\t eps = 0.9237\n","t = 6200 \t loss = 0.000488920253701508\t eps = 0.9225\n","t = 6300 \t loss = 0.0022836008574813604\t eps = 0.9213\n","t = 6400 \t loss = 0.0007991022430360317\t eps = 0.92\n","t = 6500 \t loss = 0.000773750536609441\t eps = 0.9187\n","t = 6500 \t reward = -0.52\t{'DQNAgent': 24, 'RandomPlus': 76}\n","\n","t = 6600 \t loss = 0.001022596494294703\t eps = 0.9175\n","t = 6700 \t loss = 0.0008533257059752941\t eps = 0.9163\n","t = 6800 \t loss = 0.0005199539591558278\t eps = 0.915\n","t = 6900 \t loss = 0.0008252001134678721\t eps = 0.9138\n","t = 7000 \t loss = 0.0008393815951421857\t eps = 0.9125\n","t = 7000 \t reward = -0.28\t{'DQNAgent': 36, 'RandomPlus': 64}\n","\n","t = 7100 \t loss = 0.0005696459556929767\t eps = 0.9113\n","t = 7200 \t loss = 0.0007163677364587784\t eps = 0.91\n","t = 7300 \t loss = 0.0003735654172487557\t eps = 0.9087\n","t = 7400 \t loss = 0.0005468899616971612\t eps = 0.9075\n","t = 7500 \t loss = 0.0006245081312954426\t eps = 0.9062\n","t = 7500 \t reward = -0.46\t{'DQNAgent': 27, 'RandomPlus': 73}\n","\n","t = 7600 \t loss = 0.0013284690212458372\t eps = 0.905\n","t = 7700 \t loss = 0.0007413484854623675\t eps = 0.9038\n","t = 7800 \t loss = 0.0012569604441523552\t eps = 0.9025\n","t = 7900 \t loss = 0.00042917727841995656\t eps = 0.9012\n","t = 8000 \t loss = 0.0004395288124214858\t eps = 0.9\n","t = 8000 \t reward = 0.08\t{'DQNAgent': 54, 'RandomPlus': 46}\n","\n","t = 8100 \t loss = 0.001037823036313057\t eps = 0.8987\n","t = 8200 \t loss = 0.0004171757318545133\t eps = 0.8975\n","t = 8300 \t loss = 0.0007291478104889393\t eps = 0.8962\n","t = 8400 \t loss = 0.0005270546535030007\t eps = 0.895\n","t = 8500 \t loss = 0.00035237710108049214\t eps = 0.8938\n","t = 8500 \t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 8600 \t loss = 0.0006608677795156837\t eps = 0.8925\n","t = 8700 \t loss = 0.0005063490243628621\t eps = 0.8912\n","t = 8800 \t loss = 0.000909850001335144\t eps = 0.89\n","t = 8900 \t loss = 0.0005413969047367573\t eps = 0.8888\n","t = 9000 \t loss = 0.0005620808806270361\t eps = 0.8875\n","t = 9000 \t reward = -0.02\t{'DQNAgent': 49, 'RandomPlus': 51}\n","\n","t = 9100 \t loss = 0.0004028782423119992\t eps = 0.8862\n","t = 9200 \t loss = 0.0004887281102128327\t eps = 0.885\n","t = 9300 \t loss = 0.0007680083508603275\t eps = 0.8838\n","t = 9400 \t loss = 0.0005148621276021004\t eps = 0.8825\n","t = 9500 \t loss = 0.0005375116597861052\t eps = 0.8812\n","t = 9500 \t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 9600 \t loss = 0.0010313744423910975\t eps = 0.88\n","t = 9700 \t loss = 0.000275791302556172\t eps = 0.8788\n","t = 9800 \t loss = 0.0005118800327181816\t eps = 0.8775\n","t = 9900 \t loss = 0.0030186278745532036\t eps = 0.8762\n","t = 10000\t loss = 0.0005341130890883505\t eps = 0.875\n","t = 10000\t reward = 0.12\t{'DQNAgent': 56, 'RandomPlus': 44}\n","\n","t = 10100\t loss = 0.0005801355000585318\t eps = 0.8738\n","t = 10200\t loss = 0.0005244569620117545\t eps = 0.8725\n","t = 10300\t loss = 0.000684404163621366\t eps = 0.8712\n","t = 10400\t loss = 0.0004325645277276635\t eps = 0.87\n","t = 10500\t loss = 0.0004898269544355571\t eps = 0.8688\n","t = 10500\t reward = 0.14\t{'DQNAgent': 57, 'RandomPlus': 43}\n","\n","t = 10600\t loss = 0.0008291021804325283\t eps = 0.8675\n","t = 10700\t loss = 0.0006228059064596891\t eps = 0.8662\n","t = 10800\t loss = 0.0006221066578291357\t eps = 0.865\n","t = 10900\t loss = 0.0004853481659665704\t eps = 0.8638\n","t = 11000\t loss = 0.0003520603640936315\t eps = 0.8625\n","t = 11000\t reward = 0.14\t{'DQNAgent': 57, 'RandomPlus': 43}\n","\n","t = 11100\t loss = 0.000651795300655067\t eps = 0.8612\n","t = 11200\t loss = 0.0004155243805143982\t eps = 0.86\n","t = 11300\t loss = 0.0015024439198896289\t eps = 0.8588\n","t = 11400\t loss = 0.0009004428866319358\t eps = 0.8575\n","t = 11500\t loss = 0.0009086974896490574\t eps = 0.8562\n","t = 11500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 11600\t loss = 0.0004699084965977818\t eps = 0.855\n","t = 11700\t loss = 0.001621637144125998\t eps = 0.8538\n","t = 11800\t loss = 0.0005616535781882703\t eps = 0.8525\n","t = 11900\t loss = 0.0005311132408678532\t eps = 0.8513\n","t = 12000\t loss = 0.0005365566466934979\t eps = 0.85\n","t = 12000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 12100\t loss = 0.0005202305037528276\t eps = 0.8488\n","t = 12200\t loss = 0.0004093150782864541\t eps = 0.8475\n","t = 12300\t loss = 0.0003742651897482574\t eps = 0.8462\n","t = 12400\t loss = 0.00035768712405115366\t eps = 0.845\n","t = 12500\t loss = 0.0006736473878845572\t eps = 0.8438\n","t = 12500\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 12600\t loss = 0.0005451955366879702\t eps = 0.8425\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ubXJqK9PByp"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_12500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_12500'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2feb8a61-9d8c-41ee-d96e-d54f88b6afaa","id":"EthU8mXWAmc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 12600\t loss = None\t eps = 0.8425\n","t = 12700\t loss = 0.0008929910836741328\t eps = 0.8413\n","t = 12800\t loss = 0.00042384787229821086\t eps = 0.84\n","t = 12900\t loss = 0.00042001449037343264\t eps = 0.8387\n","t = 13000\t loss = 0.0003424016758799553\t eps = 0.8375\n","t = 13000\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 13100\t loss = 0.0005153411184437573\t eps = 0.8362\n","t = 13200\t loss = 0.0009429357014596462\t eps = 0.835\n","t = 13300\t loss = 0.0008155627292580903\t eps = 0.8337\n","t = 13400\t loss = 0.0007702329894527793\t eps = 0.8325\n","t = 13500\t loss = 0.00035658638807944953\t eps = 0.8313\n","t = 13500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 13600\t loss = 0.0006528746453113854\t eps = 0.83\n","t = 13700\t loss = 0.0004594996280502528\t eps = 0.8287\n","t = 13800\t loss = 0.0010459225159138441\t eps = 0.8275\n","t = 13900\t loss = 0.00038195308297872543\t eps = 0.8263\n","t = 14000\t loss = 0.0004274129751138389\t eps = 0.825\n","t = 14000\t reward = 0.66\t{'DQNAgent': 83, 'RandomPlus': 17}\n","\n","t = 14100\t loss = 0.0002744620433077216\t eps = 0.8237\n","t = 14200\t loss = 0.0006802628049626946\t eps = 0.8225\n","t = 14300\t loss = 0.0011165717151015997\t eps = 0.8213\n","t = 14400\t loss = 0.0003777280217036605\t eps = 0.82\n","t = 14500\t loss = 0.0005227047950029373\t eps = 0.8187\n","t = 14500\t reward = 0.49\t{'DQNAgent': 74, 'RandomPlus': 25}\n","\n","t = 14600\t loss = 0.00035727318027056754\t eps = 0.8175\n","t = 14700\t loss = 0.0003905179037246853\t eps = 0.8163\n","t = 14800\t loss = 0.0005370639264583588\t eps = 0.815\n","t = 14900\t loss = 0.00035310679231770337\t eps = 0.8137\n","t = 15000\t loss = 0.0006367807509377599\t eps = 0.8125\n","t = 15000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 15100\t loss = 0.0003442836459726095\t eps = 0.8113\n","t = 15200\t loss = 0.00029597917455248535\t eps = 0.81\n","t = 15300\t loss = 0.00037458084989339113\t eps = 0.8087\n","t = 15400\t loss = 0.0011418875074014068\t eps = 0.8075\n","t = 15500\t loss = 0.0007141911191865802\t eps = 0.8063\n","t = 15500\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 15600\t loss = 0.00037534357397817075\t eps = 0.805\n","t = 15700\t loss = 0.0002980413264594972\t eps = 0.8037\n","t = 15800\t loss = 0.0005380091606639326\t eps = 0.8025\n","t = 15900\t loss = 0.0003200985083822161\t eps = 0.8013\n","t = 16000\t loss = 0.0006152126006782055\t eps = 0.8\n","t = 16000\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 16100\t loss = 0.0004340278101153672\t eps = 0.7987\n","t = 16200\t loss = 0.0002678203454706818\t eps = 0.7975\n","t = 16300\t loss = 0.0003992507990915328\t eps = 0.7963\n","t = 16400\t loss = 0.0004057147307321429\t eps = 0.795\n","t = 16500\t loss = 0.0008636224665679038\t eps = 0.7937\n","t = 16500\t reward = 0.59\t{'DQNAgent': 79, 'RandomPlus': 20}\n","\n","t = 16600\t loss = 0.00041654150118120015\t eps = 0.7925\n","t = 16700\t loss = 0.00024228918482549489\t eps = 0.7913\n","t = 16800\t loss = 0.000681154546327889\t eps = 0.79\n","t = 16900\t loss = 0.0005336612230166793\t eps = 0.7888\n","t = 17000\t loss = 0.00026358486502431333\t eps = 0.7875\n","t = 17000\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 17100\t loss = 0.0005559296696446836\t eps = 0.7863\n","t = 17200\t loss = 0.005354066379368305\t eps = 0.785\n","t = 17300\t loss = 0.00030436337692663074\t eps = 0.7837\n","t = 17400\t loss = 0.0006097290897741914\t eps = 0.7825\n","t = 17500\t loss = 0.0004243704897817224\t eps = 0.7812\n","t = 17500\t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 17600\t loss = 0.00032987206941470504\t eps = 0.78\n","t = 17700\t loss = 0.0011014885967597365\t eps = 0.7788\n","t = 17800\t loss = 0.0009758262312971056\t eps = 0.7775\n","t = 17900\t loss = 0.00048625707859173417\t eps = 0.7762\n","t = 18000\t loss = 0.0006175120361149311\t eps = 0.775\n","t = 18000\t reward = 0.66\t{'DQNAgent': 83, 'RandomPlus': 17}\n","\n","t = 18100\t loss = 0.001023745397105813\t eps = 0.7737\n","t = 18200\t loss = 0.000283043016679585\t eps = 0.7725\n","t = 18300\t loss = 0.0005146890180185437\t eps = 0.7712\n","t = 18400\t loss = 0.0005805385299026966\t eps = 0.77\n","t = 18500\t loss = 0.0006492146058008075\t eps = 0.7688\n","t = 18500\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 18600\t loss = 0.00039015826769173145\t eps = 0.7675\n","t = 18700\t loss = 0.0003124101785942912\t eps = 0.7662\n","t = 18800\t loss = 0.000590337673202157\t eps = 0.765\n","t = 18900\t loss = 0.00028328876942396164\t eps = 0.7638\n","t = 19000\t loss = 0.0009975170250982046\t eps = 0.7625\n","t = 19000\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 19100\t loss = 0.00036699662450701\t eps = 0.7612\n","t = 19200\t loss = 0.0007449527038261294\t eps = 0.76\n","t = 19300\t loss = 0.0004596256767399609\t eps = 0.7588\n","t = 19400\t loss = 0.00039555045077577233\t eps = 0.7575\n","t = 19500\t loss = 0.00031314638908952475\t eps = 0.7562\n","t = 19500\t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 19600\t loss = 0.0003426886396482587\t eps = 0.755\n","t = 19700\t loss = 0.0005757911712862551\t eps = 0.7538\n","t = 19800\t loss = 0.0005059047252871096\t eps = 0.7525\n","t = 19900\t loss = 0.0002951446804217994\t eps = 0.7512\n","t = 20000\t loss = 0.00023590156342834234\t eps = 0.75\n","t = 20000\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 20100\t loss = 0.0006355730001814663\t eps = 0.7488\n","t = 20200\t loss = 0.00044507544953376055\t eps = 0.7475\n","t = 20300\t loss = 0.00042279597255401313\t eps = 0.7463\n","t = 20400\t loss = 0.0006406348547898233\t eps = 0.745\n","t = 20500\t loss = 0.0002911469782702625\t eps = 0.7438\n","t = 20500\t reward = 0.81\t{'DQNAgent': 90, 'RandomPlus': 9}\n","\n","t = 20600\t loss = 0.0002957869728561491\t eps = 0.7425\n","t = 20700\t loss = 0.00038143532583490014\t eps = 0.7412\n","t = 20800\t loss = 0.0003524861531332135\t eps = 0.74\n","t = 20900\t loss = 0.0005122814327478409\t eps = 0.7388\n","t = 21000\t loss = 0.0002569436328485608\t eps = 0.7375\n","t = 21000\t reward = 0.68\t{'DQNAgent': 83, 'RandomPlus': 15}\n","\n","t = 21100\t loss = 0.0003847892803605646\t eps = 0.7363\n","t = 21200\t loss = 0.000541899586096406\t eps = 0.735\n","t = 21300\t loss = 0.00029556918889284134\t eps = 0.7338\n","t = 21400\t loss = 0.0003520788159221411\t eps = 0.7325\n","t = 21500\t loss = 0.0004470194398891181\t eps = 0.7312\n","t = 21500\t reward = 0.66\t{'DQNAgent': 83, 'RandomPlus': 17}\n","\n","t = 21600\t loss = 0.0015083806356415153\t eps = 0.73\n","t = 21700\t loss = 0.0004205193545203656\t eps = 0.7288\n","t = 21800\t loss = 0.00023847425472922623\t eps = 0.7275\n","t = 21900\t loss = 0.0004441301862243563\t eps = 0.7263\n","t = 22000\t loss = 0.000526891031768173\t eps = 0.725\n","t = 22000\t reward = 0.75\t{'DQNAgent': 87, 'RandomPlus': 12}\n","\n","t = 22100\t loss = 0.00023464465630240738\t eps = 0.7238\n","t = 22200\t loss = 0.00035999505780637264\t eps = 0.7225\n","t = 22300\t loss = 0.0002865975257009268\t eps = 0.7212\n","t = 22400\t loss = 0.00020452452008612454\t eps = 0.72\n","t = 22500\t loss = 0.0003037719870917499\t eps = 0.7188\n","t = 22500\t reward = 0.81\t{'DQNAgent': 90, 'RandomPlus': 9}\n","\n","t = 22600\t loss = 0.0005024388083256781\t eps = 0.7175\n","t = 22700\t loss = 0.00023882364621385932\t eps = 0.7163\n","t = 22800\t loss = 0.0011988525511696935\t eps = 0.715\n","t = 22900\t loss = 0.00040091542177833617\t eps = 0.7137\n","t = 23000\t loss = 0.00041101541137322783\t eps = 0.7125\n","t = 23000\t reward = 0.84\t{'DQNAgent': 91, 'RandomPlus': 7}\n","\n","t = 23100\t loss = 0.0003729360760189593\t eps = 0.7112\n","t = 23200\t loss = 0.00028387142810970545\t eps = 0.71\n","t = 23300\t loss = 0.0003571609267964959\t eps = 0.7087\n","t = 23400\t loss = 0.0010133156320080161\t eps = 0.7075\n","t = 23500\t loss = 0.0004298728599678725\t eps = 0.7063\n","t = 23500\t reward = 0.89\t{'DQNAgent': 94, 'RandomPlus': 5}\n","\n","t = 23600\t loss = 0.00027031180798076093\t eps = 0.705\n","t = 23700\t loss = 0.00026974297361448407\t eps = 0.7037\n","t = 23800\t loss = 0.0004440642660483718\t eps = 0.7025\n","t = 23900\t loss = 0.0003283799160271883\t eps = 0.7012\n","t = 24000\t loss = 0.00021871994249522686\t eps = 0.7\n","t = 24000\t reward = 0.85\t{'DQNAgent': 92, 'RandomPlus': 7}\n","\n","t = 24100\t loss = 0.0006130815017968416\t eps = 0.6987\n","t = 24200\t loss = 0.00025478278985247016\t eps = 0.6975\n","t = 24300\t loss = 0.0005415499326772988\t eps = 0.6963\n","t = 24400\t loss = 0.00024184686481021345\t eps = 0.695\n","t = 24500\t loss = 0.0005587090272456408\t eps = 0.6937\n","t = 24500\t reward = 0.79\t{'DQNAgent': 89, 'RandomPlus': 10}\n","\n","t = 24600\t loss = 0.00033464294392615557\t eps = 0.6925\n","t = 24700\t loss = 0.0006346436566673219\t eps = 0.6912\n","t = 24800\t loss = 0.00032299981103278697\t eps = 0.69\n","t = 24900\t loss = 0.00023239446454681456\t eps = 0.6887\n","t = 25000\t loss = 0.0003753859782591462\t eps = 0.6875\n","t = 25000\t reward = 0.74\t{'DQNAgent': 87, 'RandomPlus': 13}\n","\n","t = 25100\t loss = 0.0007097237394191325\t eps = 0.6863\n","t = 25200\t loss = 0.00040232299943454564\t eps = 0.685\n","t = 25300\t loss = 0.0004290059441700578\t eps = 0.6838\n","t = 25400\t loss = 0.00032459580688737333\t eps = 0.6825\n","t = 25500\t loss = 0.00023290561512112617\t eps = 0.6813\n","t = 25500\t reward = 0.8\t{'DQNAgent': 89, 'RandomPlus': 9}\n","\n","t = 25600\t loss = 0.00039608313818462193\t eps = 0.68\n","t = 25700\t loss = 0.0005139567656442523\t eps = 0.6787\n","t = 25800\t loss = 0.0002699380274862051\t eps = 0.6775\n","t = 25900\t loss = 0.0002335596946068108\t eps = 0.6763\n","t = 26000\t loss = 0.0003793782670982182\t eps = 0.675\n","t = 26000\t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 26100\t loss = 0.00018030416686087847\t eps = 0.6738\n","t = 26200\t loss = 0.00025549810379743576\t eps = 0.6725\n","t = 26300\t loss = 0.000322051317198202\t eps = 0.6713\n","t = 26400\t loss = 0.0002524959563743323\t eps = 0.67\n","t = 26500\t loss = 0.0003873438690789044\t eps = 0.6687\n","t = 26500\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 26600\t loss = 0.0003405972383916378\t eps = 0.6675\n","t = 26700\t loss = 0.002093074144795537\t eps = 0.6663\n","t = 26800\t loss = 0.00036783027462661266\t eps = 0.665\n","t = 26900\t loss = 0.0003275607596151531\t eps = 0.6638\n","t = 27000\t loss = 0.0006112508708611131\t eps = 0.6625\n","t = 27000\t reward = 0.71\t{'DQNAgent': 85, 'RandomPlus': 14}\n","\n","t = 27100\t loss = 0.0007658132817596197\t eps = 0.6613\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(12_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSbw6EAkYL5N"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_27000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_27000'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0ab35f33-8be1-4cdb-8adc-68230e0172a8","id":"e94ovhwcYL5O"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 27100\t loss = None\t eps = 0.6613\n","t = 27200\t loss = 0.0059985509142279625\t eps = 0.66\n","t = 27300\t loss = 0.00033890249324031174\t eps = 0.6587\n","t = 27400\t loss = 0.0007647744496352971\t eps = 0.6575\n","t = 27500\t loss = 0.0003159498446621001\t eps = 0.6562\n","t = 27500\t reward = 0.73\t{'DQNAgent': 84, 'RandomPlus': 11}\n","\n","t = 27600\t loss = 0.00028065693913958967\t eps = 0.655\n","t = 27700\t loss = 0.00038898485945537686\t eps = 0.6538\n","t = 27800\t loss = 0.0002986114704981446\t eps = 0.6525\n","t = 27900\t loss = 0.00038932362804189324\t eps = 0.6512\n","t = 28000\t loss = 0.00032276188721880317\t eps = 0.65\n","t = 28000\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 28100\t loss = 0.00022563812672160566\t eps = 0.6487\n","t = 28200\t loss = 0.00037838303251191974\t eps = 0.6475\n","t = 28300\t loss = 0.0004960792139172554\t eps = 0.6462\n","t = 28400\t loss = 0.00029072415782138705\t eps = 0.645\n","t = 28500\t loss = 0.0003081182949244976\t eps = 0.6438\n","t = 28500\t reward = 0.68\t{'DQNAgent': 84, 'RandomPlus': 16}\n","\n","t = 28600\t loss = 0.0004371666582301259\t eps = 0.6425\n","t = 28700\t loss = 0.00027298260829411447\t eps = 0.6412\n","t = 28800\t loss = 0.0005516647943295538\t eps = 0.64\n","t = 28900\t loss = 0.0003829046036116779\t eps = 0.6387\n","t = 29000\t loss = 0.0011581912403926253\t eps = 0.6375\n","t = 29000\t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 29100\t loss = 0.00021316882339306176\t eps = 0.6362\n","t = 29200\t loss = 0.00038654523086734116\t eps = 0.635\n","t = 29300\t loss = 0.0002706365776248276\t eps = 0.6338\n","t = 29400\t loss = 0.0003803814761340618\t eps = 0.6325\n","t = 29500\t loss = 0.0003245238331146538\t eps = 0.6312\n","t = 29500\t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 29600\t loss = 0.00021651809220202267\t eps = 0.63\n","t = 29700\t loss = 0.0004672577779274434\t eps = 0.6287\n","t = 29800\t loss = 0.0002740266500040889\t eps = 0.6275\n","t = 29900\t loss = 0.00028888386441394687\t eps = 0.6262\n","t = 30000\t loss = 0.00042527972254902124\t eps = 0.625\n","t = 30000\t reward = 0.78\t{'DQNAgent': 86, 'RandomPlus': 8}\n","\n","t = 30100\t loss = 0.00022862435434944928\t eps = 0.6238\n","t = 30200\t loss = 0.0003031016094610095\t eps = 0.6225\n","t = 30300\t loss = 0.00026329816319048405\t eps = 0.6213\n","t = 30400\t loss = 0.0005687450175173581\t eps = 0.62\n","t = 30500\t loss = 0.0005422875983640552\t eps = 0.6188\n","t = 30500\t reward = 0.68\t{'DQNAgent': 84, 'RandomPlus': 16}\n","\n","t = 30600\t loss = 0.0005681676557287574\t eps = 0.6175\n","t = 30700\t loss = 0.0005496986559592187\t eps = 0.6162\n","t = 30800\t loss = 0.00022744829766452312\t eps = 0.615\n","t = 30900\t loss = 0.00028486744849942625\t eps = 0.6138\n","t = 31000\t loss = 0.0002608555369079113\t eps = 0.6125\n","t = 31000\t reward = 0.8\t{'DQNAgent': 89, 'RandomPlus': 9}\n","\n","t = 31100\t loss = 0.00039730867138132453\t eps = 0.6113\n","t = 31200\t loss = 0.0005472493357956409\t eps = 0.61\n","t = 31300\t loss = 0.0002196431451011449\t eps = 0.6088\n","t = 31400\t loss = 0.00021790493337903172\t eps = 0.6075\n","t = 31500\t loss = 0.00040344998706132174\t eps = 0.6062\n","t = 31500\t reward = 0.8\t{'DQNAgent': 89, 'RandomPlus': 9}\n","\n","t = 31600\t loss = 0.0003174992452841252\t eps = 0.605\n","t = 31700\t loss = 0.0004468494444154203\t eps = 0.6038\n","t = 31800\t loss = 0.0003201362560503185\t eps = 0.6025\n","t = 31900\t loss = 0.0004155530477873981\t eps = 0.6013\n","t = 32000\t loss = 0.0003910091472789645\t eps = 0.6\n","t = 32000\t reward = 0.71\t{'DQNAgent': 85, 'RandomPlus': 14}\n","\n","t = 32100\t loss = 0.00021295242186170071\t eps = 0.5988\n","t = 32200\t loss = 0.00035584563738666475\t eps = 0.5975\n","t = 32300\t loss = 0.0011543199652805924\t eps = 0.5962\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(27_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7VASltfhBvY"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_32000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_32000'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c50e49a-4135-4161-cb75-59009c7d4bd6","id":"QPZfmX1QhBvZ"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 32100\t loss = None\t eps = 0.5988\n","t = 32200\t loss = 0.0003604223020374775\t eps = 0.5975\n","t = 32300\t loss = 0.0002640708698891103\t eps = 0.5962\n","t = 32400\t loss = 0.00029565137811005116\t eps = 0.595\n","t = 32500\t loss = 0.0005859998636879027\t eps = 0.5938\n","t = 32500\t reward = 0.79\t{'DQNAgent': 89, 'RandomPlus': 10}\n","\n","t = 32600\t loss = 0.0003901832096744329\t eps = 0.5925\n","t = 32700\t loss = 0.00025767215993255377\t eps = 0.5913\n","t = 32800\t loss = 0.0002867078292183578\t eps = 0.59\n","t = 32900\t loss = 0.0003160769119858742\t eps = 0.5887\n","t = 33000\t loss = 0.0007393527776002884\t eps = 0.5875\n","t = 33000\t reward = 0.77\t{'DQNAgent': 88, 'RandomPlus': 11}\n","\n","t = 33100\t loss = 0.0002735173038672656\t eps = 0.5862\n","t = 33200\t loss = 0.0005184731562621891\t eps = 0.585\n","t = 33300\t loss = 0.00022128145792521536\t eps = 0.5837\n","t = 33400\t loss = 0.0003853509551845491\t eps = 0.5825\n","t = 33500\t loss = 0.000253845879342407\t eps = 0.5813\n","t = 33500\t reward = 0.86\t{'DQNAgent': 91, 'RandomPlus': 5}\n","\n","t = 33600\t loss = 0.0002703147765714675\t eps = 0.58\n","t = 33700\t loss = 0.0009460051660425961\t eps = 0.5787\n","t = 33800\t loss = 0.00042590295197442174\t eps = 0.5775\n","t = 33900\t loss = 0.0001716864062473178\t eps = 0.5762\n","t = 34000\t loss = 0.0014239961747080088\t eps = 0.575\n","t = 34000\t reward = 0.68\t{'DQNAgent': 84, 'RandomPlus': 16}\n","\n","t = 34100\t loss = 0.0003293017507530749\t eps = 0.5737\n","t = 34200\t loss = 0.0005527441389858723\t eps = 0.5725\n","t = 34300\t loss = 0.0002216417051386088\t eps = 0.5713\n","t = 34400\t loss = 0.0006199248018674552\t eps = 0.57\n","t = 34500\t loss = 0.00032165725133381784\t eps = 0.5687\n","t = 34500\t reward = 0.92\t{'DQNAgent': 94, 'RandomPlus': 2}\n","\n","t = 34600\t loss = 0.0003437104169279337\t eps = 0.5675\n","t = 34700\t loss = 0.00024044074234552681\t eps = 0.5662\n","t = 34800\t loss = 0.0004326998023316264\t eps = 0.565\n","t = 34900\t loss = 0.00042629329254850745\t eps = 0.5637\n","t = 35000\t loss = 0.000522790418472141\t eps = 0.5625\n","t = 35000\t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 35100\t loss = 0.00034429033985361457\t eps = 0.5613\n","t = 35200\t loss = 0.00032358913449570537\t eps = 0.56\n","t = 35300\t loss = 0.000823543407022953\t eps = 0.5588\n","t = 35400\t loss = 0.00022392559912987053\t eps = 0.5575\n","t = 35500\t loss = 0.0006232794257812202\t eps = 0.5563\n","t = 35500\t reward = 0.75\t{'DQNAgent': 86, 'RandomPlus': 11}\n","\n","t = 35600\t loss = 0.00022534772870130837\t eps = 0.555\n","t = 35700\t loss = 0.0003010607906617224\t eps = 0.5537\n","t = 35800\t loss = 0.0002384386316407472\t eps = 0.5525\n","t = 35900\t loss = 0.00032361384364776313\t eps = 0.5513\n","t = 36000\t loss = 0.0006373220239765942\t eps = 0.55\n","t = 36000\t reward = 0.72\t{'DQNAgent': 85, 'RandomPlus': 13}\n","\n","t = 36100\t loss = 0.0003008109924849123\t eps = 0.5488\n","t = 36200\t loss = 0.00023749143292661756\t eps = 0.5475\n","t = 36300\t loss = 0.000581411411985755\t eps = 0.5463\n","t = 36400\t loss = 0.00022712943609803915\t eps = 0.545\n","t = 36500\t loss = 0.000441249692812562\t eps = 0.5437\n","t = 36500\t reward = 0.73\t{'DQNAgent': 86, 'RandomPlus': 13}\n","\n","t = 36600\t loss = 0.00024579212185926735\t eps = 0.5425\n","t = 36700\t loss = 0.0004500987706705928\t eps = 0.5413\n","t = 36800\t loss = 0.00030135654378682375\t eps = 0.54\n","t = 36900\t loss = 0.00026999725378118455\t eps = 0.5388\n","t = 37000\t loss = 0.0002066485903924331\t eps = 0.5375\n","t = 37000\t reward = 0.79\t{'DQNAgent': 88, 'RandomPlus': 9}\n","\n","t = 37100\t loss = 0.0008548952755518258\t eps = 0.5363\n","t = 37200\t loss = 0.00018324513803236187\t eps = 0.535\n","t = 37300\t loss = 0.0003326340520288795\t eps = 0.5337\n","t = 37400\t loss = 0.0001819679164327681\t eps = 0.5325\n","t = 37500\t loss = 0.0003792893257923424\t eps = 0.5312\n","t = 37500\t reward = 0.83\t{'DQNAgent': 90, 'RandomPlus': 7}\n","\n","t = 37600\t loss = 0.0002513405343052\t eps = 0.53\n","t = 37700\t loss = 0.00022739851556252688\t eps = 0.5288\n","t = 37800\t loss = 0.0003097497974522412\t eps = 0.5275\n","t = 37900\t loss = 0.00023330624389927834\t eps = 0.5262\n","t = 38000\t loss = 0.0011650027008727193\t eps = 0.525\n","t = 38000\t reward = 0.89\t{'DQNAgent': 93, 'RandomPlus': 4}\n","\n","t = 38100\t loss = 0.000503943650983274\t eps = 0.5237\n","t = 38200\t loss = 0.00036102349986322224\t eps = 0.5225\n","t = 38300\t loss = 0.00021553011902142316\t eps = 0.5212\n","t = 38400\t loss = 0.00022615771740674973\t eps = 0.52\n","t = 38500\t loss = 0.00040199834620580077\t eps = 0.5188\n","t = 38500\t reward = 0.78\t{'DQNAgent': 89, 'RandomPlus': 11}\n","\n","t = 38600\t loss = 0.00046593346633017063\t eps = 0.5175\n","t = 38700\t loss = 0.00026187411276623607\t eps = 0.5162\n","t = 38800\t loss = 0.00027471993234939873\t eps = 0.515\n","t = 38900\t loss = 0.00045881158439442515\t eps = 0.5137\n","t = 39000\t loss = 0.0003926860517822206\t eps = 0.5125\n","t = 39000\t reward = 0.83\t{'DQNAgent': 91, 'RandomPlus': 8}\n","\n","t = 39100\t loss = 0.00037042205804027617\t eps = 0.5112\n","t = 39200\t loss = 0.0002635203127283603\t eps = 0.51\n","t = 39300\t loss = 0.00046662811655551195\t eps = 0.5088\n","t = 39400\t loss = 0.00020357622997835279\t eps = 0.5075\n","t = 39500\t loss = 0.0004586343711707741\t eps = 0.5062\n","t = 39500\t reward = 0.85\t{'DQNAgent': 91, 'RandomPlus': 6}\n","\n","t = 39600\t loss = 0.000456291891168803\t eps = 0.505\n","t = 39700\t loss = 0.0001306479680351913\t eps = 0.5037\n","t = 39800\t loss = 0.00021536624990403652\t eps = 0.5025\n","t = 39900\t loss = 0.000634431722573936\t eps = 0.5012\n","t = 40000\t loss = 0.000276154198218137\t eps = 0.5\n","t = 40000\t reward = 0.84\t{'DQNAgent': 90, 'RandomPlus': 6}\n","\n","t = 40100\t loss = 0.0003044890472665429\t eps = 0.4988\n","t = 40200\t loss = 0.0003929648664779961\t eps = 0.4975\n","t = 40300\t loss = 0.0004306539776735008\t eps = 0.4962\n","t = 40400\t loss = 0.0005486171576194465\t eps = 0.495\n","t = 40500\t loss = 0.0005246903747320175\t eps = 0.4938\n","t = 40500\t reward = 0.81\t{'DQNAgent': 90, 'RandomPlus': 9}\n","\n","t = 40600\t loss = 0.0004917940241284668\t eps = 0.4925\n","t = 40700\t loss = 0.00018984021153301\t eps = 0.4912\n","t = 40800\t loss = 0.000374165247194469\t eps = 0.49\n","t = 40900\t loss = 0.0003097597509622574\t eps = 0.4888\n","t = 41000\t loss = 0.0005537203978747129\t eps = 0.4875\n","t = 41000\t reward = 0.86\t{'DQNAgent': 91, 'RandomPlus': 5}\n","\n","t = 41100\t loss = 0.00016717621474526823\t eps = 0.4862\n","t = 41200\t loss = 0.00031128068803809583\t eps = 0.485\n","t = 41300\t loss = 0.0005197860882617533\t eps = 0.4838\n","t = 41400\t loss = 0.0002802900562528521\t eps = 0.4825\n","t = 41500\t loss = 0.00034010520903393626\t eps = 0.4812\n","t = 41500\t reward = 0.76\t{'DQNAgent': 87, 'RandomPlus': 11}\n","\n","t = 41600\t loss = 0.0002299235638929531\t eps = 0.48\n","t = 41700\t loss = 0.0002084971929434687\t eps = 0.4788\n","t = 41800\t loss = 0.00016694965597707778\t eps = 0.4775\n","t = 41900\t loss = 0.0002733149449340999\t eps = 0.4762\n","t = 42000\t loss = 0.0005282401689328253\t eps = 0.475\n","t = 42000\t reward = 0.71\t{'DQNAgent': 84, 'RandomPlus': 13}\n","\n","t = 42100\t loss = 0.0004423059872351587\t eps = 0.4738\n","t = 42200\t loss = 0.00030608937959186733\t eps = 0.4725\n","t = 42300\t loss = 0.00021978514268994331\t eps = 0.4712\n","t = 42400\t loss = 0.004305264912545681\t eps = 0.47\n","t = 42500\t loss = 0.00019464937213342637\t eps = 0.4688\n","t = 42500\t reward = 0.79\t{'DQNAgent': 88, 'RandomPlus': 9}\n","\n","t = 42600\t loss = 0.00045804097317159176\t eps = 0.4675\n","t = 42700\t loss = 0.0005126164760440588\t eps = 0.4663\n","t = 42800\t loss = 0.0004950514412485063\t eps = 0.465\n","t = 42900\t loss = 0.0006155827431939542\t eps = 0.4637\n","t = 43000\t loss = 0.0003873154928442091\t eps = 0.4625\n","t = 43000\t reward = 0.93\t{'DQNAgent': 95, 'RandomPlus': 2}\n","\n","t = 43100\t loss = 0.000999548239633441\t eps = 0.4613\n","t = 43200\t loss = 0.00024033835506998003\t eps = 0.46\n","t = 43300\t loss = 0.00040902418550103903\t eps = 0.4587\n","t = 43400\t loss = 0.0004447807150427252\t eps = 0.4575\n","t = 43500\t loss = 0.0002720075426623225\t eps = 0.4563\n","t = 43500\t reward = 0.83\t{'DQNAgent': 90, 'RandomPlus': 7}\n","\n","t = 43600\t loss = 0.0006812218925915658\t eps = 0.455\n","t = 43700\t loss = 0.0002843902038875967\t eps = 0.4537\n","t = 43800\t loss = 0.0005696077714674175\t eps = 0.4525\n","t = 43900\t loss = 0.00028925761580467224\t eps = 0.4513\n","t = 44000\t loss = 0.0005667060613632202\t eps = 0.45\n","t = 44000\t reward = 0.83\t{'DQNAgent': 89, 'RandomPlus': 6}\n","\n","t = 44100\t loss = 0.0001974063052330166\t eps = 0.4487\n","t = 44200\t loss = 0.00036499270936474204\t eps = 0.4475\n","t = 44300\t loss = 0.00023575137311127037\t eps = 0.4463\n","t = 44400\t loss = 0.00040663813706487417\t eps = 0.445\n","t = 44500\t loss = 0.0005330222193151712\t eps = 0.4437\n","t = 44500\t reward = 0.71\t{'DQNAgent': 84, 'RandomPlus': 13}\n","\n","t = 44600\t loss = 0.0003371524508111179\t eps = 0.4425\n","t = 44700\t loss = 0.0012564188800752163\t eps = 0.4413\n","t = 44800\t loss = 0.0003025473852176219\t eps = 0.44\n","t = 44900\t loss = 0.00031928400858305395\t eps = 0.4387\n","t = 45000\t loss = 0.00034625999978743494\t eps = 0.4375\n","t = 45000\t reward = 0.71\t{'DQNAgent': 84, 'RandomPlus': 13}\n","\n","t = 45100\t loss = 0.0003099107416346669\t eps = 0.4363\n","t = 45200\t loss = 0.0003558430471457541\t eps = 0.435\n","t = 45300\t loss = 0.0007008311804383993\t eps = 0.4337\n","t = 45400\t loss = 0.00029024697141721845\t eps = 0.4325\n","t = 45500\t loss = 0.0003723854315467179\t eps = 0.4313\n","t = 45500\t reward = 0.81\t{'DQNAgent': 90, 'RandomPlus': 9}\n","\n","t = 45600\t loss = 0.0005789807764813304\t eps = 0.43\n","t = 45700\t loss = 0.0003426324110478163\t eps = 0.4287\n","t = 45800\t loss = 0.0002547669573687017\t eps = 0.4275\n","t = 45900\t loss = 0.00030461078858934343\t eps = 0.4263\n","t = 46000\t loss = 0.0004425377119332552\t eps = 0.425\n","t = 46000\t reward = 0.83\t{'DQNAgent': 90, 'RandomPlus': 7}\n","\n","t = 46100\t loss = 0.0014486947329714894\t eps = 0.4237\n","t = 46200\t loss = 0.0009397858520969748\t eps = 0.4225\n","t = 46300\t loss = 0.00025170700973831117\t eps = 0.4213\n","t = 46400\t loss = 0.00046446314081549644\t eps = 0.42\n","t = 46500\t loss = 0.0006460854201577604\t eps = 0.4187\n","t = 46500\t reward = 0.87\t{'DQNAgent': 93, 'RandomPlus': 6}\n","\n","t = 46600\t loss = 0.0002706693485379219\t eps = 0.4175\n","t = 46700\t loss = 0.00040066958172246814\t eps = 0.4163\n","t = 46800\t loss = 0.00019885285291820765\t eps = 0.415\n","t = 46900\t loss = 0.00027444626903161407\t eps = 0.4137\n","t = 47000\t loss = 0.0004156666691415012\t eps = 0.4125\n","t = 47000\t reward = 0.87\t{'DQNAgent': 92, 'RandomPlus': 5}\n","\n","t = 47100\t loss = 0.0003067165962420404\t eps = 0.4113\n","t = 47200\t loss = 0.00035749192466028035\t eps = 0.41\n","t = 47300\t loss = 0.0002584401809144765\t eps = 0.4087\n","t = 47400\t loss = 0.0003688639553729445\t eps = 0.4075\n","t = 47500\t loss = 0.0001848690735641867\t eps = 0.4062\n","t = 47500\t reward = 0.82\t{'DQNAgent': 90, 'RandomPlus': 8}\n","\n","t = 47600\t loss = 0.00022821796301286668\t eps = 0.405\n","t = 47700\t loss = 0.0008063744753599167\t eps = 0.4038\n","t = 47800\t loss = 0.00016602984396740794\t eps = 0.4025\n","t = 47900\t loss = 0.00021687711705453694\t eps = 0.4012\n","t = 48000\t loss = 0.00048339407658204436\t eps = 0.4\n","t = 48000\t reward = 0.82\t{'DQNAgent': 90, 'RandomPlus': 8}\n","\n","t = 48100\t loss = 0.00023100584803614765\t eps = 0.3988\n","t = 48200\t loss = 0.003221019171178341\t eps = 0.3975\n","t = 48300\t loss = 0.00022388581419363618\t eps = 0.3962\n","t = 48400\t loss = 0.0009009580826386809\t eps = 0.395\n","t = 48500\t loss = 0.00037065340438857675\t eps = 0.3938\n","t = 48500\t reward = 0.74\t{'DQNAgent': 85, 'RandomPlus': 11}\n","\n","t = 48600\t loss = 0.00026164844166487455\t eps = 0.3925\n","t = 48700\t loss = 0.00021397955424617976\t eps = 0.3912\n","t = 48800\t loss = 0.00027067583869211376\t eps = 0.39\n","t = 48900\t loss = 0.0004141813260503113\t eps = 0.3888\n","t = 49000\t loss = 0.0005156411207281053\t eps = 0.3875\n","t = 49000\t reward = 0.92\t{'DQNAgent': 94, 'RandomPlus': 2}\n","\n","t = 49100\t loss = 0.0003510314563754946\t eps = 0.3862\n","t = 49200\t loss = 0.0002602165041025728\t eps = 0.385\n","t = 49300\t loss = 0.00033675594022497535\t eps = 0.3838\n","t = 49400\t loss = 0.0003357972018420696\t eps = 0.3825\n","t = 49500\t loss = 0.0006724556442350149\t eps = 0.3812\n","t = 49500\t reward = 0.83\t{'DQNAgent': 87, 'RandomPlus': 4}\n","\n","t = 49600\t loss = 0.0003600121126510203\t eps = 0.38\n","t = 49700\t loss = 0.00046339136315509677\t eps = 0.3788\n","t = 49800\t loss = 0.00023431114095728844\t eps = 0.3775\n","t = 49900\t loss = 0.00018264015670865774\t eps = 0.3762\n","t = 50000\t loss = 0.0002749360864982009\t eps = 0.375\n","t = 50000\t reward = 0.91\t{'DQNAgent': 95, 'RandomPlus': 4}\n","\n","t = 50100\t loss = 0.0002941255224868655\t eps = 0.3738\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(32_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXr8NLZ_TpCQ"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_50000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_50000'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca0cedc7-6c95-4b2f-c617-db6c1193bc16","id":"in7mBd41TpCR"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 50100\t loss = None\t eps = 0.3738\n","t = 50200\t loss = 0.0002211250684922561\t eps = 0.3725\n","t = 50300\t loss = 0.0002295014710398391\t eps = 0.3712\n","t = 50400\t loss = 0.00014761908096261322\t eps = 0.37\n","t = 50500\t loss = 0.00020375415624585003\t eps = 0.3688\n","t = 50500\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 50600\t loss = 0.0003613890730775893\t eps = 0.3675\n","t = 50700\t loss = 0.00017614458920434117\t eps = 0.3662\n","t = 50800\t loss = 0.0006521661998704076\t eps = 0.365\n","t = 50900\t loss = 0.00022069099941290915\t eps = 0.3638\n","t = 51000\t loss = 0.000389240711228922\t eps = 0.3625\n","t = 51000\t reward = 0.91\t{'DQNAgent': 95, 'RandomPlus': 4}\n","\n","t = 51100\t loss = 0.0002868498268071562\t eps = 0.3612\n","t = 51200\t loss = 0.00017824700626078993\t eps = 0.36\n","t = 51300\t loss = 0.00012416072422638535\t eps = 0.3588\n","t = 51400\t loss = 0.0002470770850777626\t eps = 0.3575\n","t = 51500\t loss = 0.00033206160878762603\t eps = 0.3562\n","t = 51500\t reward = 0.85\t{'DQNAgent': 92, 'RandomPlus': 7}\n","\n","t = 51600\t loss = 0.0006461766315624118\t eps = 0.355\n","t = 51700\t loss = 0.00020080278045497835\t eps = 0.3538\n","t = 51800\t loss = 0.0003347227757330984\t eps = 0.3525\n","t = 51900\t loss = 0.0008311644778586924\t eps = 0.3512\n","t = 52000\t loss = 0.00020875371410511434\t eps = 0.35\n","t = 52000\t reward = 0.86\t{'DQNAgent': 92, 'RandomPlus': 6}\n","\n","t = 52100\t loss = 0.00029952876502647996\t eps = 0.3488\n","t = 52200\t loss = 0.0003742444678209722\t eps = 0.3475\n","t = 52300\t loss = 0.0003273746115155518\t eps = 0.3462\n","t = 52400\t loss = 0.0004303092136979103\t eps = 0.345\n","t = 52500\t loss = 0.00026104238349944353\t eps = 0.3438\n","t = 52500\t reward = 0.84\t{'DQNAgent': 89, 'RandomPlus': 5}\n","\n","t = 52600\t loss = 0.0002730675623752177\t eps = 0.3425\n","t = 52700\t loss = 0.00043990585254505277\t eps = 0.3413\n","t = 52800\t loss = 0.00024399071116931736\t eps = 0.34\n","t = 52900\t loss = 0.0002466531004756689\t eps = 0.3387\n","t = 53000\t loss = 0.0001882856886368245\t eps = 0.3375\n","t = 53000\t reward = 0.86\t{'DQNAgent': 92, 'RandomPlus': 6}\n","\n","t = 53100\t loss = 0.00017931243928615004\t eps = 0.3363\n","t = 53200\t loss = 0.0002395223273197189\t eps = 0.335\n","t = 53300\t loss = 0.00018790969625115395\t eps = 0.3337\n","t = 53400\t loss = 0.0003557783493306488\t eps = 0.3325\n","t = 53500\t loss = 0.0003680357476696372\t eps = 0.3313\n","t = 53500\t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 53600\t loss = 0.0003347657329868525\t eps = 0.33\n","t = 53700\t loss = 0.000728332088328898\t eps = 0.3287\n","t = 53800\t loss = 0.00015858476399444044\t eps = 0.3275\n","t = 53900\t loss = 0.00029630347853526473\t eps = 0.3263\n","t = 54000\t loss = 0.0001798307930584997\t eps = 0.325\n","t = 54000\t reward = 0.75\t{'DQNAgent': 87, 'RandomPlus': 12}\n","\n","t = 54100\t loss = 0.00016924161172937602\t eps = 0.3237\n","t = 54200\t loss = 0.0001979648368433118\t eps = 0.3225\n","t = 54300\t loss = 0.00022756107500754297\t eps = 0.3213\n","t = 54400\t loss = 0.0002570588840171695\t eps = 0.32\n","t = 54500\t loss = 0.00022170718875713646\t eps = 0.3187\n","t = 54500\t reward = 0.57\t{'DQNAgent': 77, 'RandomPlus': 20}\n","\n","t = 54600\t loss = 0.00017619204299990088\t eps = 0.3175\n","t = 54700\t loss = 0.00030097030685283244\t eps = 0.3163\n","t = 54800\t loss = 0.00013969195424579084\t eps = 0.315\n","t = 54900\t loss = 0.00027686188695952296\t eps = 0.3137\n","t = 55000\t loss = 0.0010852819541469216\t eps = 0.3125\n","t = 55000\t reward = 0.81\t{'DQNAgent': 89, 'RandomPlus': 8}\n","\n","t = 55100\t loss = 0.0011015734635293484\t eps = 0.3113\n","t = 55200\t loss = 0.0031055365689098835\t eps = 0.31\n","t = 55300\t loss = 0.0011291267583146691\t eps = 0.3087\n","t = 55400\t loss = 0.00016326873446814716\t eps = 0.3075\n","t = 55500\t loss = 0.00028667261358350515\t eps = 0.3063\n","t = 55500\t reward = 0.82\t{'DQNAgent': 88, 'RandomPlus': 6}\n","\n","t = 55600\t loss = 0.00019809741934295744\t eps = 0.305\n","t = 55700\t loss = 0.00017956345982383937\t eps = 0.3037\n","t = 55800\t loss = 0.00022396567510440946\t eps = 0.3025\n","t = 55900\t loss = 0.0002837966603692621\t eps = 0.3013\n","t = 56000\t loss = 0.00027074816171079874\t eps = 0.3\n","t = 56000\t reward = 0.75\t{'DQNAgent': 83, 'RandomPlus': 8}\n","\n","t = 56100\t loss = 0.0002109013294102624\t eps = 0.2987\n","t = 56200\t loss = 0.000506758107803762\t eps = 0.2975\n","t = 56300\t loss = 0.00046554344589821994\t eps = 0.2963\n","t = 56400\t loss = 0.00012977584265172482\t eps = 0.295\n","t = 56500\t loss = 0.00836917757987976\t eps = 0.2937\n","t = 56500\t reward = 0.85\t{'DQNAgent': 89, 'RandomPlus': 4}\n","\n","t = 56600\t loss = 0.0004753455286845565\t eps = 0.2925\n","t = 56700\t loss = 0.00023617869010195136\t eps = 0.2913\n","t = 56800\t loss = 0.00021201407071202993\t eps = 0.29\n","t = 56900\t loss = 0.00020644240430556238\t eps = 0.2887\n","t = 57000\t loss = 0.00020885388948954642\t eps = 0.2875\n","t = 57000\t reward = 0.87\t{'DQNAgent': 91, 'RandomPlus': 4}\n","\n","t = 57100\t loss = 0.0002712226123549044\t eps = 0.2863\n","t = 57200\t loss = 0.00017638792633078992\t eps = 0.285\n","t = 57300\t loss = 0.00017454726912546903\t eps = 0.2837\n","t = 57400\t loss = 0.00020537630189210176\t eps = 0.2825\n","t = 57500\t loss = 0.00015688606072217226\t eps = 0.2812\n","t = 57500\t reward = 0.8\t{'DQNAgent': 89, 'RandomPlus': 9}\n","\n","t = 57600\t loss = 0.00022410924430005252\t eps = 0.28\n","t = 57700\t loss = 0.000148872917634435\t eps = 0.2788\n","t = 57800\t loss = 0.0002883627312257886\t eps = 0.2775\n","t = 57900\t loss = 0.001164300600066781\t eps = 0.2762\n","t = 58000\t loss = 0.00041533398325555027\t eps = 0.275\n","t = 58000\t reward = 0.71\t{'DQNAgent': 81, 'RandomPlus': 10}\n","\n","t = 58100\t loss = 0.0003565178485587239\t eps = 0.2738\n","t = 58200\t loss = 0.00030252194846980274\t eps = 0.2725\n","t = 58300\t loss = 0.0003270923625677824\t eps = 0.2712\n","t = 58400\t loss = 0.0003034139226656407\t eps = 0.27\n","t = 58500\t loss = 0.0001897821930469945\t eps = 0.2688\n","t = 58500\t reward = 0.83\t{'DQNAgent': 89, 'RandomPlus': 6}\n","\n","t = 58600\t loss = 0.00021789903985336423\t eps = 0.2675\n","t = 58700\t loss = 0.0004962269449606538\t eps = 0.2662\n","t = 58800\t loss = 0.00035655812826007605\t eps = 0.265\n","t = 58900\t loss = 0.00033482175786048174\t eps = 0.2638\n","t = 59000\t loss = 0.00021680716599803418\t eps = 0.2625\n","t = 59000\t reward = 0.61\t{'DQNAgent': 70, 'RandomPlus': 9}\n","\n","t = 59100\t loss = 0.0001948679273482412\t eps = 0.2612\n","t = 59200\t loss = 0.0001819263125071302\t eps = 0.26\n","t = 59300\t loss = 0.0002918616228271276\t eps = 0.2588\n","t = 59400\t loss = 0.000183159121661447\t eps = 0.2575\n","t = 59500\t loss = 0.00017278350424021482\t eps = 0.2562\n","t = 59500\t reward = 0.87\t{'DQNAgent': 93, 'RandomPlus': 6}\n","\n","t = 59600\t loss = 0.00045992503874003887\t eps = 0.255\n","t = 59700\t loss = 0.00010318808199372143\t eps = 0.2538\n","t = 59800\t loss = 0.00031356344697996974\t eps = 0.2525\n","t = 59900\t loss = 0.0006913726683706045\t eps = 0.2512\n","t = 60000\t loss = 0.000188424251973629\t eps = 0.25\n","t = 60000\t reward = 0.74\t{'DQNAgent': 85, 'RandomPlus': 11}\n","\n","t = 60100\t loss = 0.0002697950112633407\t eps = 0.25\n","t = 60200\t loss = 0.0013034413568675518\t eps = 0.25\n","t = 60300\t loss = 0.002342373598366976\t eps = 0.25\n","t = 60400\t loss = 0.00018960997113026679\t eps = 0.25\n","t = 60500\t loss = 0.0005875426577404141\t eps = 0.25\n","t = 60500\t reward = 0.83\t{'DQNAgent': 87, 'RandomPlus': 4}\n","\n","t = 60600\t loss = 0.0004351347452029586\t eps = 0.25\n","t = 60700\t loss = 0.00022076151799410582\t eps = 0.25\n","t = 60800\t loss = 0.0042122285813093185\t eps = 0.25\n","t = 60900\t loss = 0.00026665389304980636\t eps = 0.25\n","t = 61000\t loss = 0.00019751784566324204\t eps = 0.25\n","t = 61000\t reward = 0.91\t{'DQNAgent': 95, 'RandomPlus': 4}\n","\n","t = 61100\t loss = 0.00021605653455480933\t eps = 0.25\n","t = 61200\t loss = 0.003557690652087331\t eps = 0.25\n","t = 61300\t loss = 0.00014326616656035185\t eps = 0.25\n","t = 61400\t loss = 0.0005362301599234343\t eps = 0.25\n","t = 61500\t loss = 0.00026132172206416726\t eps = 0.25\n","t = 61500\t reward = 0.88\t{'DQNAgent': 93, 'RandomPlus': 5}\n","\n","t = 61600\t loss = 0.0004987836582586169\t eps = 0.25\n","t = 61700\t loss = 0.00016848737141117454\t eps = 0.25\n","t = 61800\t loss = 0.00031149887945502996\t eps = 0.25\n","t = 61900\t loss = 0.0004088974674232304\t eps = 0.25\n","t = 62000\t loss = 0.00023570444318465889\t eps = 0.25\n","t = 62000\t reward = 0.75\t{'DQNAgent': 84, 'RandomPlus': 9}\n","\n","t = 62100\t loss = 0.0001854946167441085\t eps = 0.25\n","t = 62200\t loss = 0.0002122567966580391\t eps = 0.25\n","t = 62300\t loss = 0.000675417366437614\t eps = 0.25\n","t = 62400\t loss = 0.00028227188158780336\t eps = 0.25\n","t = 62500\t loss = 0.00042533600935712457\t eps = 0.25\n","t = 62500\t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 62600\t loss = 0.0002911896153818816\t eps = 0.25\n","t = 62700\t loss = 0.0007323428289964795\t eps = 0.25\n","t = 62800\t loss = 0.00032070541055873036\t eps = 0.25\n","t = 62900\t loss = 0.000304115324979648\t eps = 0.25\n","t = 63000\t loss = 0.00017919216770678759\t eps = 0.25\n","t = 63000\t reward = 0.83\t{'DQNAgent': 90, 'RandomPlus': 7}\n","\n","t = 63100\t loss = 0.00020477213547565043\t eps = 0.25\n","t = 63200\t loss = 0.0009908921783789992\t eps = 0.25\n","t = 63300\t loss = 0.00016332989616785198\t eps = 0.25\n","t = 63400\t loss = 0.00018218881450593472\t eps = 0.25\n","t = 63500\t loss = 0.00036204903153702617\t eps = 0.25\n","t = 63500\t reward = 0.75\t{'DQNAgent': 84, 'RandomPlus': 9}\n","\n","t = 63600\t loss = 0.00020320230396464467\t eps = 0.25\n","t = 63700\t loss = 0.00010394302807981148\t eps = 0.25\n","t = 63800\t loss = 0.00021277923951856792\t eps = 0.25\n","t = 63900\t loss = 0.0003131251723971218\t eps = 0.25\n","t = 64000\t loss = 0.00038018537452444434\t eps = 0.25\n","t = 64000\t reward = 0.85\t{'DQNAgent': 92, 'RandomPlus': 7}\n","\n","t = 64100\t loss = 0.00017473651678301394\t eps = 0.25\n","t = 64200\t loss = 0.00023663928732275963\t eps = 0.25\n","t = 64300\t loss = 0.0002202088653575629\t eps = 0.25\n","t = 64400\t loss = 0.0002469139581080526\t eps = 0.25\n","t = 64500\t loss = 0.00017584607121534646\t eps = 0.25\n","t = 64500\t reward = 0.85\t{'DQNAgent': 90, 'RandomPlus': 5}\n","\n","t = 64600\t loss = 0.00045842109830118716\t eps = 0.25\n","t = 64700\t loss = 0.00022539730707649142\t eps = 0.25\n","t = 64800\t loss = 0.00021776577341370285\t eps = 0.25\n","t = 64900\t loss = 0.00035260256845504045\t eps = 0.25\n","t = 65000\t loss = 0.00017438830400351435\t eps = 0.25\n","t = 65000\t reward = 0.64\t{'DQNAgent': 72, 'RandomPlus': 8}\n","\n","t = 65100\t loss = 0.00034044182393699884\t eps = 0.25\n","t = 65200\t loss = 0.0004051077412441373\t eps = 0.25\n","t = 65300\t loss = 0.0004660772974602878\t eps = 0.25\n","t = 65400\t loss = 0.00029046606505289674\t eps = 0.25\n","t = 65500\t loss = 0.0011563270818442106\t eps = 0.25\n","t = 65500\t reward = 0.8\t{'DQNAgent': 86, 'RandomPlus': 6}\n","\n","t = 65600\t loss = 0.00015107475337572396\t eps = 0.25\n","t = 65700\t loss = 0.0017614418175071478\t eps = 0.25\n","t = 65800\t loss = 0.00045714981388300657\t eps = 0.25\n","t = 65900\t loss = 0.00022621317475568503\t eps = 0.25\n","t = 66000\t loss = 0.00032366751111112535\t eps = 0.25\n","t = 66000\t reward = 0.77\t{'DQNAgent': 85, 'RandomPlus': 8}\n","\n","t = 66100\t loss = 0.0003436816041357815\t eps = 0.25\n","t = 66200\t loss = 0.00021355561329983175\t eps = 0.25\n","t = 66300\t loss = 0.00017432257300242782\t eps = 0.25\n","t = 66400\t loss = 0.00019742685253731906\t eps = 0.25\n","t = 66500\t loss = 0.0002804800751619041\t eps = 0.25\n","t = 66500\t reward = 0.76\t{'DQNAgent': 84, 'RandomPlus': 8}\n","\n","t = 66600\t loss = 0.0004257522232364863\t eps = 0.25\n","t = 66700\t loss = 0.0006114301504567266\t eps = 0.25\n","t = 66800\t loss = 0.00034370546927675605\t eps = 0.25\n","t = 66900\t loss = 0.000712683773599565\t eps = 0.25\n","t = 67000\t loss = 0.0002515526139177382\t eps = 0.25\n","t = 67000\t reward = 0.84\t{'DQNAgent': 89, 'RandomPlus': 5}\n","\n","t = 67100\t loss = 0.00018888997146859765\t eps = 0.25\n","t = 67200\t loss = 0.00022595323389396071\t eps = 0.25\n","t = 67300\t loss = 0.002594557125121355\t eps = 0.25\n","t = 67400\t loss = 0.0002742794749792665\t eps = 0.25\n","t = 67500\t loss = 0.00035473075695335865\t eps = 0.25\n","t = 67500\t reward = 0.9\t{'DQNAgent': 93, 'RandomPlus': 3}\n","\n","t = 67600\t loss = 0.0003755326906684786\t eps = 0.25\n","t = 67700\t loss = 0.000248035357799381\t eps = 0.25\n","t = 67800\t loss = 0.00013179647794459015\t eps = 0.25\n","t = 67900\t loss = 0.0002244814531877637\t eps = 0.25\n","t = 68000\t loss = 0.0004302689922042191\t eps = 0.25\n","t = 68000\t reward = 0.71\t{'DQNAgent': 80, 'RandomPlus': 9}\n","\n","t = 68100\t loss = 0.0004348419315647334\t eps = 0.25\n","t = 68200\t loss = 0.0005898174131289124\t eps = 0.25\n","t = 68300\t loss = 0.0003152475692331791\t eps = 0.25\n","t = 68400\t loss = 0.00021625228691846132\t eps = 0.25\n","t = 68500\t loss = 0.001471109688282013\t eps = 0.25\n","t = 68500\t reward = 0.85\t{'DQNAgent': 90, 'RandomPlus': 5}\n","\n","t = 68600\t loss = 0.00030095429974608123\t eps = 0.25\n","t = 68700\t loss = 0.00023701522150076926\t eps = 0.25\n","t = 68800\t loss = 0.003259779419749975\t eps = 0.25\n","t = 68900\t loss = 0.0002268958487547934\t eps = 0.25\n","t = 69000\t loss = 0.0004157375660724938\t eps = 0.25\n","t = 69000\t reward = 0.78\t{'DQNAgent': 87, 'RandomPlus': 9}\n","\n","t = 69100\t loss = 0.004664984066039324\t eps = 0.25\n","t = 69200\t loss = 0.0002714456059038639\t eps = 0.25\n","t = 69300\t loss = 9.833112562773749e-05\t eps = 0.25\n","t = 69400\t loss = 0.0008509886683896184\t eps = 0.25\n","t = 69500\t loss = 0.0001922092487802729\t eps = 0.25\n","t = 69500\t reward = 0.85\t{'DQNAgent': 92, 'RandomPlus': 7}\n","\n","t = 69600\t loss = 0.00032865372486412525\t eps = 0.25\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(50_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"markdown","metadata":{"id":"wMHCdyXqKqCk"},"source":["#Тестирование обученных моделей (инференс с маскированием)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QySv5l9i6fUs"},"outputs":[],"source":["PATH = '/content/drive/MyDrive/TicTacToe_10/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txmhrUHlOM-2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718800249427,"user_tz":-180,"elapsed":10952850,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"}},"outputId":"b7d7d861-c98a-4047-b634-703510171551"},"outputs":[{"output_type":"stream","name":"stdout","text":["    0 {'DQNAgent': 2, 'RandomPlus': 996}\n","  500 {'DQNAgent': 5, 'RandomPlus': 985}\n"," 1000 {'DQNAgent': 22, 'RandomPlus': 947}\n"," 1500 {'DQNAgent': 73, 'RandomPlus': 879}\n"," 2000 {'DQNAgent': 89, 'RandomPlus': 809}\n"," 2500 {'DQNAgent': 214, 'RandomPlus': 654}\n"," 3000 {'DQNAgent': 182, 'RandomPlus': 666}\n"," 3500 {'DQNAgent': 347, 'RandomPlus': 521}\n"," 4000 {'DQNAgent': 405, 'RandomPlus': 444}\n"," 4500 {'DQNAgent': 557, 'RandomPlus': 343}\n"," 5000 {'DQNAgent': 617, 'RandomPlus': 254}\n"," 5500 {'DQNAgent': 551, 'RandomPlus': 239}\n"," 6000 {'DQNAgent': 652, 'RandomPlus': 195}\n"," 6500 {'DQNAgent': 651, 'RandomPlus': 134}\n"," 7000 {'DQNAgent': 686, 'RandomPlus': 149}\n"," 7500 {'DQNAgent': 706, 'RandomPlus': 100}\n"," 8000 {'DQNAgent': 769, 'RandomPlus': 70}\n"," 8500 {'DQNAgent': 789, 'RandomPlus': 60}\n"," 9000 {'DQNAgent': 776, 'RandomPlus': 59}\n"," 9500 {'DQNAgent': 831, 'RandomPlus': 43}\n","10000 {'DQNAgent': 816, 'RandomPlus': 28}\n","10500 {'DQNAgent': 784, 'RandomPlus': 54}\n","11000 {'DQNAgent': 830, 'RandomPlus': 32}\n","11500 {'DQNAgent': 766, 'RandomPlus': 26}\n","12000 {'DQNAgent': 860, 'RandomPlus': 24}\n","12500 {'DQNAgent': 844, 'RandomPlus': 33}\n","13000 {'DQNAgent': 897, 'RandomPlus': 20}\n","13500 {'DQNAgent': 896, 'RandomPlus': 16}\n","14000 {'DQNAgent': 885, 'RandomPlus': 16}\n","14500 {'DQNAgent': 901, 'RandomPlus': 11}\n","15000 {'DQNAgent': 897, 'RandomPlus': 6}\n","15500 {'DQNAgent': 895, 'RandomPlus': 17}\n","16000 {'DQNAgent': 903, 'RandomPlus': 5}\n","16500 {'DQNAgent': 903, 'RandomPlus': 17}\n","17000 {'DQNAgent': 892, 'RandomPlus': 19}\n","17500 {'DQNAgent': 899, 'RandomPlus': 15}\n","18000 {'DQNAgent': 902, 'RandomPlus': 9}\n","18500 {'DQNAgent': 906, 'RandomPlus': 15}\n","19000 {'DQNAgent': 899, 'RandomPlus': 13}\n","19500 {'DQNAgent': 918, 'RandomPlus': 17}\n","20000 {'DQNAgent': 926, 'RandomPlus': 14}\n","20500 {'DQNAgent': 923, 'RandomPlus': 8}\n","21000 {'DQNAgent': 895, 'RandomPlus': 13}\n","21500 {'DQNAgent': 938, 'RandomPlus': 2}\n","22000 {'DQNAgent': 925, 'RandomPlus': 8}\n","22500 {'DQNAgent': 919, 'RandomPlus': 7}\n","23000 {'DQNAgent': 933, 'RandomPlus': 8}\n","23500 {'DQNAgent': 928, 'RandomPlus': 12}\n","24000 {'DQNAgent': 938, 'RandomPlus': 7}\n","24500 {'DQNAgent': 924, 'RandomPlus': 4}\n","25000 {'DQNAgent': 942, 'RandomPlus': 6}\n","25500 {'DQNAgent': 941, 'RandomPlus': 9}\n","26000 {'DQNAgent': 944, 'RandomPlus': 7}\n","26500 {'DQNAgent': 934, 'RandomPlus': 10}\n","27000 {'DQNAgent': 945, 'RandomPlus': 12}\n","27500 {'DQNAgent': 941, 'RandomPlus': 11}\n","28000 {'DQNAgent': 946, 'RandomPlus': 9}\n","28500 {'DQNAgent': 937, 'RandomPlus': 9}\n","29000 {'DQNAgent': 957, 'RandomPlus': 7}\n","29500 {'DQNAgent': 938, 'RandomPlus': 11}\n","30000 {'DQNAgent': 929, 'RandomPlus': 2}\n","30500 {'DQNAgent': 947, 'RandomPlus': 2}\n","31000 {'DQNAgent': 919, 'RandomPlus': 12}\n","31500 {'DQNAgent': 939, 'RandomPlus': 7}\n","32000 {'DQNAgent': 923, 'RandomPlus': 8}\n","32500 {'DQNAgent': 945, 'RandomPlus': 7}\n","33000 {'DQNAgent': 932, 'RandomPlus': 11}\n","33500 {'DQNAgent': 927, 'RandomPlus': 18}\n","34000 {'DQNAgent': 940, 'RandomPlus': 5}\n","34500 {'DQNAgent': 931, 'RandomPlus': 8}\n","35000 {'DQNAgent': 948, 'RandomPlus': 7}\n","35500 {'DQNAgent': 938, 'RandomPlus': 13}\n","36000 {'DQNAgent': 923, 'RandomPlus': 13}\n","36500 {'DQNAgent': 942, 'RandomPlus': 4}\n","37000 {'DQNAgent': 948, 'RandomPlus': 9}\n","37500 {'DQNAgent': 946, 'RandomPlus': 6}\n","38000 {'DQNAgent': 943, 'RandomPlus': 7}\n","38500 {'DQNAgent': 947, 'RandomPlus': 18}\n","39000 {'DQNAgent': 935, 'RandomPlus': 10}\n","39500 {'DQNAgent': 943, 'RandomPlus': 13}\n","40000 {'DQNAgent': 940, 'RandomPlus': 15}\n","40500 {'DQNAgent': 948, 'RandomPlus': 4}\n","41000 {'DQNAgent': 941, 'RandomPlus': 6}\n","41500 {'DQNAgent': 937, 'RandomPlus': 9}\n","42000 {'DQNAgent': 959, 'RandomPlus': 10}\n","42500 {'DQNAgent': 941, 'RandomPlus': 9}\n","43000 {'DQNAgent': 957, 'RandomPlus': 7}\n","43500 {'DQNAgent': 953, 'RandomPlus': 12}\n","44000 {'DQNAgent': 919, 'RandomPlus': 6}\n","44500 {'DQNAgent': 957, 'RandomPlus': 5}\n","45000 {'DQNAgent': 936, 'RandomPlus': 11}\n","45500 {'DQNAgent': 929, 'RandomPlus': 17}\n","46000 {'DQNAgent': 959, 'RandomPlus': 10}\n","46500 {'DQNAgent': 937, 'RandomPlus': 16}\n","47000 {'DQNAgent': 910, 'RandomPlus': 15}\n","47500 {'DQNAgent': 928, 'RandomPlus': 15}\n","48000 {'DQNAgent': 945, 'RandomPlus': 12}\n","48500 {'DQNAgent': 931, 'RandomPlus': 17}\n","49000 {'DQNAgent': 953, 'RandomPlus': 6}\n","49500 {'DQNAgent': 934, 'RandomPlus': 9}\n","50000 {'DQNAgent': 957, 'RandomPlus': 1}\n","50500 {'DQNAgent': 943, 'RandomPlus': 9}\n","51000 {'DQNAgent': 959, 'RandomPlus': 8}\n","51500 {'DQNAgent': 958, 'RandomPlus': 13}\n","52000 {'DQNAgent': 931, 'RandomPlus': 22}\n","52500 {'DQNAgent': 942, 'RandomPlus': 18}\n","53000 {'DQNAgent': 951, 'RandomPlus': 20}\n","53500 {'DQNAgent': 953, 'RandomPlus': 17}\n","54000 {'DQNAgent': 951, 'RandomPlus': 14}\n","54500 {'DQNAgent': 863, 'RandomPlus': 12}\n","55000 {'DQNAgent': 956, 'RandomPlus': 17}\n","55500 {'DQNAgent': 928, 'RandomPlus': 18}\n","56000 {'DQNAgent': 923, 'RandomPlus': 11}\n","56500 {'DQNAgent': 906, 'RandomPlus': 15}\n","57000 {'DQNAgent': 933, 'RandomPlus': 14}\n","57500 {'DQNAgent': 921, 'RandomPlus': 16}\n","58000 {'DQNAgent': 856, 'RandomPlus': 18}\n","58500 {'DQNAgent': 894, 'RandomPlus': 16}\n","59000 {'DQNAgent': 703, 'RandomPlus': 36}\n","59500 {'DQNAgent': 961, 'RandomPlus': 10}\n","60000 {'DQNAgent': 946, 'RandomPlus': 12}\n","60500 {'DQNAgent': 937, 'RandomPlus': 14}\n","61000 {'DQNAgent': 943, 'RandomPlus': 14}\n","61500 {'DQNAgent': 949, 'RandomPlus': 15}\n","62000 {'DQNAgent': 917, 'RandomPlus': 18}\n","62500 {'DQNAgent': 956, 'RandomPlus': 16}\n","63000 {'DQNAgent': 954, 'RandomPlus': 15}\n","63500 {'DQNAgent': 899, 'RandomPlus': 17}\n","64000 {'DQNAgent': 967, 'RandomPlus': 18}\n","64500 {'DQNAgent': 924, 'RandomPlus': 21}\n","65000 {'DQNAgent': 888, 'RandomPlus': 12}\n","65500 {'DQNAgent': 894, 'RandomPlus': 16}\n","66000 {'DQNAgent': 946, 'RandomPlus': 20}\n","66500 {'DQNAgent': 895, 'RandomPlus': 25}\n","67000 {'DQNAgent': 923, 'RandomPlus': 15}\n","67500 {'DQNAgent': 935, 'RandomPlus': 12}\n","68000 {'DQNAgent': 819, 'RandomPlus': 29}\n","68500 {'DQNAgent': 937, 'RandomPlus': 15}\n","69000 {'DQNAgent': 938, 'RandomPlus': 15}\n","69500 {'DQNAgent': 949, 'RandomPlus': 12}\n"]}],"source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(0, 70_000, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9LIq2qJIT0u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718802584231,"user_tz":-180,"elapsed":692331,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"}},"outputId":"4941084d-a3ed-4c60-800d-410b0fdd0194"},"outputs":[{"output_type":"stream","name":"stdout","text":["50000 {'DQNAgent': 9495, 'RandomPlus': 61}\n"]}],"source":["# Сравнение лучших моделей (без проигрышей)\n","models = [50_000]\n","\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for model in models:\n","    agent.load_state_dict(torch.load(f'{PATH}model_{model}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(10_000)\n","    print(model, eval_game.wins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3005,"status":"ok","timestamp":1718755389056,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"sT5QLsvSj0-2","outputId":"b6cce4f3-b135-402f-c690-2862017e9a7f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":26}],"source":["# Загрузка самой лучшей модели\n","agent.load_state_dict(torch.load(f'{PATH}model_61000', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":496639,"status":"error","timestamp":1718755889541,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"_bgzNN9tsPVN","outputId":"3078e16a-dbe2-40de-ec30-9dfb73ebd647"},"outputs":[{"output_type":"stream","name":"stdout","text":["player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 5\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  O  .  .  .\n"," .  X  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","Клетка занята!\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  .  .  .\n"," .  X  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  X  .  .\n"," .  X  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 6\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  O  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  .\n"," .  .  X  X  O  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 2\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  .\n"," .  .  X  X  O  .  .\n"," .  O  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  X\n"," .  .  X  X  O  .  .\n"," .  O  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 7\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  X\n"," .  .  X  X  O  .  O\n"," .  O  O  O  X  .  .\n"," .  X  O  .  .  .  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  X\n"," .  .  X  X  O  .  O\n"," .  O  O  O  X  .  .\n"," .  X  O  X  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 6\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  .  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  .  .\n"," .  X  O  X  .  .  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  .  .\n"," .  X  O  X  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 6\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  .\n"," .  X  O  X  .  .  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  .\n"," .  X  O  X  .  .  .\n"," .  X  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 6\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  .\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  .\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  .\n","Введите ваш ход (Строка, столбец)\n","2 2\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  .  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  .\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  .  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  O  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  O  .  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  O  O  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  .\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  O  O  .  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","2 5\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  O  O  O  O  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," X  O  O  O  O  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","1 2\n","player 1's turn:\n"," .  O  .  .  .  .  .\n"," X  O  O  O  O  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  O  .  .  X  .  .\n"," X  O  O  O  O  X  X\n"," .  .  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","3 2\n","player 1's turn:\n"," .  O  .  .  X  .  .\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  .  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  O  .  .  X  .  .\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","1 3\n","player 1's turn:\n"," .  O  O  .  X  .  .\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  O  O  X  X  .  .\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","1 6\n","player 1's turn:\n"," .  O  O  X  X  O  .\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," .  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","1 1\n","player 1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  .  O  X\n"," .  X  .  .  .  X  X\n","player -1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  X  O  X\n"," .  X  .  .  .  X  X\n","Введите ваш ход (Строка, столбец)\n","7 5\n","player 1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  X  O  X\n"," .  X  .  .  O  X  X\n","player -1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  X  O  X\n"," X  X  .  .  O  X  X\n","Введите ваш ход (Строка, столбец)\n","7 4\n","player 1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," .  X  O  X  X  O  X\n"," X  X  .  O  O  X  X\n","player -1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," X  X  O  X  X  O  X\n"," X  X  .  O  O  X  X\n","Введите ваш ход (Строка, столбец)\n","7 3\n","player 1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," .  O  O  O  X  O  X\n"," X  X  O  X  X  O  X\n"," X  X  O  O  O  X  X\n","player -1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," .  X  X  X  O  O  O\n"," X  O  O  O  X  O  X\n"," X  X  O  X  X  O  X\n"," X  X  O  O  O  X  X\n","Введите ваш ход (Строка, столбец)\n","4 1\n","player 1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," .  O  O  X  X  O  X\n"," O  X  X  X  O  O  O\n"," X  O  O  O  X  O  X\n"," X  X  O  X  X  O  X\n"," X  X  O  O  O  X  X\n","player -1's turn:\n"," O  O  O  X  X  O  X\n"," X  O  O  O  O  X  X\n"," X  O  O  X  X  O  X\n"," O  X  X  X  O  O  O\n"," X  O  O  O  X  O  X\n"," X  X  O  X  X  O  X\n"," X  X  O  O  O  X  X\n","Ничья!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","Введите ваш ход (Строка, столбец)\n","2 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  .  .  .  X  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  .  O  .  X  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  .  O  .  X  .  O\n"," .  .  X  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  .  X  O  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  .  X  O  O  .  O\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  X  X  O  O  .  O\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  X  X  O  O  .  O\n"," .  O  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 7\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  .  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  .  .  X\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  .  .  X\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 5\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  X  .  X\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  .  O\n"," .  O  .  X  X  .  X\n"," .  .  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  .  O\n"," .  O  X  X  X  .  X\n"," .  .  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  .  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 6\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  O  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","7 3\n","player -1's turn:\n"," .  .  O  .  .  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  .  .  .  .\n","player 1's turn:\n"," .  .  O  .  .  .  .\n"," .  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","7 4\n","player -1's turn:\n"," .  .  O  .  .  .  .\n"," .  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  .  .  .\n","player 1's turn:\n"," .  .  O  .  .  .  O\n"," .  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  .  .  .\n","Введите ваш ход (Строка, столбец)\n","7 5\n","player -1's turn:\n"," .  .  O  .  .  .  O\n"," .  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  X  .  .\n","player 1's turn:\n"," .  .  O  .  .  .  O\n"," .  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  X  O  .\n","Введите ваш ход (Строка, столбец)\n","2 1\n","player -1's turn:\n"," .  .  O  .  .  .  O\n"," X  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  X  O  .\n","player 1's turn:\n"," .  .  O  O  .  .  O\n"," X  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  X  O  .\n","Введите ваш ход (Строка, столбец)\n","1 5\n","player -1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  .  O  .  .\n"," O  .  X  X  X  O  .\n","player 1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," .  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  O  O  .  .\n"," O  .  X  X  X  O  .\n","Введите ваш ход (Строка, столбец)\n","3 1\n","player -1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  O  O  .  .\n"," O  .  X  X  X  O  .\n","player 1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," .  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","4 1\n","player -1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," .  .  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","player 1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," .  O  X  X  X  O  X\n"," O  .  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","5 1\n","player -1's turn:\n"," .  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  .  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","player 1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  .  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","6 2\n","player -1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  .\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","player 1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  .  .\n"," O  .  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","7 2\n","player -1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  .  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  .  .\n"," O  X  X  X  X  O  O\n","player 1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  .  .\n"," O  X  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","6 6\n","player -1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  X  .\n"," O  X  X  X  X  O  O\n","player 1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  .  O  O  X  O\n"," O  X  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","6 3\n","player -1's turn:\n"," O  .  O  O  X  .  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  X  O  O  X  O\n"," O  X  X  X  X  O  O\n","player 1's turn:\n"," O  .  O  O  X  O  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  X  O  O  X  O\n"," O  X  X  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","1 2\n","player -1's turn:\n"," O  X  O  O  X  O  O\n"," X  X  X  X  O  O  O\n"," X  X  O  O  X  O  O\n"," X  X  X  O  O  X  O\n"," X  O  X  X  X  O  X\n"," O  X  X  O  O  X  O\n"," O  X  X  X  X  O  O\n","Ничья!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-44f6ae1e7b31>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHuman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-12f108871000>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, num_games, visualize)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mstate_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mcurrent_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_player\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mnext_state_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstate_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_state_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#state, action, reward, new_state, done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-4b0eda9a0e6f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstate2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Введите ваш ход (Строка, столбец)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Клетка занята!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["agent.epsilon = 0\n","test_game = TicTacToe(agent, Human(), board_size=board_size, win_size=win_size)\n","test_game.play(4, True)\n","test_game.wins"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEC7nnsVzZLb","executionInfo":{"status":"ok","timestamp":1718755383507,"user_tz":-180,"elapsed":5083,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"}},"outputId":"6bdb4d75-9a2a-4ee3-bac8-219d4c3332b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"TAq9ckumpm01"},"source":["# Первый ход за крестики и значения $Q$-фунцкии в начальном состоянии"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1718562904401,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"aKjltLQC1-vk","outputId":"4eeacc16-0953-4d2c-8386-ee747857564f"},"outputs":[{"data":{"text/plain":["(3, 3)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["state2d = torch.tensor(np.zeros((1, 7, 7))).to(device)\n","\n","q_values = agent(state2d).squeeze(0).detach().cpu().numpy()\n","np.unravel_index(q_values.argmax(), q_values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1718562908136,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"dTKnN9UG4TJN","outputId":"23486e20-ef3e-471d-b152-18788c98364b"},"outputs":[{"data":{"text/plain":["array([[-0.0684, -0.064 , -0.0358, -0.0494, -0.0263, -0.0711, -0.0195],\n","       [-0.0457, -0.0207, -0.0132, -0.0035, -0.0091, -0.029 , -0.0438],\n","       [-0.0156, -0.0113,  0.0434,  0.0295,  0.0367, -0.0051, -0.0104],\n","       [-0.0425, -0.0255,  0.0354,  0.0539,  0.0183, -0.0157, -0.0361],\n","       [-0.0721, -0.0236,  0.0205,  0.0216,  0.0134, -0.0366, -0.0267],\n","       [-0.0979, -0.0705, -0.0431, -0.0291, -0.044 , -0.0472, -0.0386],\n","       [-0.0893, -0.0818, -0.0544, -0.0399, -0.0268, -0.0384, -0.0467]],\n","      dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["q_values.round(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jzAPJvAZeGY"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1bEWfzN4sOeL7anrqvAVRHfQTNdGDzOA0","timestamp":1718717652700},{"file_id":"1xkpvZIncGCQWTMS_FZAbkoNgcgEEVSqC","timestamp":1718578441085},{"file_id":"1wqCozfdeRJnqyq9lgTKHqqbIOJ70UoZc","timestamp":1718484277044},{"file_id":"17AdIcgMxS_7_mOiy7FUK1C5VUgC8F-8_","timestamp":1718460691857},{"file_id":"1Gr04QBn85xAghWhQrafFAC3IVYCCcrdF","timestamp":1718270221903},{"file_id":"1tYpwZfpcc8mwjf9xBvf2Qh4nBVyZDdDi","timestamp":1718209975048},{"file_id":"1srwb210ZiHsQBrRBDRQ5YvK6o5ZuV2x9","timestamp":1718193488488},{"file_id":"17BHq081ewJDS6eZRZvxiWWTUVu9adCx1","timestamp":1718173770359}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
