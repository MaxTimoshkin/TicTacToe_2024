{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jas5z2XbgpIK"},"outputs":[],"source":["import numpy as np\n","from collections import deque\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1718714265662,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"eGa4uhXjfHDA","outputId":"d098eb30-c51e-495f-d341-7834919eeff6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"Q9aoBPtbKYgm"},"source":["#Игра"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkV_S73IfMyq"},"outputs":[],"source":["# Игра крестики-нолики\n","class TicTacToe:\n","    def __init__(self, player_1, player_2, board_size=3, win_size=3):\n","        self.players = {-1: player_1,\n","                         1: player_2}\n","\n","        self.wins = {player_1.name: 0,\n","                     player_2.name: 0}\n","\n","        self.board_size=board_size\n","        self.win_size = win_size\n","        self._kernel = self._create_kernel()\n","\n","\n","    # Создает ядро свертки для расчета побед\n","    def _create_kernel(self):\n","        kernel = np.zeros((2 * self.win_size + 2, self.win_size, self.win_size))\n","        for i in range(self.win_size):\n","            kernel[i, i, :] = np.ones(self.win_size)\n","        for i in range(self.win_size, 2 * self.win_size):\n","            kernel[i, :, i - self.win_size] = np.ones(self.win_size).T\n","        kernel[2 * self.win_size] = np.eye(self.win_size)\n","        kernel[2 * self.win_size + 1] = np.fliplr(np.eye(self.win_size))\n","        return kernel\n","\n","\n","    # Проверяет победы для состояний states, в кот. ходы были совершены игроками turns, turn={-1, 1}\n","    def _test_win(self, state, turn):\n","        rows, cols, w_size = *state.shape, self.win_size\n","        expanded_states = np.lib.stride_tricks.as_strided(\n","            state,\n","            shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","            strides=(*state.strides, *state.strides),\n","            writeable=False,\n","        )\n","        feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","        return -turn * (feature_map == turn * w_size).any().astype(int)\n","\n","\n","    # Проигрывание нескольких полных эпизодов\n","    def play(self, num_games=1, visualize=False):\n","        transitions = []\n","        for t in range(num_games):\n","            next_turn = turn = -1\n","            state = (np.zeros((self.board_size, self.board_size)), turn) # Начальное состояние игры. state = (state2d, turn)\n","            if visualize:\n","                self.visualize_state(state, turn)\n","            while(next_turn != 0):\n","                state_2d, turn = state\n","                current_player = self.players[turn]\n","                action = current_player.get_action(state)\n","                next_state_2d, next_turn, reward = self.play_turn(state, action)\n","                transitions.append((turn * state_2d, action, reward, -turn * next_state_2d, next_turn == 0))   #state, action, reward, new_state, done\n","                if visualize:\n","                    self.visualize_state((next_state_2d, next_turn), turn)\n","                if next_turn == 0:\n","                    if visualize:\n","                        if (reward == 0): print('Ничья!\\n')\n","                        else: print(f'Победа ({self.players[reward * turn].name})!\\n')\n","                    if reward != 0:\n","                        self.wins[self.players[reward * turn].name] += 1\n","                    self.players = {-1: self.players[1], 1: self.players[-1]}\n","                state = next_state_2d, next_turn\n","        return transitions\n","\n","\n","    # Выполнение хода и проверка на некорректный ход (проигрышь) / выигрыш / ничью\n","    def play_turn(self, state, action): # next_state2d, next_turn, reward\n","        state2d, turn = state\n","        next_state2d = state2d.copy()\n","\n","        # Проверка корректности хода\n","        if (state2d[(action)] != 0):\n","            return next_state2d, 0, -1        # Игрок проиграл (# next_turn == 0 => Игра окончена)\n","\n","        # Совершение хода\n","        next_state2d[action] = turn\n","\n","        # Проверка победы\n","        if self._test_win(next_state2d, turn):\n","            return next_state2d, 0, 1         # Текущий игрок побеждает (next_turn == 0 => Игра окончена)\n","\n","        # Проверка ничьи\n","        if (next_state2d != 0).all():\n","            return next_state2d, 0, 0         # Ничья (next_turn == 0 => Игра окончена)\n","\n","        # Инчае, ход следующего игрока\n","        return next_state2d, -turn, 0         # next_turn == -turn => Смена хода\n","\n","\n","    # Выводит на экран состояние игры после хода игрока\n","    @staticmethod\n","    def visualize_state(next_state, turn):\n","        next_state2d, next_turn = next_state\n","        print(f\"player {turn}'s turn:\")\n","        if (next_state2d == 0).all() and turn == 0:\n","            print(\"[invalid state]\\n\\n\")\n","        else:\n","            print(str(next_state2d)\n","                  .replace(\".\", \"\")\n","                  .replace(\"[[\", \"\")\n","                  .replace(\" [\", \"\")\n","                  .replace(\"]]\", \"\")\n","                  .replace(\"]\", \"\")\n","                  .replace(\"-0\", \" .\")\n","                  .replace(\"0\", \".\")\n","                  .replace(\"-1\", \" X\")\n","                  .replace(\"1\", \"O\")\n","            )\n","\n","\n","    @staticmethod\n","    def print_transitions(transitions):\n","        states, actions, rewards, next_states, dones = zip(*transitions)\n","        for i in np.arange(len(states)):\n","            print(\"\\033[31m{}.\".format(i + 1), '\\033[30m')\n","            TicTacToe.visualize_state((next_states[i], -1), 1)\n","            print('\\naction = ', actions[i] + np.array([1, 1]), end='\\n')\n","            print('reward = ', rewards[i], end='\\n')\n","            if (dones[i]): print('Игра окончена', end='\\n\\n')\n","            else: print('Игра продолжается', end='\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"M3pr2-P0Ka5F"},"source":["#Игроки"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5rtWxp4hTVB"},"outputs":[],"source":["class Human:\n","    def __init__(self, name='Human'):\n","        self.name = name\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        print('Введите ваш ход (Строка, столбец)')\n","        row, col = map(int, input().split())\n","        while (state2d[row - 1, col - 1] != 0):\n","            print('Клетка занята!')\n","            print('Введите ваш ход (Строка, столбец)')\n","            row, col = map(int, input().split())\n","        return row - 1, col - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPVMOC0qTIlK"},"outputs":[],"source":["# Игрок Рандом с преимуществами:\n","# 1. Если есть возможность выиграть за один ход, он делает это (win = True)\n","# 2. Если у соперника есть возможность выиграть в следующем ходу, он блокирует этот ход (defense = True)\n","# 3. Если есть возможность построить четверку, он делает это (win_2 = True)\n","# 4. Если у соперника есть возможность построить четверку в следующем ходу, он блокирует этот ход (defense_2 = True)\n","# 5. Иначе, выбирает случайный ход из множества допустимых\n","class RandomPlus:\n","    def __init__(self, board_size=3, win_size=3, name='RandomPlus',\n","                 win=False, defense=False, win_2=False, defense_2=False):\n","        self.name = name\n","        self.board_size = board_size\n","        self.win_size = win_size\n","\n","        self.win = win\n","        self.defense = defense\n","\n","        self.win_2 = win_2\n","        self.defense_2 = defense_2\n","\n","        if win or defense:\n","            self._kernel = self._create_kernel(win_size)\n","\n","        if win_2 or defense_2:\n","            self._kernel_2 = self._create_kernel(win_size - 1)\n","\n","\n","    # Создает ядро свертки для расчета потенциальных побед\n","    def _create_kernel(self, win_size):\n","        kernel = np.zeros((2 * win_size + 2, win_size, win_size))\n","        for i in range(win_size):\n","            kernel[i, i, :] = np.ones(win_size)\n","        for i in range(win_size, 2 * win_size):\n","            kernel[i, :, i - win_size] = np.ones(win_size).T\n","        kernel[2 * win_size] = np.eye(win_size)\n","        kernel[2 * win_size + 1] = np.fliplr(np.eye(win_size))\n","        return kernel\n","\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        rows, cols, w_size = *state2d.shape, self.win_size\n","\n","        if self.win or self.defense:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","\n","            if self.win:\n","                wins = np.array(np.where(turn * feature_map == w_size - 1))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 1))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        if self.win_2 or self.defense_2:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 2, cols - w_size + 2, w_size - 1, w_size - 1),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel_2)\n","\n","            if self.win_2:\n","                wins = np.array(np.where(turn * feature_map == w_size - 2))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense_2:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 2))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRBw9v0hmVIi"},"outputs":[],"source":["class DQNAgent(nn.Module):\n","    def __init__(self, epsilon=0, name='DQNAgent', masking=False):\n","        super().__init__()\n","\n","        self.name = name\n","        self.epsilon = epsilon\n","        self.n_channels = 3\n","        self.masking = masking    # Маскирование (ВКЛЮЧАТЬ ТОЛЬКО ПРИ ИНФЕРЕНСЕ)\n","\n","        self.network = nn.Sequential(\n","            nn.Conv2d(self.n_channels, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 1, kernel_size=(3, 3), padding='same')\n","        )\n","\n","    def forward(self, x):\n","        x = torch.stack([x == 1, x == -1, x == 0], axis=1).float()\n","        return self.network(x).squeeze(1)\n","\n","    def greedy_action(self, state, device=device):\n","        state2d, turn = state\n","        state_t = torch.FloatTensor(turn * state2d).unsqueeze(0).to(device)\n","        q_values = self.forward(state_t).squeeze(0).detach().cpu().numpy()\n","        if self.masking:\n","            q_values[state2d != 0] = -float(\"Inf\")\n","        return np.unravel_index(q_values.argmax(), q_values.shape)\n","\n","    def random_action(self, state):\n","        state2d, turn = state\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])\n","\n","    def get_action(self, state):\n","        if random.random() < self.epsilon:\n","            action = self.random_action(state)\n","        else:\n","            action = self.greedy_action(state)\n","        return action"]},{"cell_type":"markdown","metadata":{"id":"03J3GWj6P8tj"},"source":["# Буферы"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ni-Mh6jE_-Xd"},"outputs":[],"source":["# Обычный буфер\n","class ReplayBuffer(object):\n","    def __init__(self, size):\n","        self._storage = deque(maxlen=size)\n","\n","    def __len__(self):\n","        return len(self._storage)\n","\n","    def add(self, transition):\n","        self._storage.append(transition)\n","\n","    def sample(self, batch_size, augmentation=False):\n","        batch = random.sample(self._storage, batch_size)\n","        states, actions, rewards, next_states, dones = zip(*batch)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            # ======== ДЛЯ ВСЕГО БАТЧА ОДИНАКОВАЯ АУГМЕНТАЦИЯ ========\n","            # n = states.shape[-1] - 1\n","            # k = np.random.randint(0, 4)\n","            # states = np.rot90(states, k, axes=(1,2)).copy()\n","            # next_states = np.rot90(next_states, k, axes=(1,2)).copy()\n","\n","            # i, j = actions[:, 0], actions[:, 1]\n","            # if k == 1: actions = np.column_stack((n - j, i))\n","            # if k == 2: actions = np.column_stack((n - i, n - j))\n","            # if k == 3: actions = np.column_stack((j, n - i))\n","\n","\n","            # ======== ДЛЯ КАЖДОГО ЭЛЕМЕНТА БАТЧА ОТДЕЛЬНО ========\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","\n","            # ======== УВЕЛИЧЕНИЕ X4 ========\n","            # n = states.shape[-1] - 1\n","            # i, j = actions[:, 0], actions[:, 1]\n","\n","            # states = np.concatenate([np.rot90(states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # next_states = np.concatenate([np.rot90(next_states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # actions = np.concatenate([actions,\n","            #                           np.column_stack((n - j, i)),\n","            #                           np.column_stack((n - i, n - j)),\n","            #                           np.column_stack((j, n - i))], axis=0)\n","            # rewards = np.tile(rewards, 4)\n","            # dones = np.tile(dones, 4)\n","\n","        return states, actions, rewards, next_states, dones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYidASkNW5XC"},"outputs":[],"source":["# =========== Prioritized Replay Buffer With Augmentation ===========\n","class PrioritizedBuffer(object):\n","    def __init__(self, capacity, prob_alpha=0.6):\n","        self.prob_alpha = prob_alpha\n","        self.capacity = capacity\n","        self.buffer = []\n","        self.pos = 0\n","        self.priorities = np.zeros((capacity,), dtype=np.float32)\n","\n","    def add(self, state, action, reward, next_state, done):\n","        max_prio = self.priorities.max() if self.buffer else 1.0\n","\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append((state, action, reward, next_state, done))\n","        else:\n","            self.buffer[self.pos] = (state, action, reward, next_state, done)\n","\n","        self.priorities[self.pos] = max_prio\n","        self.pos = (self.pos + 1) % self.capacity\n","\n","    def sample(self, batch_size, beta=0.4, augmentation=False):\n","        if len(self.buffer) == self.capacity:\n","            prios = self.priorities\n","        else:\n","            prios = self.priorities[:self.pos]\n","\n","        probs  = prios ** self.prob_alpha\n","        probs /= probs.sum()\n","\n","        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n","        samples = [self.buffer[idx] for idx in indices]\n","\n","        total    = len(self.buffer)\n","        weights  = (total * probs[indices]) ** (-beta)\n","        weights /= weights.max()\n","        weights  = np.array(weights, dtype=np.float32)\n","\n","        states, actions, rewards, next_states, dones = zip(*samples)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","        return states, actions, rewards, next_states, dones, indices, weights\n","\n","    def update_priorities(self, batch_indices, batch_priorities):\n","        for idx, prio in zip(batch_indices, batch_priorities):\n","            self.priorities[idx] = prio\n","\n","    def __len__(self):\n","        return len(self.buffer)"]},{"cell_type":"markdown","metadata":{"id":"32ujexFHKgAU"},"source":["#Функции и гиперпараметры для обучения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWj7D_iuy3oT"},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRFnHMHaC7um"},"outputs":[],"source":["board_size = 7\n","win_size = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_gPKyIB504V"},"outputs":[],"source":["# Гиперпараметры метода DQN\n","\n","batch_size = 128        # 512 - много\n","total_steps = 90_000\n","\n","decay_steps = 60_000\n","init_epsilon = 1\n","final_epsilon = 0.25     # 0.02 - мало; 0.1 - мало\n","\n","loss_freq = 100\n","refresh_target_network_freq = 100    # 1000 - много, 50 - мало\n","\n","eval_freq = 500\n","n_eval_games = 100\n","\n","max_grad_norm = 50\n","\n","gamma = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuZM4BiVn_8X"},"outputs":[],"source":["agent = DQNAgent(init_epsilon).to(device)\n","\n","target_network = DQNAgent(init_epsilon).to(device)\n","target_network.load_state_dict(agent.state_dict())\n","\n","optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n","exp_replay = PrioritizedBuffer(16_000) #ReplayBuffer(16_000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1718714267671,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"-ZJT-NWjTE9g","outputId":"af8f7802-d773-487c-e95d-959d689baf64"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1185025"]},"metadata":{},"execution_count":13}],"source":["sum([p.numel() for p in agent.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKGcoDrQCzXi"},"outputs":[],"source":["# Возвращает temporal difference loss\n","def compute_td_loss(states, actions, rewards, next_states, dones,\n","                    agent, target_network, weights=None, indices=None,    #exp_replay\n","                    gamma=0.9, device=device, prioritized=False):\n","\n","    states = torch.tensor(states, device=device, dtype=torch.float32)                # shape: [batch_size, state_dim]\n","    actions = torch.tensor(actions, device=device, dtype=torch.int64)                # shape: [batch_size]\n","    rewards = torch.tensor(rewards, device=device, dtype=torch.float32)              # shape: [batch_size]\n","    next_states = torch.tensor(next_states, device=device, dtype=torch.float32)      # shape: [batch_size, state_dim]\n","    dones = torch.tensor(dones, device=device, dtype=torch.int64)                    # shape: [batch_size]\n","\n","    predicted_qvalues = agent(states)                                                # shape: [batch_size, n_actions]\n","    predicted_next_qvalues = target_network(next_states)                             # shape: [batch_size, n_actions]\n","    predicted_qvalues_for_actions = predicted_qvalues[range(len(actions)), actions[:, 0], actions[:, 1]]  # shape: [batch_size]\n","    next_state_values = predicted_next_qvalues.view(dones.shape[0], -1).max(axis=1).values\n","    target_qvalues_for_actions = rewards - (1 - dones) * gamma * next_state_values\n","\n","    if prioritized:   #[Prioterized DQN]\n","        weights = torch.tensor(weights, device=device, dtype=torch.float32)\n","        loss = weights * (predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2\n","        prios = (loss + 1e-5).data.cpu().numpy()  # Обновление приоритетов\n","        loss = torch.mean(loss)\n","        exp_replay.update_priorities(indices, prios)\n","        return loss\n","    else:\n","        return torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)  #loss\n","\n","# Рассчитывает epsilon на текущем шаге step\n","def linear_decay(init_epsilon, final_epsilon, step, decay_steps):\n","    return max(init_epsilon - step * (init_epsilon - final_epsilon) / decay_steps, final_epsilon)"]},{"cell_type":"markdown","metadata":{"id":"e73vABV6cKH2"},"source":["# Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27632,"status":"ok","timestamp":1718714295289,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"IigXAGYNdoU7","outputId":"831feb8f-7757-46a4-c42e-5aaa22755b28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVtRXPFnZ1ug"},"outputs":[],"source":["main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4mXgvfVsN-2"},"outputs":[],"source":["PATH = f'/content/drive/MyDrive/TicTacToe_9/'\n","\n","loss = None\n","loss_values = []\n","reward_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0C5lrTuAUGmp","outputId":"c2ffcb6c-92b7-428e-9a19-cf5fa56d58a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["t = 0    \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 100  \t loss = 0.0003841750440187752\t eps = 0.9987\n","t = 200  \t loss = 0.0013114686589688063\t eps = 0.9973\n","t = 300  \t loss = 0.0014353715814650059\t eps = 0.996\n","t = 400  \t loss = 0.0027881222777068615\t eps = 0.9947\n","t = 500  \t loss = 0.0027120334561914206\t eps = 0.9933\n","t = 500  \t reward = -0.96\t{'DQNAgent': 2, 'RandomPlus': 98}\n","\n","t = 600  \t loss = 0.0022848183289170265\t eps = 0.992\n","t = 700  \t loss = 0.0027413733769208193\t eps = 0.9907\n","t = 800  \t loss = 0.0028765317983925343\t eps = 0.9893\n","t = 900  \t loss = 0.002784157171845436\t eps = 0.988\n","t = 1000 \t loss = 0.002125442260876298\t eps = 0.9867\n","t = 1000 \t reward = -0.9\t{'DQNAgent': 5, 'RandomPlus': 95}\n","\n","t = 1100 \t loss = 0.002114892704412341\t eps = 0.9853\n","t = 1200 \t loss = 0.003842887468636036\t eps = 0.984\n","t = 1300 \t loss = 0.0021191625855863094\t eps = 0.9827\n","t = 1400 \t loss = 0.004602209664881229\t eps = 0.9813\n","t = 1500 \t loss = 0.0019302833825349808\t eps = 0.98\n","t = 1500 \t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 1600 \t loss = 0.0021826140582561493\t eps = 0.9787\n","t = 1700 \t loss = 0.001137333456426859\t eps = 0.9773\n","t = 1800 \t loss = 0.0016688366886228323\t eps = 0.976\n","t = 1900 \t loss = 0.0020764435175806284\t eps = 0.9747\n","t = 2000 \t loss = 0.0011464140843600035\t eps = 0.9733\n","t = 2000 \t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 2100 \t loss = 0.0018721534870564938\t eps = 0.972\n","t = 2200 \t loss = 0.0022945767268538475\t eps = 0.9707\n","t = 2300 \t loss = 0.0009757824009284377\t eps = 0.9693\n","t = 2400 \t loss = 0.0008023750269785523\t eps = 0.968\n","t = 2500 \t loss = 0.0014641197631135583\t eps = 0.9667\n","t = 2500 \t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 2600 \t loss = 0.0011556611862033606\t eps = 0.9653\n","t = 2700 \t loss = 0.0017432956956326962\t eps = 0.964\n","t = 2800 \t loss = 0.001212649280205369\t eps = 0.9627\n","t = 2900 \t loss = 0.001303249504417181\t eps = 0.9613\n","t = 3000 \t loss = 0.005107239820063114\t eps = 0.96\n","t = 3000 \t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 3100 \t loss = 0.0012824895093217492\t eps = 0.9587\n","t = 3200 \t loss = 0.0014053334016352892\t eps = 0.9573\n","t = 3300 \t loss = 0.0018434477970004082\t eps = 0.956\n","t = 3400 \t loss = 0.0012701781233772635\t eps = 0.9547\n","t = 3500 \t loss = 0.00487541314214468\t eps = 0.9533\n","t = 3500 \t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 3600 \t loss = 0.001039569266140461\t eps = 0.952\n","t = 3700 \t loss = 0.0007622242555953562\t eps = 0.9507\n","t = 3800 \t loss = 0.0013819367159157991\t eps = 0.9493\n","t = 3900 \t loss = 0.0025375455152243376\t eps = 0.948\n","t = 4000 \t loss = 0.0027325700502842665\t eps = 0.9467\n","t = 4000 \t reward = 0.76\t{'DQNAgent': 88, 'RandomPlus': 12}\n","\n","t = 4100 \t loss = 0.0008835385087877512\t eps = 0.9453\n","t = 4200 \t loss = 0.0011506853625178337\t eps = 0.944\n","t = 4300 \t loss = 0.0007144439732655883\t eps = 0.9427\n","t = 4400 \t loss = 0.0017699897289276123\t eps = 0.9413\n","t = 4500 \t loss = 0.003094820538535714\t eps = 0.94\n","t = 4500 \t reward = 0.74\t{'DQNAgent': 87, 'RandomPlus': 13}\n","\n","t = 4600 \t loss = 0.0013755835825577378\t eps = 0.9387\n","t = 4700 \t loss = 0.0007947998819872737\t eps = 0.9373\n","t = 4800 \t loss = 0.001520835212431848\t eps = 0.936\n","t = 4900 \t loss = 0.0021526117343455553\t eps = 0.9347\n","t = 5000 \t loss = 0.000662568025290966\t eps = 0.9333\n","t = 5000 \t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 5100 \t loss = 0.0019110030261799693\t eps = 0.932\n","t = 5200 \t loss = 0.0013195434585213661\t eps = 0.9307\n","t = 5300 \t loss = 0.00142541597597301\t eps = 0.9293\n","t = 5400 \t loss = 0.0010397130390629172\t eps = 0.928\n","t = 5500 \t loss = 0.0009653947781771421\t eps = 0.9267\n","t = 5500 \t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 5600 \t loss = 0.001492452109232545\t eps = 0.9253\n","t = 5700 \t loss = 0.0010736389085650444\t eps = 0.924\n","t = 5800 \t loss = 0.0017164439195767045\t eps = 0.9227\n","t = 5900 \t loss = 0.0013632344780489802\t eps = 0.9213\n","t = 6000 \t loss = 0.0010543267708271742\t eps = 0.92\n","t = 6000 \t reward = 0.78\t{'DQNAgent': 89, 'RandomPlus': 11}\n","\n","t = 6100 \t loss = 0.0008394462638534606\t eps = 0.9187\n","t = 6200 \t loss = 0.0015837944811210036\t eps = 0.9173\n","t = 6300 \t loss = 0.0014875916531309485\t eps = 0.916\n","t = 6400 \t loss = 0.0008672608528286219\t eps = 0.9147\n","t = 6500 \t loss = 0.001307881437242031\t eps = 0.9133\n","t = 6500 \t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 6600 \t loss = 0.0009641434880904853\t eps = 0.912\n","t = 6700 \t loss = 0.0012323749251663685\t eps = 0.9107\n","t = 6800 \t loss = 0.001091822050511837\t eps = 0.9093\n","t = 6900 \t loss = 0.0017608285415917635\t eps = 0.908\n","t = 7000 \t loss = 0.0018809420289471745\t eps = 0.9067\n","t = 7000 \t reward = 0.76\t{'DQNAgent': 88, 'RandomPlus': 12}\n","\n","t = 7100 \t loss = 0.0023027933202683926\t eps = 0.9053\n","t = 7200 \t loss = 0.0010867477394640446\t eps = 0.904\n","t = 7300 \t loss = 0.00190072413533926\t eps = 0.9027\n","t = 7400 \t loss = 0.001586881815455854\t eps = 0.9013\n","t = 7500 \t loss = 0.0013787089847028255\t eps = 0.9\n","t = 7500 \t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 7600 \t loss = 0.005401975009590387\t eps = 0.8987\n","t = 7700 \t loss = 0.001474499236792326\t eps = 0.8973\n","t = 7800 \t loss = 0.001797489239834249\t eps = 0.896\n","t = 7900 \t loss = 0.0014951196499168873\t eps = 0.8947\n","t = 8000 \t loss = 0.0007372133550234139\t eps = 0.8933\n","t = 8000 \t reward = 0.82\t{'DQNAgent': 91, 'RandomPlus': 9}\n","\n","t = 8100 \t loss = 0.002312049036845565\t eps = 0.892\n","t = 8200 \t loss = 0.0009794940706342459\t eps = 0.8907\n","t = 8300 \t loss = 0.0011609777575358748\t eps = 0.8893\n","t = 8400 \t loss = 0.0010483585065230727\t eps = 0.888\n","t = 8500 \t loss = 0.0010186719009652734\t eps = 0.8867\n","t = 8500 \t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 8600 \t loss = 0.000784465519245714\t eps = 0.8853\n","t = 8700 \t loss = 0.0012283537071198225\t eps = 0.884\n","t = 8800 \t loss = 0.0009706569835543633\t eps = 0.8827\n","t = 8900 \t loss = 0.0015501470770686865\t eps = 0.8813\n","t = 9000 \t loss = 0.0010250515770167112\t eps = 0.88\n","t = 9000 \t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 9100 \t loss = 0.0010971776209771633\t eps = 0.8787\n","t = 9200 \t loss = 0.0007388349040411413\t eps = 0.8773\n","t = 9300 \t loss = 0.0012735790805891156\t eps = 0.876\n","t = 9400 \t loss = 0.0018310440937057137\t eps = 0.8747\n","t = 9500 \t loss = 0.001842460478655994\t eps = 0.8733\n","t = 9500 \t reward = 0.82\t{'DQNAgent': 91, 'RandomPlus': 9}\n","\n","t = 9600 \t loss = 0.000877650105394423\t eps = 0.872\n","t = 9700 \t loss = 0.0009254486649297178\t eps = 0.8707\n","t = 9800 \t loss = 0.0008058118401095271\t eps = 0.8693\n","t = 9900 \t loss = 0.0014526703162118793\t eps = 0.868\n","t = 10000\t loss = 0.0007063903613016009\t eps = 0.8667\n","t = 10000\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 10100\t loss = 0.0020701545290648937\t eps = 0.8653\n","t = 10200\t loss = 0.0006286889547482133\t eps = 0.864\n","t = 10300\t loss = 0.000753303524106741\t eps = 0.8627\n","t = 10400\t loss = 0.0010741520673036575\t eps = 0.8613\n","t = 10500\t loss = 0.0014441669918596745\t eps = 0.86\n","t = 10500\t reward = 0.76\t{'DQNAgent': 88, 'RandomPlus': 12}\n","\n","t = 10600\t loss = 0.000697917421348393\t eps = 0.8587\n","t = 10700\t loss = 0.0006471765809692442\t eps = 0.8573\n","t = 10800\t loss = 0.0028958835173398256\t eps = 0.856\n","t = 10900\t loss = 0.0020993377547711134\t eps = 0.8547\n","t = 11000\t loss = 0.0008114524534903467\t eps = 0.8533\n","t = 11000\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 11100\t loss = 0.0011100000701844692\t eps = 0.852\n","t = 11200\t loss = 0.0010112505406141281\t eps = 0.8507\n","t = 11300\t loss = 0.0004995614290237427\t eps = 0.8493\n","t = 11400\t loss = 0.0007760470034554601\t eps = 0.848\n","t = 11500\t loss = 0.001023458898998797\t eps = 0.8467\n","t = 11500\t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 11600\t loss = 0.000739468727260828\t eps = 0.8453\n","t = 11700\t loss = 0.0012081039603799582\t eps = 0.844\n","t = 11800\t loss = 0.0014227903448045254\t eps = 0.8427\n","t = 11900\t loss = 0.0016717893304303288\t eps = 0.8413\n","t = 12000\t loss = 0.0007293400703929365\t eps = 0.84\n","t = 12000\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 12100\t loss = 0.0019170171581208706\t eps = 0.8387\n","t = 12200\t loss = 0.0009935215348377824\t eps = 0.8373\n","t = 12300\t loss = 0.0018942441092804074\t eps = 0.836\n","t = 12400\t loss = 0.0011835889890789986\t eps = 0.8347\n","t = 12500\t loss = 0.0017500624526292086\t eps = 0.8333\n","t = 12500\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 12600\t loss = 0.0007998790824785829\t eps = 0.832\n","t = 12700\t loss = 0.0007573675829917192\t eps = 0.8307\n","t = 12800\t loss = 0.0020183040760457516\t eps = 0.8293\n","t = 12900\t loss = 0.0017611265648156404\t eps = 0.828\n","t = 13000\t loss = 0.0013261539861559868\t eps = 0.8267\n","t = 13000\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 13100\t loss = 0.0006631887517869473\t eps = 0.8253\n","t = 13200\t loss = 0.0008498874958604574\t eps = 0.824\n","t = 13300\t loss = 0.0008342587389051914\t eps = 0.8227\n","t = 13400\t loss = 0.0007163580739870667\t eps = 0.8213\n","t = 13500\t loss = 0.0015117411967366934\t eps = 0.82\n","t = 13500\t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 13600\t loss = 0.0005486777517944574\t eps = 0.8187\n","t = 13700\t loss = 0.0005703631322830915\t eps = 0.8173\n","t = 13800\t loss = 0.0008146720938384533\t eps = 0.816\n","t = 13900\t loss = 0.0021717161871492863\t eps = 0.8147\n","t = 14000\t loss = 0.002041394356638193\t eps = 0.8133\n","t = 14000\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 14100\t loss = 0.0006107799126766622\t eps = 0.812\n","t = 14200\t loss = 0.0014651557430624962\t eps = 0.8107\n","t = 14300\t loss = 0.0012240492505952716\t eps = 0.8093\n","t = 14400\t loss = 0.0006969236419536173\t eps = 0.808\n","t = 14500\t loss = 0.0009199126507155597\t eps = 0.8067\n","t = 14500\t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 14600\t loss = 0.0007234066724777222\t eps = 0.8053\n","t = 14700\t loss = 0.000976069422904402\t eps = 0.804\n","t = 14800\t loss = 0.001686283154413104\t eps = 0.8027\n","t = 14900\t loss = 0.000632166862487793\t eps = 0.8013\n","t = 15000\t loss = 0.0009219031780958176\t eps = 0.8\n","t = 15000\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 15100\t loss = 0.0005679677706211805\t eps = 0.7987\n","t = 15200\t loss = 0.0017235715640708804\t eps = 0.7973\n","t = 15300\t loss = 0.0022145938128232956\t eps = 0.796\n","t = 15400\t loss = 0.0006199490744620562\t eps = 0.7947\n","t = 15500\t loss = 0.0007924711680971086\t eps = 0.7933\n","t = 15500\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 15600\t loss = 0.002956247655674815\t eps = 0.792\n","t = 15700\t loss = 0.0004608709132298827\t eps = 0.7907\n","t = 15800\t loss = 0.0006855493411421776\t eps = 0.7893\n","t = 15900\t loss = 0.0011730048572644591\t eps = 0.788\n","t = 16000\t loss = 0.0007945956313051283\t eps = 0.7867\n","t = 16000\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 16100\t loss = 0.000632811221294105\t eps = 0.7853\n","t = 16200\t loss = 0.0008189421496354043\t eps = 0.784\n","t = 16300\t loss = 0.0009552381234243512\t eps = 0.7827\n","t = 16400\t loss = 0.001371449208818376\t eps = 0.7813\n","t = 16500\t loss = 0.0006912447279319167\t eps = 0.78\n","t = 16500\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 16600\t loss = 0.0010879684705287218\t eps = 0.7787\n","t = 16700\t loss = 0.00039415271021425724\t eps = 0.7773\n","t = 16800\t loss = 0.0006910284282639623\t eps = 0.776\n","t = 16900\t loss = 0.0011516055092215538\t eps = 0.7747\n","t = 17000\t loss = 0.0019707106985151768\t eps = 0.7733\n","t = 17000\t reward = 0.95\t{'DQNAgent': 97, 'RandomPlus': 2}\n","\n","t = 17100\t loss = 0.0006214150926098228\t eps = 0.772\n","t = 17200\t loss = 0.0007106650155037642\t eps = 0.7707\n","t = 17300\t loss = 0.0008707016240805387\t eps = 0.7693\n","t = 17400\t loss = 0.0008852194878272712\t eps = 0.768\n","t = 17500\t loss = 0.0007837900193408132\t eps = 0.7667\n","t = 17500\t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 17600\t loss = 0.0007529376889578998\t eps = 0.7653\n","t = 17700\t loss = 0.0010278852423653007\t eps = 0.764\n","t = 17800\t loss = 0.0009814499644562602\t eps = 0.7627\n","t = 17900\t loss = 0.0017451634630560875\t eps = 0.7613\n","t = 18000\t loss = 0.0009745543356984854\t eps = 0.76\n","t = 18000\t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 18100\t loss = 0.00046211195876821876\t eps = 0.7587\n","t = 18200\t loss = 0.0008936768863350153\t eps = 0.7573\n","t = 18300\t loss = 0.0024856836535036564\t eps = 0.756\n","t = 18400\t loss = 0.0004741843731608242\t eps = 0.7547\n","t = 18500\t loss = 0.000593260454479605\t eps = 0.7533\n","t = 18500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 18600\t loss = 0.0012096886057406664\t eps = 0.752\n","t = 18700\t loss = 0.002355828881263733\t eps = 0.7507\n","t = 18800\t loss = 0.0007439575856551528\t eps = 0.7493\n","t = 18900\t loss = 0.0007077826885506511\t eps = 0.748\n","t = 19000\t loss = 0.0021814710926264524\t eps = 0.7467\n","t = 19000\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 19100\t loss = 0.0009562118793837726\t eps = 0.7453\n","t = 19200\t loss = 0.0005065295845270157\t eps = 0.744\n","t = 19300\t loss = 0.0013673771172761917\t eps = 0.7427\n","t = 19400\t loss = 0.0033428228925913572\t eps = 0.7413\n","t = 19500\t loss = 0.0005145397735759616\t eps = 0.74\n","t = 19500\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 19600\t loss = 0.0008876401116140187\t eps = 0.7387\n","t = 19700\t loss = 0.0010641231201589108\t eps = 0.7373\n","t = 19800\t loss = 0.0009569599060341716\t eps = 0.736\n","t = 19900\t loss = 0.0007243026047945023\t eps = 0.7347\n","t = 20000\t loss = 0.0005517081590369344\t eps = 0.7333\n","t = 20000\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 20100\t loss = 0.0016323546878993511\t eps = 0.732\n","t = 20200\t loss = 0.0009971654508262873\t eps = 0.7307\n","t = 20300\t loss = 0.0006615706952288747\t eps = 0.7293\n","t = 20400\t loss = 0.001049757469445467\t eps = 0.728\n","t = 20500\t loss = 0.0007978586945682764\t eps = 0.7267\n","t = 20500\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 20600\t loss = 0.0005220053135417402\t eps = 0.7253\n","t = 20700\t loss = 0.003656963352113962\t eps = 0.724\n","t = 20800\t loss = 0.0007902908837422729\t eps = 0.7227\n","t = 20900\t loss = 0.0013070483691990376\t eps = 0.7213\n","t = 21000\t loss = 0.000969802204053849\t eps = 0.72\n","t = 21000\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 21100\t loss = 0.0007406327640637755\t eps = 0.7187\n","t = 21200\t loss = 0.00048246135702356696\t eps = 0.7173\n","t = 21300\t loss = 0.0008140243589878082\t eps = 0.716\n","t = 21400\t loss = 0.0007539604557678103\t eps = 0.7147\n","t = 21500\t loss = 0.0008847804856486619\t eps = 0.7133\n","t = 21500\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 21600\t loss = 0.000714360736310482\t eps = 0.712\n","t = 21700\t loss = 0.0008950268384069204\t eps = 0.7107\n","t = 21800\t loss = 0.0008447271538898349\t eps = 0.7093\n","t = 21900\t loss = 0.00043385906610637903\t eps = 0.708\n","t = 22000\t loss = 0.0005689010140486062\t eps = 0.7067\n","t = 22000\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 22100\t loss = 0.00041611280175857246\t eps = 0.7053\n","t = 22200\t loss = 0.0009061194723471999\t eps = 0.704\n","t = 22300\t loss = 0.001421336317434907\t eps = 0.7027\n","t = 22400\t loss = 0.0005963601870462298\t eps = 0.7013\n","t = 22500\t loss = 0.001034246408380568\t eps = 0.7\n","t = 22500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 22600\t loss = 0.0008213528781197965\t eps = 0.6987\n","t = 22700\t loss = 0.0008955232333391905\t eps = 0.6973\n","t = 22800\t loss = 0.0008300788467749953\t eps = 0.696\n","t = 22900\t loss = 0.001021039206534624\t eps = 0.6947\n","t = 23000\t loss = 0.0007267227047123015\t eps = 0.6933\n","t = 23000\t reward = 0.92\t{'DQNAgent': 96, 'RandomPlus': 4}\n","\n","t = 23100\t loss = 0.000993117573671043\t eps = 0.692\n","t = 23200\t loss = 0.0013934250455349684\t eps = 0.6907\n","t = 23300\t loss = 0.0007518250495195389\t eps = 0.6893\n","t = 23400\t loss = 0.0007588817388750613\t eps = 0.688\n","t = 23500\t loss = 0.0022170040756464005\t eps = 0.6867\n","t = 23500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 23600\t loss = 0.000918702979106456\t eps = 0.6853\n","t = 23700\t loss = 0.0011311080306768417\t eps = 0.684\n","t = 23800\t loss = 0.001075000036507845\t eps = 0.6827\n","t = 23900\t loss = 0.0008262241608463228\t eps = 0.6813\n","t = 24000\t loss = 0.00086700648535043\t eps = 0.68\n","t = 24000\t reward = 0.95\t{'DQNAgent': 97, 'RandomPlus': 2}\n","\n","t = 24100\t loss = 0.0005643745535053313\t eps = 0.6787\n","t = 24200\t loss = 0.0016179759986698627\t eps = 0.6773\n","t = 24300\t loss = 0.00044760614400729537\t eps = 0.676\n","t = 24400\t loss = 0.0005524976295419037\t eps = 0.6747\n","t = 24500\t loss = 0.0013570907758548856\t eps = 0.6733\n","t = 24500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 24600\t loss = 0.0004487374098971486\t eps = 0.672\n","t = 24700\t loss = 0.0006373581127263606\t eps = 0.6707\n","t = 24800\t loss = 0.0007367045618593693\t eps = 0.6693\n","t = 24900\t loss = 0.0008748611435294151\t eps = 0.668\n","t = 25000\t loss = 0.0005264548235572875\t eps = 0.6667\n","t = 25000\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 25100\t loss = 0.0008977000252343714\t eps = 0.6653\n","t = 25200\t loss = 0.0005651874234899879\t eps = 0.664\n","t = 25300\t loss = 0.0007599532837048173\t eps = 0.6627\n","t = 25400\t loss = 0.0015022984007373452\t eps = 0.6613\n","t = 25500\t loss = 0.0007533570169471204\t eps = 0.66\n","t = 25500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 25600\t loss = 0.0009459489956498146\t eps = 0.6587\n","t = 25700\t loss = 0.0007894821465015411\t eps = 0.6573\n","t = 25800\t loss = 0.000757695990614593\t eps = 0.656\n","t = 25900\t loss = 0.0004950533621013165\t eps = 0.6547\n","t = 26000\t loss = 0.00115380366332829\t eps = 0.6533\n","t = 26000\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 26100\t loss = 0.0007125663105398417\t eps = 0.652\n","t = 26200\t loss = 0.0004173247143626213\t eps = 0.6507\n","t = 26300\t loss = 0.0017751639243215322\t eps = 0.6493\n","t = 26400\t loss = 0.0006183071527630091\t eps = 0.648\n","t = 26500\t loss = 0.0007976427441462874\t eps = 0.6467\n","t = 26500\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 26600\t loss = 0.0004989425651729107\t eps = 0.6453\n","t = 26700\t loss = 0.0006682525854557753\t eps = 0.644\n","t = 26800\t loss = 0.0009640943026170135\t eps = 0.6427\n","t = 26900\t loss = 0.0006662230589427054\t eps = 0.6413\n","t = 27000\t loss = 0.000573864090256393\t eps = 0.64\n","t = 27000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 27100\t loss = 0.0009466834599152207\t eps = 0.6387\n","t = 27200\t loss = 0.0006993985734879971\t eps = 0.6373\n","t = 27300\t loss = 0.0008777634357102215\t eps = 0.636\n","t = 27400\t loss = 0.0007685900200158358\t eps = 0.6347\n","t = 27500\t loss = 0.00042717577889561653\t eps = 0.6333\n","t = 27500\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 27600\t loss = 0.0008318604668602347\t eps = 0.632\n","t = 27700\t loss = 0.0006752192275598645\t eps = 0.6307\n","t = 27800\t loss = 0.0005460068350657821\t eps = 0.6293\n","t = 27900\t loss = 0.0005647070938721299\t eps = 0.628\n","t = 28000\t loss = 0.000565063557587564\t eps = 0.6267\n","t = 28000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 28100\t loss = 0.0017112868372350931\t eps = 0.6253\n","t = 28200\t loss = 0.0005683756317012012\t eps = 0.624\n","t = 28300\t loss = 0.0009354383801110089\t eps = 0.6227\n","t = 28400\t loss = 0.0004902941873297095\t eps = 0.6213\n","t = 28500\t loss = 0.0004969817819073796\t eps = 0.62\n","t = 28500\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 28600\t loss = 0.002044383203610778\t eps = 0.6187\n","t = 28700\t loss = 0.0010710896458476782\t eps = 0.6173\n","t = 28800\t loss = 0.0005895867943763733\t eps = 0.616\n","t = 28900\t loss = 0.0007428301032632589\t eps = 0.6147\n","t = 29000\t loss = 0.0009475821861997247\t eps = 0.6133\n","t = 29000\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 29100\t loss = 0.0028255886863917112\t eps = 0.612\n","t = 29200\t loss = 0.0006723692058585584\t eps = 0.6107\n","t = 29300\t loss = 0.0012585247168317437\t eps = 0.6093\n","t = 29400\t loss = 0.0006519548478536308\t eps = 0.608\n","t = 29500\t loss = 0.0043028234504163265\t eps = 0.6067\n","t = 29500\t reward = 0.9\t{'DQNAgent': 95, 'RandomPlus': 5}\n","\n","t = 29600\t loss = 0.0005361436633393168\t eps = 0.6053\n","t = 29700\t loss = 0.0013936306349933147\t eps = 0.604\n","t = 29800\t loss = 0.0005277595482766628\t eps = 0.6027\n","t = 29900\t loss = 0.0007598904194310308\t eps = 0.6013\n","t = 30000\t loss = 0.0006230341969057918\t eps = 0.6\n","t = 30000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 30100\t loss = 0.0004623686836566776\t eps = 0.5987\n","t = 30200\t loss = 0.0008263799827545881\t eps = 0.5973\n","t = 30300\t loss = 0.0008393828757107258\t eps = 0.596\n","t = 30400\t loss = 0.0004981648526154459\t eps = 0.5947\n","t = 30500\t loss = 0.0010614939965307713\t eps = 0.5933\n","t = 30500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 30600\t loss = 0.0009886125335469842\t eps = 0.592\n","t = 30700\t loss = 0.0004323907778598368\t eps = 0.5907\n","t = 30800\t loss = 0.00043076195288449526\t eps = 0.5893\n","t = 30900\t loss = 0.0004877820611000061\t eps = 0.588\n","t = 31000\t loss = 0.0007473115692846477\t eps = 0.5867\n","t = 31000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 31100\t loss = 0.0011593762319535017\t eps = 0.5853\n","t = 31200\t loss = 0.0004861029447056353\t eps = 0.584\n","t = 31300\t loss = 0.0006596511229872704\t eps = 0.5827\n","t = 31400\t loss = 0.001110580749809742\t eps = 0.5813\n","t = 31500\t loss = 0.0005658111185766757\t eps = 0.58\n","t = 31500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 31600\t loss = 0.0009737390209920704\t eps = 0.5787\n","t = 31700\t loss = 0.0004289912758395076\t eps = 0.5773\n","t = 31800\t loss = 0.0006403250736184418\t eps = 0.576\n","t = 31900\t loss = 0.00079377117799595\t eps = 0.5747\n","t = 32000\t loss = 0.0006348000606521964\t eps = 0.5733\n","t = 32000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 32100\t loss = 0.0006521278992295265\t eps = 0.572\n","t = 32200\t loss = 0.0006680036894977093\t eps = 0.5707\n","t = 32300\t loss = 0.0022481856867671013\t eps = 0.5693\n","t = 32400\t loss = 0.0009461309527978301\t eps = 0.568\n","t = 32500\t loss = 0.003318138886243105\t eps = 0.5667\n","t = 32500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 32600\t loss = 0.0011582286097109318\t eps = 0.5653\n","t = 32700\t loss = 0.0005255912546999753\t eps = 0.564\n","t = 32800\t loss = 0.0005892225308343768\t eps = 0.5627\n","t = 32900\t loss = 0.0005685137002728879\t eps = 0.5613\n","t = 33000\t loss = 0.0015558605082333088\t eps = 0.56\n","t = 33000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 33100\t loss = 0.0007580628735013306\t eps = 0.5587\n","t = 33200\t loss = 0.0003988226526416838\t eps = 0.5573\n","t = 33300\t loss = 0.0007157219224609435\t eps = 0.556\n","t = 33400\t loss = 0.0007311605731956661\t eps = 0.5547\n","t = 33500\t loss = 0.0006542594055645168\t eps = 0.5533\n","t = 33500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 33600\t loss = 0.0005220704479143023\t eps = 0.552\n","t = 33700\t loss = 0.0035634979140013456\t eps = 0.5507\n","t = 33800\t loss = 0.000542488123755902\t eps = 0.5493\n","t = 33900\t loss = 0.0005349327111616731\t eps = 0.548\n","t = 34000\t loss = 0.0009160604095086455\t eps = 0.5467\n","t = 34000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 34100\t loss = 0.0009317852091044188\t eps = 0.5453\n","t = 34200\t loss = 0.0006799756083637476\t eps = 0.544\n","t = 34300\t loss = 0.0005143433227203786\t eps = 0.5427\n","t = 34400\t loss = 0.0004604591813404113\t eps = 0.5413\n","t = 34500\t loss = 0.0007364365155808628\t eps = 0.54\n","t = 34500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 34600\t loss = 0.0008644949411973357\t eps = 0.5387\n","t = 34700\t loss = 0.0005498374230228364\t eps = 0.5373\n","t = 34800\t loss = 0.0005018872325308621\t eps = 0.536\n","t = 34900\t loss = 0.0008554015657864511\t eps = 0.5347\n","t = 35000\t loss = 0.0007801329484209418\t eps = 0.5333\n","t = 35000\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 35100\t loss = 0.0004581747343763709\t eps = 0.532\n","t = 35200\t loss = 0.0005630217492580414\t eps = 0.5307\n","t = 35300\t loss = 0.0009055208647623658\t eps = 0.5293\n","t = 35400\t loss = 0.0009574010036885738\t eps = 0.528\n","t = 35500\t loss = 0.0006820489652454853\t eps = 0.5267\n","t = 35500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 35600\t loss = 0.00035323738120496273\t eps = 0.5253\n","t = 35700\t loss = 0.0005631974199786782\t eps = 0.524\n","t = 35800\t loss = 0.00154215341899544\t eps = 0.5227\n","t = 35900\t loss = 0.0009151817648671567\t eps = 0.5213\n","t = 36000\t loss = 0.0006576939485967159\t eps = 0.52\n","t = 36000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 36100\t loss = 0.0005693105631507933\t eps = 0.5187\n","t = 36200\t loss = 0.0007420129841193557\t eps = 0.5173\n","t = 36300\t loss = 0.0006818192196078598\t eps = 0.516\n","t = 36400\t loss = 0.001287223189137876\t eps = 0.5147\n","t = 36500\t loss = 0.0003636812325567007\t eps = 0.5133\n","t = 36500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 36600\t loss = 0.00040083806379698217\t eps = 0.512\n","t = 36700\t loss = 0.00047300889855250716\t eps = 0.5107\n","t = 36800\t loss = 0.0004155258066020906\t eps = 0.5093\n","t = 36900\t loss = 0.0015019256388768554\t eps = 0.508\n","t = 37000\t loss = 0.0009743322152644396\t eps = 0.5067\n","t = 37000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 37100\t loss = 0.001577344723045826\t eps = 0.5053\n","t = 37200\t loss = 0.000430642714491114\t eps = 0.504\n","t = 37300\t loss = 0.0004405082727316767\t eps = 0.5027\n","t = 37400\t loss = 0.0008230644161812961\t eps = 0.5013\n","t = 37500\t loss = 0.000633779913187027\t eps = 0.5\n","t = 37500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 37600\t loss = 0.0008059691172093153\t eps = 0.4987\n","t = 37700\t loss = 0.0005196737474761903\t eps = 0.4973\n","t = 37800\t loss = 0.0005928244790993631\t eps = 0.496\n","t = 37900\t loss = 0.0005406575510278344\t eps = 0.4947\n","t = 38000\t loss = 0.001036510686390102\t eps = 0.4933\n","t = 38000\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 38100\t loss = 0.0006463913596235216\t eps = 0.492\n","t = 38200\t loss = 0.00038535744533874094\t eps = 0.4907\n","t = 38300\t loss = 0.0014780019409954548\t eps = 0.4893\n","t = 38400\t loss = 0.0008652684045955539\t eps = 0.488\n","t = 38500\t loss = 0.0006348802126012743\t eps = 0.4867\n","t = 38500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 38600\t loss = 0.0007686549797654152\t eps = 0.4853\n","t = 38700\t loss = 0.000768209109082818\t eps = 0.484\n","t = 38800\t loss = 0.0010337966959923506\t eps = 0.4827\n","t = 38900\t loss = 0.0009679273352958262\t eps = 0.4813\n","t = 39000\t loss = 0.0006236026529222727\t eps = 0.48\n","t = 39000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 39100\t loss = 0.0013964612735435367\t eps = 0.4787\n","t = 39200\t loss = 0.0005203740438446403\t eps = 0.4773\n","t = 39300\t loss = 0.0005095447413623333\t eps = 0.476\n","t = 39400\t loss = 0.0012858777772635221\t eps = 0.4747\n","t = 39500\t loss = 0.001496660290285945\t eps = 0.4733\n","t = 39500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 39600\t loss = 0.0008039792301133275\t eps = 0.472\n","t = 39700\t loss = 0.0005557115655392408\t eps = 0.4707\n","t = 39800\t loss = 0.0013183425180613995\t eps = 0.4693\n","t = 39900\t loss = 0.0009184962837025523\t eps = 0.468\n","t = 40000\t loss = 0.0012043132446706295\t eps = 0.4667\n","t = 40000\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 40100\t loss = 0.0010269933845847845\t eps = 0.4653\n","t = 40200\t loss = 0.002008709590882063\t eps = 0.464\n","t = 40300\t loss = 0.0008768781553953886\t eps = 0.4627\n","t = 40400\t loss = 0.0007141093956306577\t eps = 0.4613\n","t = 40500\t loss = 0.00026473027537576854\t eps = 0.46\n","t = 40500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 40600\t loss = 0.002376380143687129\t eps = 0.4587\n","t = 40700\t loss = 0.0007848876994103193\t eps = 0.4573\n","t = 40800\t loss = 0.0009760739631019533\t eps = 0.456\n","t = 40900\t loss = 0.0005578564596362412\t eps = 0.4547\n","t = 41000\t loss = 0.000680034514516592\t eps = 0.4533\n","t = 41000\t reward = 0.95\t{'DQNAgent': 97, 'RandomPlus': 2}\n","\n","t = 41100\t loss = 0.0009438608540222049\t eps = 0.452\n","t = 41200\t loss = 0.0007842465420253575\t eps = 0.4507\n","t = 41300\t loss = 0.000682564452290535\t eps = 0.4493\n","t = 41400\t loss = 0.0006014257669448853\t eps = 0.448\n","t = 41500\t loss = 0.0005118956323713064\t eps = 0.4467\n","t = 41500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 41600\t loss = 0.000761795905418694\t eps = 0.4453\n","t = 41700\t loss = 0.0005963648436591029\t eps = 0.444\n","t = 41800\t loss = 0.006740642245858908\t eps = 0.4427\n","t = 41900\t loss = 0.0007064682431519032\t eps = 0.4413\n","t = 42000\t loss = 0.0006844752933830023\t eps = 0.44\n","t = 42000\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 42100\t loss = 0.0015775859355926514\t eps = 0.4387\n","t = 42200\t loss = 0.0004000964981969446\t eps = 0.4373\n","t = 42300\t loss = 0.00035181414568796754\t eps = 0.436\n","t = 42400\t loss = 0.0009706893470138311\t eps = 0.4347\n","t = 42500\t loss = 0.00048487528692930937\t eps = 0.4333\n","t = 42500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 42600\t loss = 0.00042869430035352707\t eps = 0.432\n","t = 42700\t loss = 0.0003941153408959508\t eps = 0.4307\n","t = 42800\t loss = 0.0003598044568207115\t eps = 0.4293\n","t = 42900\t loss = 0.0005095069645904005\t eps = 0.428\n","t = 43000\t loss = 0.0013510973658412695\t eps = 0.4267\n","t = 43000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 43100\t loss = 0.0004395988362375647\t eps = 0.4253\n","t = 43200\t loss = 0.0006952692056074739\t eps = 0.424\n","t = 43300\t loss = 0.0009408042533323169\t eps = 0.4227\n","t = 43400\t loss = 0.0009058366413228214\t eps = 0.4213\n","t = 43500\t loss = 0.000352784845745191\t eps = 0.42\n","t = 43500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 43600\t loss = 0.00032413264852948487\t eps = 0.4187\n","t = 43700\t loss = 0.0002802078961394727\t eps = 0.4173\n","t = 43800\t loss = 0.0006239316426217556\t eps = 0.416\n","t = 43900\t loss = 0.0005837853532284498\t eps = 0.4147\n","t = 44000\t loss = 0.0003023954341188073\t eps = 0.4133\n","t = 44000\t reward = 0.94\t{'DQNAgent': 97, 'RandomPlus': 3}\n","\n","t = 44100\t loss = 0.0007371396059170365\t eps = 0.412\n","t = 44200\t loss = 0.0008511788910254836\t eps = 0.4107\n","t = 44300\t loss = 0.00028389424551278353\t eps = 0.4093\n","t = 44400\t loss = 0.0006654728204011917\t eps = 0.408\n","t = 44500\t loss = 0.0009529703529551625\t eps = 0.4067\n","t = 44500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 44600\t loss = 0.0008020775276236236\t eps = 0.4053\n","t = 44700\t loss = 0.0004328641516622156\t eps = 0.404\n","t = 44800\t loss = 0.0015259315259754658\t eps = 0.4027\n","t = 44900\t loss = 0.0003725384594872594\t eps = 0.4013\n","t = 45000\t loss = 0.00041645654710009694\t eps = 0.4\n","t = 45000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 45100\t loss = 0.0013773171231150627\t eps = 0.3987\n","t = 45200\t loss = 0.0006903012399561703\t eps = 0.3973\n","t = 45300\t loss = 0.0010734791867434978\t eps = 0.396\n","t = 45400\t loss = 0.0006003751186653972\t eps = 0.3947\n","t = 45500\t loss = 0.0006975631695240736\t eps = 0.3933\n","t = 45500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ubXJqK9PByp"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_45500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_45500'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"f-HOVRiDPY2p","outputId":"b1a448b6-4e71-4802-acfa-64c26e2be871"},"outputs":[{"name":"stdout","output_type":"stream","text":["t = 45600\t loss = None\t eps = 0.392\n","t = 45700\t loss = 0.0007163088885135949\t eps = 0.3907\n","t = 45800\t loss = 0.0023001134395599365\t eps = 0.3893\n","t = 45900\t loss = 0.003419699613004923\t eps = 0.388\n","t = 46000\t loss = 0.0007219476974569261\t eps = 0.3867\n","t = 46000\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 46100\t loss = 0.000741938129067421\t eps = 0.3853\n","t = 46200\t loss = 0.00024738075444474816\t eps = 0.384\n","t = 46300\t loss = 0.0008657713187858462\t eps = 0.3827\n","t = 46400\t loss = 0.00047062651719897985\t eps = 0.3813\n","t = 46500\t loss = 0.0006787946331314743\t eps = 0.38\n","t = 46500\t reward = 0.66\t{'DQNAgent': 82, 'RandomPlus': 16}\n","\n","t = 46600\t loss = 0.0011206482304260135\t eps = 0.3787\n","t = 46700\t loss = 0.0007954401080496609\t eps = 0.3773\n","t = 46800\t loss = 0.0005883672856725752\t eps = 0.376\n","t = 46900\t loss = 0.0005571823567152023\t eps = 0.3747\n","t = 47000\t loss = 0.0006007581250742078\t eps = 0.3733\n","t = 47000\t reward = 0.49\t{'DQNAgent': 73, 'RandomPlus': 24}\n","\n","t = 47100\t loss = 0.0010953887831419706\t eps = 0.372\n","t = 47200\t loss = 0.0004188256280031055\t eps = 0.3707\n","t = 47300\t loss = 0.0013869302347302437\t eps = 0.3693\n","t = 47400\t loss = 0.0007887555984780192\t eps = 0.368\n","t = 47500\t loss = 0.0003760259132832289\t eps = 0.3667\n","t = 47500\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 47600\t loss = 0.0004479752969928086\t eps = 0.3653\n","t = 47700\t loss = 0.00060667609795928\t eps = 0.364\n","t = 47800\t loss = 0.000787934404797852\t eps = 0.3627\n","t = 47900\t loss = 0.0007376117864623666\t eps = 0.3613\n","t = 48000\t loss = 0.0003813534858636558\t eps = 0.36\n","t = 48000\t reward = 0.7\t{'DQNAgent': 83, 'RandomPlus': 13}\n","\n","t = 48100\t loss = 0.0006113929557614028\t eps = 0.3587\n","t = 48200\t loss = 0.0007478022016584873\t eps = 0.3573\n","t = 48300\t loss = 0.0009818215621635318\t eps = 0.356\n","t = 48400\t loss = 0.001263199606910348\t eps = 0.3547\n","t = 48500\t loss = 0.001025807112455368\t eps = 0.3533\n","t = 48500\t reward = 0.58\t{'DQNAgent': 77, 'RandomPlus': 19}\n","\n","t = 48600\t loss = 0.0008745224913582206\t eps = 0.352\n","t = 48700\t loss = 0.0009745372226461768\t eps = 0.3507\n","t = 48800\t loss = 0.0016923423390835524\t eps = 0.3493\n","t = 48900\t loss = 0.0017528346506878734\t eps = 0.348\n","t = 49000\t loss = 0.0012473769020289183\t eps = 0.3467\n","t = 49000\t reward = 0.74\t{'DQNAgent': 85, 'RandomPlus': 11}\n","\n","t = 49100\t loss = 0.0004658202815335244\t eps = 0.3453\n","t = 49200\t loss = 0.0007075761677697301\t eps = 0.344\n","t = 49300\t loss = 0.0028505732771009207\t eps = 0.3427\n","t = 49400\t loss = 0.0004480673815123737\t eps = 0.3413\n","t = 49500\t loss = 0.001169462688267231\t eps = 0.34\n","t = 49500\t reward = 0.76\t{'DQNAgent': 88, 'RandomPlus': 12}\n","\n","t = 49600\t loss = 0.0007316527189686894\t eps = 0.3387\n","t = 49700\t loss = 0.0008588058408349752\t eps = 0.3373\n","t = 49800\t loss = 0.0007576702046208084\t eps = 0.336\n","t = 49900\t loss = 0.0006230191793292761\t eps = 0.3347\n","t = 50000\t loss = 0.0005860177334398031\t eps = 0.3333\n","t = 50000\t reward = 0.53\t{'DQNAgent': 74, 'RandomPlus': 21}\n","\n","t = 50100\t loss = 0.0006523578194901347\t eps = 0.332\n","t = 50200\t loss = 0.00046255759662017226\t eps = 0.3307\n","t = 50300\t loss = 0.000524123024661094\t eps = 0.3293\n","t = 50400\t loss = 0.0007728263735771179\t eps = 0.328\n","t = 50500\t loss = 0.0005292805726639926\t eps = 0.3267\n","t = 50500\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 50600\t loss = 0.0005256802542135119\t eps = 0.3253\n","t = 50700\t loss = 0.0008045394206419587\t eps = 0.324\n","t = 50800\t loss = 0.0007048445986583829\t eps = 0.3227\n","t = 50900\t loss = 0.0006091539980843663\t eps = 0.3213\n","t = 51000\t loss = 0.0011049704626202583\t eps = 0.32\n","t = 51000\t reward = 0.52\t{'DQNAgent': 74, 'RandomPlus': 22}\n","\n","t = 51100\t loss = 0.0009844375308603048\t eps = 0.3187\n","t = 51200\t loss = 0.0007630534237250686\t eps = 0.3173\n","t = 51300\t loss = 0.0008894248167052865\t eps = 0.316\n","t = 51400\t loss = 0.0006965462816879153\t eps = 0.3147\n","t = 51500\t loss = 0.0009149328689090908\t eps = 0.3133\n","t = 51500\t reward = 0.65\t{'DQNAgent': 81, 'RandomPlus': 16}\n","\n","t = 51600\t loss = 0.000843987800180912\t eps = 0.312\n","t = 51700\t loss = 0.000836490246001631\t eps = 0.3107\n","t = 51800\t loss = 0.0007380658644251525\t eps = 0.3093\n","t = 51900\t loss = 0.0029823416844010353\t eps = 0.308\n","t = 52000\t loss = 0.0012444842141121626\t eps = 0.3067\n","t = 52000\t reward = 0.44\t{'DQNAgent': 71, 'RandomPlus': 27}\n","\n","t = 52100\t loss = 0.0009768449235707521\t eps = 0.3053\n","t = 52200\t loss = 0.000866709859110415\t eps = 0.304\n","t = 52300\t loss = 0.0006681532831862569\t eps = 0.3027\n","t = 52400\t loss = 0.0014945846050977707\t eps = 0.3013\n","t = 52500\t loss = 0.00047555481432937086\t eps = 0.3\n","t = 52500\t reward = 0.6\t{'DQNAgent': 79, 'RandomPlus': 19}\n","\n","t = 52600\t loss = 0.0007501242216676474\t eps = 0.2987\n","t = 52700\t loss = 0.0007793931290507317\t eps = 0.2973\n","t = 52800\t loss = 0.000515214167535305\t eps = 0.296\n","t = 52900\t loss = 0.0004900597268715501\t eps = 0.2947\n","t = 53000\t loss = 0.0005512867937795818\t eps = 0.2933\n","t = 53000\t reward = 0.61\t{'DQNAgent': 78, 'RandomPlus': 17}\n","\n","t = 53100\t loss = 0.001697939122095704\t eps = 0.292\n","t = 53200\t loss = 0.0024496987462043762\t eps = 0.2907\n","t = 53300\t loss = 0.0003001089789904654\t eps = 0.2893\n","t = 53400\t loss = 0.0011086869053542614\t eps = 0.288\n","t = 53500\t loss = 0.0010404048953205347\t eps = 0.2867\n","t = 53500\t reward = 0.76\t{'DQNAgent': 86, 'RandomPlus': 10}\n","\n","t = 53600\t loss = 0.002910437062382698\t eps = 0.2853\n","t = 53700\t loss = 0.0009236999321728945\t eps = 0.284\n","t = 53800\t loss = 0.0009688491118140519\t eps = 0.2827\n","t = 53900\t loss = 0.0004468499100767076\t eps = 0.2813\n","t = 54000\t loss = 0.0020063957199454308\t eps = 0.28\n","t = 54000\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 54100\t loss = 0.001094633131287992\t eps = 0.2787\n","t = 54200\t loss = 0.0012519585434347391\t eps = 0.2773\n","t = 54300\t loss = 0.0004414831637404859\t eps = 0.276\n","t = 54400\t loss = 0.0011074102949351072\t eps = 0.2747\n","t = 54500\t loss = 0.00047213435755111277\t eps = 0.2733\n","t = 54500\t reward = 0.71\t{'DQNAgent': 85, 'RandomPlus': 14}\n","\n","t = 54600\t loss = 0.0008760591736063361\t eps = 0.272\n","t = 54700\t loss = 0.0009628495899960399\t eps = 0.2707\n","t = 54800\t loss = 0.001091742655262351\t eps = 0.2693\n","t = 54900\t loss = 0.0005367188132368028\t eps = 0.268\n","t = 55000\t loss = 0.0005779375205747783\t eps = 0.2667\n","t = 55000\t reward = 0.76\t{'DQNAgent': 88, 'RandomPlus': 12}\n","\n","t = 55100\t loss = 0.0005826543783769011\t eps = 0.2653\n","t = 55200\t loss = 0.0011912421323359013\t eps = 0.264\n","t = 55300\t loss = 0.0003791248600464314\t eps = 0.2627\n","t = 55400\t loss = 0.0006338111124932766\t eps = 0.2613\n","t = 55500\t loss = 0.0012489974033087492\t eps = 0.26\n","t = 55500\t reward = 0.66\t{'DQNAgent': 81, 'RandomPlus': 15}\n","\n","t = 55600\t loss = 0.0007484953966923058\t eps = 0.2587\n","t = 55700\t loss = 0.0004164205165579915\t eps = 0.2573\n","t = 55800\t loss = 0.0029985930304974318\t eps = 0.256\n","t = 55900\t loss = 0.0005463241832330823\t eps = 0.2547\n","t = 56000\t loss = 0.0006023473106324673\t eps = 0.2533\n","t = 56000\t reward = 0.63\t{'DQNAgent': 80, 'RandomPlus': 17}\n","\n","t = 56100\t loss = 0.004343782085925341\t eps = 0.252\n","t = 56200\t loss = 0.0006095364806242287\t eps = 0.2507\n","t = 56300\t loss = 0.0004557364445645362\t eps = 0.2493\n","t = 56400\t loss = 0.0004177694208920002\t eps = 0.248\n","t = 56500\t loss = 0.0012651658616960049\t eps = 0.2467\n","t = 56500\t reward = 0.61\t{'DQNAgent': 78, 'RandomPlus': 17}\n","\n","t = 56600\t loss = 0.000730977684725076\t eps = 0.2453\n","t = 56700\t loss = 0.0006582806818187237\t eps = 0.244\n","t = 56800\t loss = 0.000621988030616194\t eps = 0.2427\n","t = 56900\t loss = 0.0005149543285369873\t eps = 0.2413\n","t = 57000\t loss = 0.000560110667720437\t eps = 0.24\n","t = 57000\t reward = 0.55\t{'DQNAgent': 76, 'RandomPlus': 21}\n","\n","t = 57100\t loss = 0.0009833795484155416\t eps = 0.2387\n","t = 57200\t loss = 0.0007419973844662309\t eps = 0.2373\n","t = 57300\t loss = 0.0010403376072645187\t eps = 0.236\n","t = 57400\t loss = 0.0007130518206395209\t eps = 0.2347\n","t = 57500\t loss = 0.0007239949190989137\t eps = 0.2333\n","t = 57500\t reward = 0.47\t{'DQNAgent': 73, 'RandomPlus': 26}\n","\n","t = 57600\t loss = 0.0007078847265802324\t eps = 0.232\n","t = 57700\t loss = 0.001006328733637929\t eps = 0.2307\n","t = 57800\t loss = 0.0004909394774585962\t eps = 0.2293\n","t = 57900\t loss = 0.0009830790804699063\t eps = 0.228\n","t = 58000\t loss = 0.00034849485382437706\t eps = 0.2267\n","t = 58000\t reward = 0.63\t{'DQNAgent': 79, 'RandomPlus': 16}\n","\n","t = 58100\t loss = 0.002091147704049945\t eps = 0.2253\n","t = 58200\t loss = 0.0013932071160525084\t eps = 0.224\n","t = 58300\t loss = 0.0023655532859265804\t eps = 0.2227\n","t = 58400\t loss = 0.0006318450905382633\t eps = 0.2213\n","t = 58500\t loss = 0.0009984426433220506\t eps = 0.22\n","t = 58500\t reward = 0.64\t{'DQNAgent': 80, 'RandomPlus': 16}\n","\n","t = 58600\t loss = 0.0013335013063624501\t eps = 0.2187\n","t = 58700\t loss = 0.001047070836648345\t eps = 0.2173\n","t = 58800\t loss = 0.0007181400433182716\t eps = 0.216\n","t = 58900\t loss = 0.001449058298021555\t eps = 0.2147\n","t = 59000\t loss = 0.0004598498926497996\t eps = 0.2133\n","t = 59000\t reward = 0.55\t{'DQNAgent': 76, 'RandomPlus': 21}\n","\n","t = 59100\t loss = 0.0025058321189135313\t eps = 0.212\n","t = 59200\t loss = 0.001214200397953391\t eps = 0.2107\n","t = 59300\t loss = 0.0011439579539000988\t eps = 0.2093\n","t = 59400\t loss = 0.0003657708002720028\t eps = 0.208\n","t = 59500\t loss = 0.0037148918490856886\t eps = 0.2067\n","t = 59500\t reward = 0.62\t{'DQNAgent': 80, 'RandomPlus': 18}\n","\n","t = 59600\t loss = 0.0005822594393976033\t eps = 0.2053\n","t = 59700\t loss = 0.001935007981956005\t eps = 0.204\n","t = 59800\t loss = 0.0017253635451197624\t eps = 0.2027\n","t = 59900\t loss = 0.0012835559900850058\t eps = 0.2013\n","t = 60000\t loss = 0.0004692076472565532\t eps = 0.2\n","t = 60000\t reward = 0.73\t{'DQNAgent': 86, 'RandomPlus': 13}\n","\n","t = 60100\t loss = 0.0005411704769358039\t eps = 0.2\n","t = 60200\t loss = 0.0005253782728686929\t eps = 0.2\n","t = 60300\t loss = 0.0011321364436298609\t eps = 0.2\n","t = 60400\t loss = 0.0005569910863414407\t eps = 0.2\n","t = 60500\t loss = 0.0004621169646270573\t eps = 0.2\n","t = 60500\t reward = 0.76\t{'DQNAgent': 85, 'RandomPlus': 9}\n","\n","t = 60600\t loss = 0.000774881336838007\t eps = 0.2\n","t = 60700\t loss = 0.0009052850073203444\t eps = 0.2\n","t = 60800\t loss = 0.0023630475625395775\t eps = 0.2\n","t = 60900\t loss = 0.0005410655285231769\t eps = 0.2\n","t = 61000\t loss = 0.0004762723110616207\t eps = 0.2\n","t = 61000\t reward = 0.65\t{'DQNAgent': 81, 'RandomPlus': 16}\n","\n","t = 61100\t loss = 0.0006963838823139668\t eps = 0.2\n","t = 61200\t loss = 0.0005017894436605275\t eps = 0.2\n","t = 61300\t loss = 0.0012945255730301142\t eps = 0.2\n","t = 61400\t loss = 0.0007227392634376884\t eps = 0.2\n","t = 61500\t loss = 0.0008022130932658911\t eps = 0.2\n","t = 61500\t reward = 0.72\t{'DQNAgent': 84, 'RandomPlus': 12}\n","\n","t = 61600\t loss = 0.0011835760669782758\t eps = 0.2\n","t = 61700\t loss = 0.0009965873323380947\t eps = 0.2\n","t = 61800\t loss = 0.0007130348822101951\t eps = 0.2\n","t = 61900\t loss = 0.000599766499362886\t eps = 0.2\n","t = 62000\t loss = 0.0005465014255605638\t eps = 0.2\n","t = 62000\t reward = 0.49\t{'DQNAgent': 73, 'RandomPlus': 24}\n","\n"]}],"source":["# ========== ОЦЕНКА КАЧЕСТВА НА НОВОМ БОТЕ ==========\n","\n","\n","with open('out.txt', 'w') as f:\n","  for t in range(45_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjIXIwwz1gBE"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_49000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_49000'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":827},"executionInfo":{"elapsed":398423,"status":"error","timestamp":1718709650369,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"f9xsc1Rh1mNs","outputId":"eda51195-d554-4dcb-ec98-935bbc1780d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["t = 49100\t loss = None\t eps = 0.3862\n","t = 49200\t loss = 0.0006231703446246684\t eps = 0.385\n","t = 49300\t loss = 0.0008477765950374305\t eps = 0.3838\n","t = 49400\t loss = 0.00030077152769081295\t eps = 0.3825\n","t = 49500\t loss = 0.0006357431411743164\t eps = 0.3812\n","t = 49500\t reward = 0.7\t{'DQNAgent': 82, 'RandomPlus': 12}\n","\n","t = 49600\t loss = 0.0006129497196525335\t eps = 0.38\n","t = 49700\t loss = 0.0012368080206215382\t eps = 0.3788\n","t = 49800\t loss = 0.0006861520814709365\t eps = 0.3775\n","t = 49900\t loss = 0.0003389932098798454\t eps = 0.3762\n","t = 50000\t loss = 0.0006419041892513633\t eps = 0.375\n","t = 50000\t reward = 0.72\t{'DQNAgent': 86, 'RandomPlus': 14}\n","\n","t = 50100\t loss = 0.0004673107177950442\t eps = 0.3738\n","t = 50200\t loss = 0.00036452687345445156\t eps = 0.3725\n","t = 50300\t loss = 0.0010725996689870954\t eps = 0.3712\n","t = 50400\t loss = 0.0014924638671800494\t eps = 0.37\n","t = 50500\t loss = 0.0010145039996132255\t eps = 0.3688\n","t = 50500\t reward = 0.57\t{'DQNAgent': 76, 'RandomPlus': 19}\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e1e79ad47b38>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ========== CONTINUE ==========\n","\n","\n","with open('out.txt', 'w') as f:\n","  for t in range(49_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NJycChX0FC2i","outputId":"a1c8e5d7-ae69-4b28-9913-bf1d8c73563f"},"outputs":[{"name":"stdout","output_type":"stream","text":["t = 50600\t loss = 0.0005726382369175553\t eps = 0.3675\n","t = 50700\t loss = 0.0007521308725699782\t eps = 0.3662\n","t = 50800\t loss = 0.00040385156171396375\t eps = 0.365\n","t = 50900\t loss = 0.0011169458739459515\t eps = 0.3638\n","t = 51000\t loss = 0.0002975226962007582\t eps = 0.3625\n","t = 51000\t reward = 0.51\t{'DQNAgent': 75, 'RandomPlus': 24}\n","\n","t = 51100\t loss = 0.0004504479584284127\t eps = 0.3612\n","t = 51200\t loss = 0.0026520220562815666\t eps = 0.36\n","t = 51300\t loss = 0.00029461923986673355\t eps = 0.3588\n","t = 51400\t loss = 0.0013692324282601476\t eps = 0.3575\n","t = 51500\t loss = 0.00035188253968954086\t eps = 0.3562\n","t = 51500\t reward = 0.64\t{'DQNAgent': 81, 'RandomPlus': 17}\n","\n","t = 51600\t loss = 0.0012226385297253728\t eps = 0.355\n","t = 51700\t loss = 0.00028253940399736166\t eps = 0.3538\n","t = 51800\t loss = 0.000478589441627264\t eps = 0.3525\n","t = 51900\t loss = 0.0004016034654341638\t eps = 0.3512\n","t = 52000\t loss = 0.0006413225783035159\t eps = 0.35\n","t = 52000\t reward = 0.77\t{'DQNAgent': 87, 'RandomPlus': 10}\n","\n","t = 52100\t loss = 0.0007230117917060852\t eps = 0.3488\n","t = 52200\t loss = 0.0010380612220615149\t eps = 0.3475\n","t = 52300\t loss = 0.0005435292841866612\t eps = 0.3462\n","t = 52400\t loss = 0.0020438823848962784\t eps = 0.345\n","t = 52500\t loss = 0.0006707952707074583\t eps = 0.3438\n","t = 52500\t reward = 0.63\t{'DQNAgent': 80, 'RandomPlus': 17}\n","\n","t = 52600\t loss = 0.0004258406988810748\t eps = 0.3425\n","t = 52700\t loss = 0.0004874207661487162\t eps = 0.3413\n","t = 52800\t loss = 0.0018241764046251774\t eps = 0.34\n","t = 52900\t loss = 0.0010269456543028355\t eps = 0.3387\n","t = 53000\t loss = 0.000697875686455518\t eps = 0.3375\n","t = 53000\t reward = 0.53\t{'DQNAgent': 76, 'RandomPlus': 23}\n","\n","t = 53100\t loss = 0.001001495635136962\t eps = 0.3363\n","t = 53200\t loss = 0.0007796059362590313\t eps = 0.335\n","t = 53300\t loss = 0.0005627585342153907\t eps = 0.3337\n","t = 53400\t loss = 0.0008402802632190287\t eps = 0.3325\n","t = 53500\t loss = 0.0004675039672292769\t eps = 0.3313\n","t = 53500\t reward = 0.65\t{'DQNAgent': 82, 'RandomPlus': 17}\n","\n","t = 53600\t loss = 0.0003479365259408951\t eps = 0.33\n","t = 53700\t loss = 0.0010700386483222246\t eps = 0.3287\n","t = 53800\t loss = 0.0006971529219299555\t eps = 0.3275\n","t = 53900\t loss = 0.0035209376364946365\t eps = 0.3263\n","t = 54000\t loss = 0.0004226066230330616\t eps = 0.325\n","t = 54000\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 54100\t loss = 0.0009036020492203534\t eps = 0.3237\n","t = 54200\t loss = 0.0014395271427929401\t eps = 0.3225\n","t = 54300\t loss = 0.0005061008268967271\t eps = 0.3213\n","t = 54400\t loss = 0.0006400051061064005\t eps = 0.32\n","t = 54500\t loss = 0.000530619639903307\t eps = 0.3187\n","t = 54500\t reward = 0.52\t{'DQNAgent': 74, 'RandomPlus': 22}\n","\n","t = 54600\t loss = 0.000414766080211848\t eps = 0.3175\n","t = 54700\t loss = 0.0025714708026498556\t eps = 0.3163\n","t = 54800\t loss = 0.0004877090686932206\t eps = 0.315\n","t = 54900\t loss = 0.0014093734789639711\t eps = 0.3137\n","t = 55000\t loss = 0.000525233568623662\t eps = 0.3125\n","t = 55000\t reward = 0.56\t{'DQNAgent': 77, 'RandomPlus': 21}\n","\n","t = 55100\t loss = 0.0005547805922105908\t eps = 0.3113\n","t = 55200\t loss = 0.00040657760109752417\t eps = 0.31\n","t = 55300\t loss = 0.0017478156369179487\t eps = 0.3087\n","t = 55400\t loss = 0.0005334331654012203\t eps = 0.3075\n","t = 55500\t loss = 0.004884605295956135\t eps = 0.3063\n","t = 55500\t reward = 0.68\t{'DQNAgent': 81, 'RandomPlus': 13}\n","\n","t = 55600\t loss = 0.0017121110577136278\t eps = 0.305\n","t = 55700\t loss = 0.0003654328756965697\t eps = 0.3037\n","t = 55800\t loss = 0.0006690136506222188\t eps = 0.3025\n","t = 55900\t loss = 0.0020387968979775906\t eps = 0.3013\n","t = 56000\t loss = 0.0012069159420207143\t eps = 0.3\n","t = 56000\t reward = 0.62\t{'DQNAgent': 78, 'RandomPlus': 16}\n","\n","t = 56100\t loss = 0.0004595759091898799\t eps = 0.2987\n","t = 56200\t loss = 0.0008231822866946459\t eps = 0.2975\n","t = 56300\t loss = 0.0006514946580864489\t eps = 0.2963\n","t = 56400\t loss = 0.0021764696575701237\t eps = 0.295\n","t = 56500\t loss = 0.0014106405433267355\t eps = 0.2937\n","t = 56500\t reward = 0.44\t{'DQNAgent': 71, 'RandomPlus': 27}\n","\n","t = 56600\t loss = 0.0005716573796235025\t eps = 0.2925\n","t = 56700\t loss = 0.001490413909777999\t eps = 0.2913\n","t = 56800\t loss = 0.00038944787229411304\t eps = 0.29\n","t = 56900\t loss = 0.0010427589295431972\t eps = 0.2887\n","t = 57000\t loss = 0.0003517020377330482\t eps = 0.2875\n","t = 57000\t reward = 0.51\t{'DQNAgent': 75, 'RandomPlus': 24}\n","\n","t = 57100\t loss = 0.00030590855749323964\t eps = 0.2863\n","t = 57200\t loss = 0.0006072806427255273\t eps = 0.285\n","t = 57300\t loss = 0.001712365890853107\t eps = 0.2837\n","t = 57400\t loss = 0.0011709267273545265\t eps = 0.2825\n","t = 57500\t loss = 0.0005379350623115897\t eps = 0.2812\n","t = 57500\t reward = 0.49\t{'DQNAgent': 73, 'RandomPlus': 24}\n","\n","t = 57600\t loss = 0.0005292993737384677\t eps = 0.28\n","t = 57700\t loss = 0.00044976911158300936\t eps = 0.2788\n","t = 57800\t loss = 0.003901661606505513\t eps = 0.2775\n","t = 57900\t loss = 0.0013566480483859777\t eps = 0.2762\n","t = 58000\t loss = 0.0009302326361648738\t eps = 0.275\n","t = 58000\t reward = 0.42\t{'DQNAgent': 70, 'RandomPlus': 28}\n","\n","t = 58100\t loss = 0.0006557677406817675\t eps = 0.2738\n","t = 58200\t loss = 0.00047557184007018805\t eps = 0.2725\n","t = 58300\t loss = 0.000528064847458154\t eps = 0.2712\n","t = 58400\t loss = 0.0004925208631902933\t eps = 0.27\n","t = 58500\t loss = 0.0034744516015052795\t eps = 0.2688\n","t = 58500\t reward = 0.61\t{'DQNAgent': 79, 'RandomPlus': 18}\n","\n","t = 58600\t loss = 0.0005661671748384833\t eps = 0.2675\n","t = 58700\t loss = 0.0006354297511279583\t eps = 0.2662\n","t = 58800\t loss = 0.0009212513687089086\t eps = 0.265\n","t = 58900\t loss = 0.0005938659887760878\t eps = 0.2638\n","t = 59000\t loss = 0.0035033298190683126\t eps = 0.2625\n","t = 59000\t reward = 0.55\t{'DQNAgent': 75, 'RandomPlus': 20}\n","\n","t = 59100\t loss = 0.0006703384569846094\t eps = 0.2612\n","t = 59200\t loss = 0.0004719001008197665\t eps = 0.26\n","t = 59300\t loss = 0.0006406250176951289\t eps = 0.2588\n","t = 59400\t loss = 0.0006672412855550647\t eps = 0.2575\n","t = 59500\t loss = 0.0005371166625991464\t eps = 0.2562\n","t = 59500\t reward = 0.79\t{'DQNAgent': 89, 'RandomPlus': 10}\n","\n","t = 59600\t loss = 0.0012972017284482718\t eps = 0.255\n","t = 59700\t loss = 0.0006659593782387674\t eps = 0.2538\n","t = 59800\t loss = 0.0008666552021168172\t eps = 0.2525\n","t = 59900\t loss = 0.000410516164265573\t eps = 0.2512\n","t = 60000\t loss = 0.0013036467134952545\t eps = 0.25\n","t = 60000\t reward = 0.67\t{'DQNAgent': 83, 'RandomPlus': 16}\n","\n","t = 60100\t loss = 0.001256386050954461\t eps = 0.25\n","t = 60200\t loss = 0.0004979347577318549\t eps = 0.25\n","t = 60300\t loss = 0.0006292794132605195\t eps = 0.25\n","t = 60400\t loss = 0.0006515647983178496\t eps = 0.25\n","t = 60500\t loss = 0.0009640002390369773\t eps = 0.25\n","t = 60500\t reward = 0.64\t{'DQNAgent': 80, 'RandomPlus': 16}\n","\n","t = 60600\t loss = 0.002022320404648781\t eps = 0.25\n","t = 60700\t loss = 0.0005914532812312245\t eps = 0.25\n","t = 60800\t loss = 0.0005923144053667784\t eps = 0.25\n","t = 60900\t loss = 0.0012281228555366397\t eps = 0.25\n","t = 61000\t loss = 0.000892632466275245\t eps = 0.25\n","t = 61000\t reward = 0.73\t{'DQNAgent': 85, 'RandomPlus': 12}\n","\n","t = 61100\t loss = 0.0014366344548761845\t eps = 0.25\n","t = 61200\t loss = 0.00031049243989400566\t eps = 0.25\n","t = 61300\t loss = 0.000980316661298275\t eps = 0.25\n","t = 61400\t loss = 0.002462002681568265\t eps = 0.25\n","t = 61500\t loss = 0.0004047685069963336\t eps = 0.25\n","t = 61500\t reward = 0.57\t{'DQNAgent': 77, 'RandomPlus': 20}\n","\n","t = 61600\t loss = 0.0007820724276825786\t eps = 0.25\n","t = 61700\t loss = 0.0004983400576747954\t eps = 0.25\n","t = 61800\t loss = 0.0006072918185964227\t eps = 0.25\n","t = 61900\t loss = 0.002752916654571891\t eps = 0.25\n","t = 62000\t loss = 0.0006747908191755414\t eps = 0.25\n","t = 62000\t reward = 0.48\t{'DQNAgent': 72, 'RandomPlus': 24}\n","\n","t = 62100\t loss = 0.0017574834637343884\t eps = 0.25\n","t = 62200\t loss = 0.000563959067221731\t eps = 0.25\n","t = 62300\t loss = 0.00051637995056808\t eps = 0.25\n","t = 62400\t loss = 0.004851627629250288\t eps = 0.25\n","t = 62500\t loss = 0.0008376440964639187\t eps = 0.25\n","t = 62500\t reward = 0.58\t{'DQNAgent': 78, 'RandomPlus': 20}\n","\n","t = 62600\t loss = 0.0013518457999452949\t eps = 0.25\n","t = 62700\t loss = 0.0004749041981995106\t eps = 0.25\n","t = 62800\t loss = 0.0011666023638099432\t eps = 0.25\n","t = 62900\t loss = 0.000492704682983458\t eps = 0.25\n","t = 63000\t loss = 0.0006372914649546146\t eps = 0.25\n","t = 63000\t reward = 0.57\t{'DQNAgent': 77, 'RandomPlus': 20}\n","\n","t = 63100\t loss = 0.0006537100416608155\t eps = 0.25\n","t = 63200\t loss = 0.0004058365593664348\t eps = 0.25\n","t = 63300\t loss = 0.000542895111721009\t eps = 0.25\n","t = 63400\t loss = 0.0026767058297991753\t eps = 0.25\n","t = 63500\t loss = 0.0009289213339798152\t eps = 0.25\n","t = 63500\t reward = 0.49\t{'DQNAgent': 71, 'RandomPlus': 22}\n","\n","t = 63600\t loss = 0.0007848340319469571\t eps = 0.25\n","t = 63700\t loss = 0.000539543922059238\t eps = 0.25\n"]}],"source":["# ========== CONTINUE ==========\n","\n","\n","with open('out.txt', 'w') as f:\n","  for t in range(50_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcrpJdfBWx2M"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_63500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_63500'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"df71328b-97a8-46ab-8e6d-7c2c34fa13a9","id":"IKMTr499Wx2N","executionInfo":{"status":"error","timestamp":1718717624617,"user_tz":-180,"elapsed":940701,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 63600\t loss = 0.009547475725412369\t eps = 0.25\n","t = 63700\t loss = 0.0023229101207107306\t eps = 0.25\n","t = 63800\t loss = 0.0004563727416098118\t eps = 0.25\n","t = 63900\t loss = 0.0004655389639083296\t eps = 0.25\n","t = 64000\t loss = 0.0006297405925579369\t eps = 0.25\n","t = 64000\t reward = 0.48\t{'DQNAgent': 72, 'RandomPlus': 24}\n","\n","t = 64100\t loss = 0.0004901965730823576\t eps = 0.25\n","t = 64200\t loss = 0.0008226131903938949\t eps = 0.25\n","t = 64300\t loss = 0.0005874842754565179\t eps = 0.25\n","t = 64400\t loss = 0.0003001315053552389\t eps = 0.25\n","t = 64500\t loss = 0.0023031188175082207\t eps = 0.25\n","t = 64500\t reward = 0.53\t{'DQNAgent': 72, 'RandomPlus': 19}\n","\n","t = 64600\t loss = 0.0005634687258861959\t eps = 0.25\n","t = 64700\t loss = 0.0016298370901495218\t eps = 0.25\n","t = 64800\t loss = 0.0012274766340851784\t eps = 0.25\n","t = 64900\t loss = 0.0007745488546788692\t eps = 0.25\n","t = 65000\t loss = 0.0008624959737062454\t eps = 0.25\n","t = 65000\t reward = 0.48\t{'DQNAgent': 73, 'RandomPlus': 25}\n","\n","t = 65100\t loss = 0.0005269839311949909\t eps = 0.25\n","t = 65200\t loss = 0.0009449983481317759\t eps = 0.25\n","t = 65300\t loss = 0.0014293601270765066\t eps = 0.25\n","t = 65400\t loss = 0.0007209139293991029\t eps = 0.25\n","t = 65500\t loss = 0.0005558452103286982\t eps = 0.25\n","t = 65500\t reward = 0.55\t{'DQNAgent': 77, 'RandomPlus': 22}\n","\n","t = 65600\t loss = 0.0010288034100085497\t eps = 0.25\n","t = 65700\t loss = 0.0006765482248738408\t eps = 0.25\n","t = 65800\t loss = 0.001169133116491139\t eps = 0.25\n","t = 65900\t loss = 0.0006416896358132362\t eps = 0.25\n","t = 66000\t loss = 0.00038543101982213557\t eps = 0.25\n","t = 66000\t reward = 0.54\t{'DQNAgent': 74, 'RandomPlus': 20}\n","\n","t = 66100\t loss = 0.0009413190418854356\t eps = 0.25\n","t = 66200\t loss = 0.0005217472207732499\t eps = 0.25\n","t = 66300\t loss = 0.0014226539060473442\t eps = 0.25\n","t = 66400\t loss = 0.0006498249713331461\t eps = 0.25\n","t = 66500\t loss = 0.0016942472429946065\t eps = 0.25\n","t = 66500\t reward = 0.67\t{'DQNAgent': 81, 'RandomPlus': 14}\n","\n","t = 66600\t loss = 0.0005974878440611064\t eps = 0.25\n","t = 66700\t loss = 0.0005926765152253211\t eps = 0.25\n","t = 66800\t loss = 0.00043167630792595446\t eps = 0.25\n","t = 66900\t loss = 0.00036426071892492473\t eps = 0.25\n","t = 67000\t loss = 0.0028897994197905064\t eps = 0.25\n","t = 67000\t reward = 0.66\t{'DQNAgent': 82, 'RandomPlus': 16}\n","\n","t = 67100\t loss = 0.002770486753433943\t eps = 0.25\n","t = 67200\t loss = 0.0008429987356066704\t eps = 0.25\n","t = 67300\t loss = 0.00038890750147402287\t eps = 0.25\n","t = 67400\t loss = 0.0016139576910063624\t eps = 0.25\n","t = 67500\t loss = 0.0010972874006256461\t eps = 0.25\n","t = 67500\t reward = 0.46\t{'DQNAgent': 71, 'RandomPlus': 25}\n","\n","t = 67600\t loss = 0.0009369725012220442\t eps = 0.25\n","t = 67700\t loss = 0.0008092054631561041\t eps = 0.25\n","t = 67800\t loss = 0.0006121634505689144\t eps = 0.25\n","t = 67900\t loss = 0.0006840646965429187\t eps = 0.25\n","t = 68000\t loss = 0.000433477689512074\t eps = 0.25\n","t = 68000\t reward = 0.68\t{'DQNAgent': 82, 'RandomPlus': 14}\n","\n","t = 68100\t loss = 0.0010744142346084118\t eps = 0.25\n","t = 68200\t loss = 0.0007740181172266603\t eps = 0.25\n","t = 68300\t loss = 0.0022018644958734512\t eps = 0.25\n","t = 68400\t loss = 0.0010894091101363301\t eps = 0.25\n","t = 68500\t loss = 0.0006561356130987406\t eps = 0.25\n","t = 68500\t reward = 0.47\t{'DQNAgent': 72, 'RandomPlus': 25}\n","\n","t = 68600\t loss = 0.0005874804337508976\t eps = 0.25\n","t = 68700\t loss = 0.0006814106600359082\t eps = 0.25\n","t = 68800\t loss = 0.002551998710259795\t eps = 0.25\n","t = 68900\t loss = 0.0006888229981996119\t eps = 0.25\n","t = 69000\t loss = 0.0007254763040691614\t eps = 0.25\n","t = 69000\t reward = 0.61\t{'DQNAgent': 79, 'RandomPlus': 18}\n","\n","t = 69100\t loss = 0.0006487099453806877\t eps = 0.25\n","t = 69200\t loss = 0.0006842366419732571\t eps = 0.25\n","t = 69300\t loss = 0.0008831839659251273\t eps = 0.25\n","t = 69400\t loss = 0.0006966833025217056\t eps = 0.25\n","t = 69500\t loss = 0.0009663273813202977\t eps = 0.25\n","t = 69500\t reward = 0.5\t{'DQNAgent': 74, 'RandomPlus': 24}\n","\n","t = 69600\t loss = 0.0003619864583015442\t eps = 0.25\n","t = 69700\t loss = 0.000445154175395146\t eps = 0.25\n","t = 69800\t loss = 0.0007052664877846837\t eps = 0.25\n","t = 69900\t loss = 0.0007906268583610654\t eps = 0.25\n","t = 70000\t loss = 0.0016513378359377384\t eps = 0.25\n","t = 70000\t reward = 0.53\t{'DQNAgent': 75, 'RandomPlus': 22}\n","\n","t = 70100\t loss = 0.0009694445179775357\t eps = 0.25\n","t = 70200\t loss = 0.00062177749350667\t eps = 0.25\n","t = 70300\t loss = 0.0009657784830778837\t eps = 0.25\n","t = 70400\t loss = 0.0010071919532492757\t eps = 0.25\n","t = 70500\t loss = 0.001482976134866476\t eps = 0.25\n","t = 70500\t reward = 0.65\t{'DQNAgent': 80, 'RandomPlus': 15}\n","\n","t = 70600\t loss = 0.0006318640662357211\t eps = 0.25\n","t = 70700\t loss = 0.0013924911618232727\t eps = 0.25\n","t = 70800\t loss = 0.0005202221218496561\t eps = 0.25\n","t = 70900\t loss = 0.0010737262200564146\t eps = 0.25\n","t = 71000\t loss = 0.0005615182453766465\t eps = 0.25\n","t = 71000\t reward = 0.65\t{'DQNAgent': 81, 'RandomPlus': 16}\n","\n","t = 71100\t loss = 0.0012891681399196386\t eps = 0.25\n","t = 71200\t loss = 0.0008308411343023181\t eps = 0.25\n","t = 71300\t loss = 0.0015338585944846272\t eps = 0.25\n","t = 71400\t loss = 0.0004986532730981708\t eps = 0.25\n","t = 71500\t loss = 0.0008791968575678766\t eps = 0.25\n","t = 71500\t reward = 0.62\t{'DQNAgent': 79, 'RandomPlus': 17}\n","\n","t = 71600\t loss = 0.0006769343744963408\t eps = 0.25\n","t = 71700\t loss = 0.0011183475144207478\t eps = 0.25\n","t = 71800\t loss = 0.001238939817994833\t eps = 0.25\n","t = 71900\t loss = 0.0006215082248672843\t eps = 0.25\n","t = 72000\t loss = 0.0011050950270146132\t eps = 0.25\n","t = 72000\t reward = 0.48\t{'DQNAgent': 73, 'RandomPlus': 25}\n","\n","t = 72100\t loss = 0.001258889795280993\t eps = 0.25\n","t = 72200\t loss = 0.0008804035023786128\t eps = 0.25\n","t = 72300\t loss = 0.0007037712493911386\t eps = 0.25\n","t = 72400\t loss = 0.0005263015627861023\t eps = 0.25\n","t = 72500\t loss = 0.001352020539343357\t eps = 0.25\n","t = 72500\t reward = 0.45\t{'DQNAgent': 71, 'RandomPlus': 26}\n","\n","t = 72600\t loss = 0.0011286437511444092\t eps = 0.25\n","t = 72700\t loss = 0.0004919878556393087\t eps = 0.25\n","t = 72800\t loss = 0.0006977508310228586\t eps = 0.25\n","t = 72900\t loss = 0.001058309804648161\t eps = 0.25\n","t = 73000\t loss = 0.0004935170290991664\t eps = 0.25\n","t = 73000\t reward = 0.3\t{'DQNAgent': 62, 'RandomPlus': 32}\n","\n","t = 73100\t loss = 0.0008701414917595685\t eps = 0.25\n","t = 73200\t loss = 0.0018673399463295937\t eps = 0.25\n","t = 73300\t loss = 0.0008765686070546508\t eps = 0.25\n","t = 73400\t loss = 0.0009763828129507601\t eps = 0.25\n","t = 73500\t loss = 0.0008340489584952593\t eps = 0.25\n","t = 73500\t reward = 0.64\t{'DQNAgent': 81, 'RandomPlus': 17}\n","\n","t = 73600\t loss = 0.0009670263389125466\t eps = 0.25\n","t = 73700\t loss = 0.0013388514053076506\t eps = 0.25\n","t = 73800\t loss = 0.001320588169619441\t eps = 0.25\n","t = 73900\t loss = 0.0006369580514729023\t eps = 0.25\n","t = 74000\t loss = 0.0015392311615869403\t eps = 0.25\n","t = 74000\t reward = 0.71\t{'DQNAgent': 83, 'RandomPlus': 12}\n","\n","t = 74100\t loss = 0.001969048986211419\t eps = 0.25\n","t = 74200\t loss = 0.00045137840788811445\t eps = 0.25\n","t = 74300\t loss = 0.0014800627250224352\t eps = 0.25\n","t = 74400\t loss = 0.007548658177256584\t eps = 0.25\n","t = 74500\t loss = 0.0011050193570554256\t eps = 0.25\n","t = 74500\t reward = 0.49\t{'DQNAgent': 72, 'RandomPlus': 23}\n","\n","t = 74600\t loss = 0.0021186238154768944\t eps = 0.25\n","t = 74700\t loss = 0.0008235421264544129\t eps = 0.25\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-749eaa1acea0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                                    agent, target_network, weights, indices, gamma, prioritized=True)\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m_no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_device_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         ):\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mnorms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ========== CONTINUE ==========\n","\n","\n","with open('out.txt', 'w') as f:\n","  for t in range(63_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"markdown","metadata":{"id":"wMHCdyXqKqCk"},"source":["#Тестирование обученных моделей (инференс с маскированием)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QySv5l9i6fUs"},"outputs":[],"source":["PATH = '/content/drive/MyDrive/TicTacToe_9/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":832,"status":"ok","timestamp":1718661759238,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"txmhrUHlOM-2","outputId":"47feaf64-17ab-4ed1-b932-2ba0fd34d277"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    0 {'DQNAgent': 3, 'RandomPlus': 997}\n","  500 {'DQNAgent': 10, 'RandomPlus': 979}\n"," 1000 {'DQNAgent': 32, 'RandomPlus': 951}\n"," 1500 {'DQNAgent': 66, 'RandomPlus': 885}\n"," 2000 {'DQNAgent': 105, 'RandomPlus': 862}\n"," 2500 {'DQNAgent': 110, 'RandomPlus': 861}\n"," 3000 {'DQNAgent': 155, 'RandomPlus': 824}\n"," 3500 {'DQNAgent': 227, 'RandomPlus': 753}\n"," 4000 {'DQNAgent': 203, 'RandomPlus': 760}\n"," 4500 {'DQNAgent': 151, 'RandomPlus': 798}\n"," 5000 {'DQNAgent': 177, 'RandomPlus': 752}\n"," 5500 {'DQNAgent': 234, 'RandomPlus': 693}\n"," 6000 {'DQNAgent': 284, 'RandomPlus': 677}\n"," 6500 {'DQNAgent': 262, 'RandomPlus': 671}\n"," 7000 {'DQNAgent': 223, 'RandomPlus': 701}\n"," 7500 {'DQNAgent': 279, 'RandomPlus': 665}\n"," 8000 {'DQNAgent': 275, 'RandomPlus': 649}\n"," 8500 {'DQNAgent': 271, 'RandomPlus': 645}\n"," 9000 {'DQNAgent': 339, 'RandomPlus': 591}\n"," 9500 {'DQNAgent': 297, 'RandomPlus': 605}\n","10000 {'DQNAgent': 265, 'RandomPlus': 636}\n","10500 {'DQNAgent': 289, 'RandomPlus': 629}\n","11000 {'DQNAgent': 367, 'RandomPlus': 561}\n","11500 {'DQNAgent': 324, 'RandomPlus': 595}\n","12000 {'DQNAgent': 372, 'RandomPlus': 556}\n","12500 {'DQNAgent': 335, 'RandomPlus': 548}\n","13000 {'DQNAgent': 383, 'RandomPlus': 539}\n","13500 {'DQNAgent': 300, 'RandomPlus': 616}\n","14000 {'DQNAgent': 361, 'RandomPlus': 551}\n","14500 {'DQNAgent': 364, 'RandomPlus': 543}\n","15000 {'DQNAgent': 403, 'RandomPlus': 496}\n","15500 {'DQNAgent': 391, 'RandomPlus': 506}\n","16000 {'DQNAgent': 388, 'RandomPlus': 507}\n","16500 {'DQNAgent': 428, 'RandomPlus': 487}\n","17000 {'DQNAgent': 363, 'RandomPlus': 545}\n","17500 {'DQNAgent': 323, 'RandomPlus': 579}\n","18000 {'DQNAgent': 359, 'RandomPlus': 559}\n","18500 {'DQNAgent': 423, 'RandomPlus': 485}\n","19000 {'DQNAgent': 397, 'RandomPlus': 498}\n","19500 {'DQNAgent': 392, 'RandomPlus': 513}\n","20000 {'DQNAgent': 418, 'RandomPlus': 485}\n","20500 {'DQNAgent': 377, 'RandomPlus': 526}\n","21000 {'DQNAgent': 363, 'RandomPlus': 517}\n","21500 {'DQNAgent': 535, 'RandomPlus': 381}\n","22000 {'DQNAgent': 567, 'RandomPlus': 363}\n","22500 {'DQNAgent': 457, 'RandomPlus': 426}\n","23000 {'DQNAgent': 520, 'RandomPlus': 380}\n","23500 {'DQNAgent': 577, 'RandomPlus': 339}\n","24000 {'DQNAgent': 557, 'RandomPlus': 355}\n","24500 {'DQNAgent': 562, 'RandomPlus': 365}\n","25000 {'DQNAgent': 586, 'RandomPlus': 330}\n","25500 {'DQNAgent': 603, 'RandomPlus': 332}\n","26000 {'DQNAgent': 589, 'RandomPlus': 337}\n","26500 {'DQNAgent': 531, 'RandomPlus': 354}\n","27000 {'DQNAgent': 562, 'RandomPlus': 324}\n","27500 {'DQNAgent': 607, 'RandomPlus': 310}\n","28000 {'DQNAgent': 663, 'RandomPlus': 286}\n","28500 {'DQNAgent': 603, 'RandomPlus': 319}\n","29000 {'DQNAgent': 587, 'RandomPlus': 315}\n","29500 {'DQNAgent': 674, 'RandomPlus': 256}\n","30000 {'DQNAgent': 703, 'RandomPlus': 250}\n","30500 {'DQNAgent': 722, 'RandomPlus': 228}\n","31000 {'DQNAgent': 659, 'RandomPlus': 254}\n","31500 {'DQNAgent': 678, 'RandomPlus': 267}\n","32000 {'DQNAgent': 628, 'RandomPlus': 296}\n","32500 {'DQNAgent': 660, 'RandomPlus': 279}\n","33000 {'DQNAgent': 672, 'RandomPlus': 267}\n","33500 {'DQNAgent': 685, 'RandomPlus': 245}\n","34000 {'DQNAgent': 694, 'RandomPlus': 231}\n","34500 {'DQNAgent': 728, 'RandomPlus': 194}\n","35000 {'DQNAgent': 721, 'RandomPlus': 212}\n","35500 {'DQNAgent': 720, 'RandomPlus': 202}\n","36000 {'DQNAgent': 765, 'RandomPlus': 182}\n","36500 {'DQNAgent': 770, 'RandomPlus': 186}\n","37000 {'DQNAgent': 756, 'RandomPlus': 188}\n","37500 {'DQNAgent': 720, 'RandomPlus': 219}\n","38000 {'DQNAgent': 767, 'RandomPlus': 170}\n","38500 {'DQNAgent': 779, 'RandomPlus': 171}\n","39000 {'DQNAgent': 769, 'RandomPlus': 184}\n","39500 {'DQNAgent': 750, 'RandomPlus': 178}\n","40000 {'DQNAgent': 756, 'RandomPlus': 192}\n","40500 {'DQNAgent': 763, 'RandomPlus': 178}\n","41000 {'DQNAgent': 780, 'RandomPlus': 177}\n","41500 {'DQNAgent': 775, 'RandomPlus': 171}\n","42000 {'DQNAgent': 799, 'RandomPlus': 155}\n","42500 {'DQNAgent': 792, 'RandomPlus': 165}\n","43000 {'DQNAgent': 776, 'RandomPlus': 178}\n","43500 {'DQNAgent': 799, 'RandomPlus': 168}\n","44000 {'DQNAgent': 775, 'RandomPlus': 181}\n","44500 {'DQNAgent': 791, 'RandomPlus': 170}\n","45000 {'DQNAgent': 799, 'RandomPlus': 162}\n","45500 {'DQNAgent': 808, 'RandomPlus': 141}\n","\n","CONTINUE\n","46000 {'DQNAgent': 829, 'RandomPlus': 145}\n","46500 {'DQNAgent': 812, 'RandomPlus': 153}\n","47000 {'DQNAgent': 821, 'RandomPlus': 149}\n","47500 {'DQNAgent': 819, 'RandomPlus': 153}\n","48000 {'DQNAgent': 794, 'RandomPlus': 163}\n","48500 {'DQNAgent': 775, 'RandomPlus': 167}\n","49000 {'DQNAgent': 826, 'RandomPlus': 131}\n","\n"]}],"source":["# Сравнение обученных моделей (START -> CONTINUE)\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(0, 49_001, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1718661556891,"user":{"displayName":"Максим Тимошкин","userId":"09734858170620036336"},"user_tz":-180},"id":"k5QnIHeaNY7W","outputId":"c703ed62-5047-4813-e2bb-7f5eced7190c"},"outputs":[{"name":"stdout","output_type":"stream","text":["49500 {'DQNAgent': 781, 'RandomPlus': 175}\n","50000 {'DQNAgent': 774, 'RandomPlus': 171}\n","50500 {'DQNAgent': 779, 'RandomPlus': 171}\n","51000 {'DQNAgent': 786, 'RandomPlus': 155}\n","51500 {'DQNAgent': 771, 'RandomPlus': 177}\n","52000 {'DQNAgent': 794, 'RandomPlus': 165}\n","52500 {'DQNAgent': 823, 'RandomPlus': 140}\n","53000 {'DQNAgent': 801, 'RandomPlus': 162}\n","53500 {'DQNAgent': 810, 'RandomPlus': 147}\n","54000 {'DQNAgent': 773, 'RandomPlus': 188}\n","54500 {'DQNAgent': 782, 'RandomPlus': 166}\n","55000 {'DQNAgent': 723, 'RandomPlus': 228}\n","55500 {'DQNAgent': 747, 'RandomPlus': 215}\n","56000 {'DQNAgent': 712, 'RandomPlus': 228}\n","56500 {'DQNAgent': 798, 'RandomPlus': 163}\n","57000 {'DQNAgent': 774, 'RandomPlus': 173}\n","57500 {'DQNAgent': 791, 'RandomPlus': 165}\n","58000 {'DQNAgent': 735, 'RandomPlus': 219}\n","58500 {'DQNAgent': 758, 'RandomPlus': 197}\n","59000 {'DQNAgent': 748, 'RandomPlus': 210}\n","59500 {'DQNAgent': 764, 'RandomPlus': 202}\n","60000 {'DQNAgent': 746, 'RandomPlus': 204}\n","60500 {'DQNAgent': 727, 'RandomPlus': 205}\n","61000 {'DQNAgent': 736, 'RandomPlus': 207}\n","61500 {'DQNAgent': 745, 'RandomPlus': 201}\n","62000 {'DQNAgent': 731, 'RandomPlus': 210}\n","62500 {'DQNAgent': 777, 'RandomPlus': 156}\n","63000 {'DQNAgent': 707, 'RandomPlus': 200}\n","63500 {'DQNAgent': 648, 'RandomPlus': 246}\n","64000 {'DQNAgent': 772, 'RandomPlus': 180}\n","64500 {'DQNAgent': 770, 'RandomPlus': 197}\n","65000 {'DQNAgent': 694, 'RandomPlus': 256}\n","65500 {'DQNAgent': 749, 'RandomPlus': 208}\n","66000 {'DQNAgent': 760, 'RandomPlus': 193}\n","66500 {'DQNAgent': 744, 'RandomPlus': 203}\n","67000 {'DQNAgent': 721, 'RandomPlus': 206}\n","67500 {'DQNAgent': 697, 'RandomPlus': 245}\n","68000 {'DQNAgent': 730, 'RandomPlus': 220}\n","68500 {'DQNAgent': 669, 'RandomPlus': 256}\n","69000 {'DQNAgent': 813, 'RandomPlus': 162}\n","69500 {'DQNAgent': 799, 'RandomPlus': 173}\n","70000 {'DQNAgent': 810, 'RandomPlus': 157}\n","70500 {'DQNAgent': 721, 'RandomPlus': 216}\n","\n"]}],"source":["# Сравнение обученных моделей (SELF PLAY - BAD)\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(49_500, 82_501, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9LIq2qJIT0u"},"outputs":[],"source":["# Сравнение лучших моделей (без проигрышей)\n","models = [...]\n","\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for model in models:\n","    agent.load_state_dict(torch.load(f'{PATH}model_{model}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(10_000)\n","    print(model, eval_game.wins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1682,"status":"ok","timestamp":1718626832207,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"sT5QLsvSj0-2","outputId":"63812e72-899e-4bc8-8a5e-a6e05587f120"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Загрузка самой лучшей модели\n","agent.load_state_dict(torch.load(f'{PATH}model_45500', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538341,"status":"ok","timestamp":1718627370538,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"_bgzNN9tsPVN","outputId":"edfd5f21-85a2-4059-bbc5-c43a9d4c5ceb"},"outputs":[{"name":"stdout","output_type":"stream","text":["player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  O  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  O  .  .\n"," .  .  O  X  X  .  .\n"," X  .  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  O  .  .\n"," .  .  O  X  X  .  .\n"," X  .  X  O  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 5\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  X  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  .  O  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 3\n","player 1's turn:\n"," .  .  .  .  X  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  O  O  O  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  X  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  .  O  O  O  X  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 2\n","player 1's turn:\n"," .  .  .  .  X  .  .\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  O  O  O  O  X  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  X  .  X\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," .  O  O  O  O  X  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 1\n","player 1's turn:\n"," .  .  .  .  X  .  X\n"," .  .  O  O  X  .  .\n"," .  X  O  X  O  .  .\n"," .  .  O  X  X  X  .\n"," X  .  X  O  .  .  .\n"," O  O  O  O  O  X  .\n"," .  .  .  .  .  .  .\n","Победа (Human)!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","Введите ваш ход (Строка, столбец)\n","4 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 2\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 2\n","player -1's turn:\n"," .  X  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  .  .  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  .  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 6\n","player -1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  .  .  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  .  O  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  .  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 6\n","player -1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  .  O  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  X  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  O  O  .  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  X  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 6\n","player -1's turn:\n"," .  X  .  .  .  .  .\n"," .  O  O  O  O  X  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  X  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  .  .  .  .  .\n"," O  O  O  O  O  X  .\n"," .  X  O  O  X  .  .\n"," .  X  X  X  O  X  .\n"," .  X  O  X  .  X  .\n"," .  O  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Победа (DQNAgent)!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 5\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  .  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  X  .  .  O  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","7 1\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  X  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  X  .\n"," .  .  O  X  X  .  .\n"," .  .  O  X  X  .  .\n"," .  .  X  O  .  .  .\n"," .  X  .  .  O  .  .\n"," O  .  .  .  .  .  .\n","Победа (DQNAgent)!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","Введите ваш ход (Строка, столбец)\n","4 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 6\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 3\n","player -1's turn:\n"," .  .  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  .  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  O\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 2\n","player -1's turn:\n"," .  X  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  .  O\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  O  O\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 7\n","player -1's turn:\n"," .  X  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  .  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  X  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 4\n","player -1's turn:\n"," .  X  X  X  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  .  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  X  X  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  .  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player -1's turn:\n"," .  X  X  X  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  X  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  X  X  .  .  .\n"," .  .  O  X  .  O  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  X  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 5\n","player -1's turn:\n"," .  X  X  X  X  .  .\n"," .  .  O  X  .  O  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  X  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  .  .  .\n","player 1's turn:\n"," .  X  X  X  X  .  .\n"," .  .  O  X  .  O  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  X  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  O  .  .\n","Введите ваш ход (Строка, столбец)\n","1 6\n","player -1's turn:\n"," .  X  X  X  X  X  .\n"," .  .  O  X  .  O  .\n"," .  .  O  O  X  O  .\n"," .  .  X  X  O  X  .\n"," .  .  O  X  O  O  O\n"," .  .  .  .  .  .  X\n"," .  .  .  .  O  .  .\n","Победа (Human)!\n","\n"]},{"data":{"text/plain":["{'DQNAgent': 2, 'Human': 2}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["agent.epsilon = 0\n","test_game = TicTacToe(agent, Human(), board_size=board_size, win_size=win_size)\n","test_game.play(4, True)\n","test_game.wins"]},{"cell_type":"markdown","metadata":{"id":"TAq9ckumpm01"},"source":["# Первый ход за крестики и значения $Q$-фунцкии в начальном состоянии"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1718562904401,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"aKjltLQC1-vk","outputId":"4eeacc16-0953-4d2c-8386-ee747857564f"},"outputs":[{"data":{"text/plain":["(3, 3)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["state2d = torch.tensor(np.zeros((1, 7, 7))).to(device)\n","\n","q_values = agent(state2d).squeeze(0).detach().cpu().numpy()\n","np.unravel_index(q_values.argmax(), q_values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1718562908136,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"dTKnN9UG4TJN","outputId":"23486e20-ef3e-471d-b152-18788c98364b"},"outputs":[{"data":{"text/plain":["array([[-0.0684, -0.064 , -0.0358, -0.0494, -0.0263, -0.0711, -0.0195],\n","       [-0.0457, -0.0207, -0.0132, -0.0035, -0.0091, -0.029 , -0.0438],\n","       [-0.0156, -0.0113,  0.0434,  0.0295,  0.0367, -0.0051, -0.0104],\n","       [-0.0425, -0.0255,  0.0354,  0.0539,  0.0183, -0.0157, -0.0361],\n","       [-0.0721, -0.0236,  0.0205,  0.0216,  0.0134, -0.0366, -0.0267],\n","       [-0.0979, -0.0705, -0.0431, -0.0291, -0.044 , -0.0472, -0.0386],\n","       [-0.0893, -0.0818, -0.0544, -0.0399, -0.0268, -0.0384, -0.0467]],\n","      dtype=float32)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["q_values.round(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jzAPJvAZeGY"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1xkpvZIncGCQWTMS_FZAbkoNgcgEEVSqC","timestamp":1718578441085},{"file_id":"1wqCozfdeRJnqyq9lgTKHqqbIOJ70UoZc","timestamp":1718484277044},{"file_id":"17AdIcgMxS_7_mOiy7FUK1C5VUgC8F-8_","timestamp":1718460691857},{"file_id":"1Gr04QBn85xAghWhQrafFAC3IVYCCcrdF","timestamp":1718270221903},{"file_id":"1tYpwZfpcc8mwjf9xBvf2Qh4nBVyZDdDi","timestamp":1718209975048},{"file_id":"1srwb210ZiHsQBrRBDRQ5YvK6o5ZuV2x9","timestamp":1718193488488},{"file_id":"17BHq081ewJDS6eZRZvxiWWTUVu9adCx1","timestamp":1718173770359}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
