{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jas5z2XbgpIK","executionInfo":{"status":"ok","timestamp":1718573177649,"user_tz":-180,"elapsed":8558,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["import numpy as np\n","from collections import deque\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718573177649,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"eGa4uhXjfHDA","outputId":"29020705-9f11-4eb3-a984-53a4e134688e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"Q9aoBPtbKYgm"},"source":["#Игра"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HkV_S73IfMyq","executionInfo":{"status":"ok","timestamp":1718573177649,"user_tz":-180,"elapsed":6,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["# Игра крестики-нолики\n","class TicTacToe:\n","    def __init__(self, player_1, player_2, board_size=3, win_size=3):\n","        self.players = {-1: player_1,\n","                         1: player_2}\n","\n","        self.wins = {player_1.name: 0,\n","                     player_2.name: 0}\n","\n","        self.board_size=board_size\n","        self.win_size = win_size\n","        self._kernel = self._create_kernel()\n","\n","\n","    # Создает ядро свертки для расчета побед\n","    def _create_kernel(self):\n","        kernel = np.zeros((2 * self.win_size + 2, self.win_size, self.win_size))\n","        for i in range(self.win_size):\n","            kernel[i, i, :] = np.ones(self.win_size)\n","        for i in range(self.win_size, 2 * self.win_size):\n","            kernel[i, :, i - self.win_size] = np.ones(self.win_size).T\n","        kernel[2 * self.win_size] = np.eye(self.win_size)\n","        kernel[2 * self.win_size + 1] = np.fliplr(np.eye(self.win_size))\n","        return kernel\n","\n","\n","    # Проверяет победы для состояний states, в кот. ходы были совершены игроками turns, turn={-1, 1}\n","    def _test_win(self, state, turn):\n","        rows, cols, w_size = *state.shape, self.win_size\n","        expanded_states = np.lib.stride_tricks.as_strided(\n","            state,\n","            shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","            strides=(*state.strides, *state.strides),\n","            writeable=False,\n","        )\n","        feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","        return -turn * (feature_map == turn * w_size).any().astype(int)\n","\n","\n","    # Проигрывание нескольких полных эпизодов\n","    def play(self, num_games=1, visualize=False):\n","        transitions = []\n","        for t in range(num_games):\n","            next_turn = turn = -1\n","            state = (np.zeros((self.board_size, self.board_size)), turn) # Начальное состояние игры. state = (state2d, turn)\n","            if visualize:\n","                self.visualize_state(state, turn)\n","            while(next_turn != 0):\n","                state_2d, turn = state\n","                current_player = self.players[turn]\n","                action = current_player.get_action(state)\n","                next_state_2d, next_turn, reward = self.play_turn(state, action)\n","                transitions.append((turn * state_2d, action, reward, -turn * next_state_2d, next_turn == 0))   #state, action, reward, new_state, done\n","                if visualize:\n","                    self.visualize_state((next_state_2d, next_turn), turn)\n","                if next_turn == 0:\n","                    if visualize:\n","                        if (reward == 0): print('Ничья!\\n')\n","                        else: print(f'Победа ({self.players[reward * turn].name})!\\n')\n","                    if reward != 0:\n","                        self.wins[self.players[reward * turn].name] += 1\n","                    self.players = {-1: self.players[1], 1: self.players[-1]}\n","                state = next_state_2d, next_turn\n","        return transitions\n","\n","\n","    # Выполнение хода и проверка на некорректный ход (проигрышь) / выигрыш / ничью\n","    def play_turn(self, state, action): # next_state2d, next_turn, reward\n","        state2d, turn = state\n","        next_state2d = state2d.copy()\n","\n","        # Проверка корректности хода\n","        if (state2d[(action)] != 0):\n","            return next_state2d, 0, -1        # Игрок проиграл (# next_turn == 0 => Игра окончена)\n","\n","        # Совершение хода\n","        next_state2d[action] = turn\n","\n","        # Проверка победы\n","        if self._test_win(next_state2d, turn):\n","            return next_state2d, 0, 1         # Текущий игрок побеждает (next_turn == 0 => Игра окончена)\n","\n","        # Проверка ничьи\n","        if (next_state2d != 0).all():\n","            return next_state2d, 0, 0         # Ничья (next_turn == 0 => Игра окончена)\n","\n","        # Инчае, ход следующего игрока\n","        return next_state2d, -turn, 0         # next_turn == -turn => Смена хода\n","\n","\n","    # Выводит на экран состояние игры после хода игрока\n","    @staticmethod\n","    def visualize_state(next_state, turn):\n","        next_state2d, next_turn = next_state\n","        print(f\"player {turn}'s turn:\")\n","        if (next_state2d == 0).all() and turn == 0:\n","            print(\"[invalid state]\\n\\n\")\n","        else:\n","            print(str(next_state2d)\n","                  .replace(\".\", \"\")\n","                  .replace(\"[[\", \"\")\n","                  .replace(\" [\", \"\")\n","                  .replace(\"]]\", \"\")\n","                  .replace(\"]\", \"\")\n","                  .replace(\"-0\", \" .\")\n","                  .replace(\"0\", \".\")\n","                  .replace(\"-1\", \" X\")\n","                  .replace(\"1\", \"O\")\n","            )\n","\n","\n","    @staticmethod\n","    def print_transitions(transitions):\n","        states, actions, rewards, next_states, dones = zip(*transitions)\n","        for i in np.arange(len(states)):\n","            print(\"\\033[31m{}.\".format(i + 1), '\\033[30m')\n","            TicTacToe.visualize_state((next_states[i], -1), 1)\n","            print('\\naction = ', actions[i] + np.array([1, 1]), end='\\n')\n","            print('reward = ', rewards[i], end='\\n')\n","            if (dones[i]): print('Игра окончена', end='\\n\\n')\n","            else: print('Игра продолжается', end='\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"M3pr2-P0Ka5F"},"source":["#Игроки"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"o5rtWxp4hTVB","executionInfo":{"status":"ok","timestamp":1718573177650,"user_tz":-180,"elapsed":6,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["class Human:\n","    def __init__(self, name='Human'):\n","        self.name = name\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        print('Введите ваш ход (Строка, столбец)')\n","        row, col = map(int, input().split())\n","        while (state2d[row - 1, col - 1] != 0):\n","            print('Клетка занята!')\n","            print('Введите ваш ход (Строка, столбец)')\n","            row, col = map(int, input().split())\n","        return row - 1, col - 1"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PPVMOC0qTIlK","executionInfo":{"status":"ok","timestamp":1718573177650,"user_tz":-180,"elapsed":6,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["# Игрок Рандом с преимуществами:\n","# 1. Если есть возможность выиграть за один ход, он делает это (win = True)\n","# 2. Если у соперника есть возможность выиграть в следующем ходу, он блокирует этот ход (defense = True)\n","# 3. Иначе, выбирает случайный ход из множества допустимых\n","class RandomPlus:\n","    def __init__(self, board_size=3, win_size=3, name='RandomPlus', win=False, defense=False):\n","        self.name = name\n","        self.board_size = board_size\n","        self.win_size = win_size\n","        self.win = win\n","        self.defense = defense\n","\n","        self._kernel = self._create_kernel()\n","\n","\n","    # Создает ядро свертки для расчета потенциальных побед\n","    def _create_kernel(self):\n","        kernel = np.zeros((2 * self.win_size + 2, self.win_size, self.win_size))\n","        for i in range(self.win_size):\n","            kernel[i, i, :] = np.ones(self.win_size)\n","        for i in range(self.win_size, 2 * self.win_size):\n","            kernel[i, :, i - self.win_size] = np.ones(self.win_size).T\n","        kernel[2 * self.win_size] = np.eye(self.win_size)\n","        kernel[2 * self.win_size + 1] = np.fliplr(np.eye(self.win_size))\n","        return kernel\n","\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        rows, cols, w_size = *state2d.shape, self.win_size\n","\n","        if self.win or self.defense:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","\n","            if self.win:\n","                wins = np.array(np.where(turn * feature_map == w_size - 1))\n","                if wins.shape[1] > 0:\n","                    K, I, J = wins[:, 0]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 1))\n","                if defenses.shape[1] > 0:\n","                    K, I, J = defenses[:, 0]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gRBw9v0hmVIi","executionInfo":{"status":"ok","timestamp":1718573178165,"user_tz":-180,"elapsed":520,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["class DQNAgent(nn.Module):\n","    def __init__(self, epsilon=0, name='DQNAgent', masking=False):\n","        super().__init__()\n","\n","        self.name = name\n","        self.epsilon = epsilon\n","        self.n_channels = 3\n","        self.masking = masking    # Маскирование (ВКЛЮЧАТЬ ТОЛЬКО ПРИ ИНФЕРЕНСЕ)\n","\n","        self.network = nn.Sequential(\n","            nn.Conv2d(self.n_channels, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 1, kernel_size=(3, 3), padding='same')\n","        )\n","\n","    def forward(self, x):\n","        x = torch.stack([x == 1, x == -1, x == 0], axis=1).float()\n","        return self.network(x).squeeze(1)\n","\n","    def greedy_action(self, state, device=device):\n","        state2d, turn = state\n","        state_t = torch.FloatTensor(turn * state2d).unsqueeze(0).to(device)\n","        q_values = self.forward(state_t).squeeze(0).detach().cpu().numpy()\n","        if self.masking:\n","            q_values[state2d != 0] = -float(\"Inf\")\n","        return np.unravel_index(q_values.argmax(), q_values.shape)\n","\n","    def random_action(self, state):\n","        state2d, turn = state\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])\n","\n","    def get_action(self, state):\n","        if random.random() < self.epsilon:\n","            action = self.random_action(state)\n","        else:\n","            action = self.greedy_action(state)\n","        return action"]},{"cell_type":"markdown","source":["# Буферы"],"metadata":{"id":"03J3GWj6P8tj"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ni-Mh6jE_-Xd","executionInfo":{"status":"ok","timestamp":1718573178166,"user_tz":-180,"elapsed":8,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["# Обычный буфер\n","class ReplayBuffer(object):\n","    def __init__(self, size):\n","        self._storage = deque(maxlen=size)\n","\n","    def __len__(self):\n","        return len(self._storage)\n","\n","    def add(self, transition):\n","        self._storage.append(transition)\n","\n","    def sample(self, batch_size, augmentation=False):\n","        batch = random.sample(self._storage, batch_size)\n","        states, actions, rewards, next_states, dones = zip(*batch)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            # ======== ДЛЯ ВСЕГО БАТЧА ОДИНАКОВАЯ АУГМЕНТАЦИЯ ========\n","            # n = states.shape[-1] - 1\n","            # k = np.random.randint(0, 4)\n","            # states = np.rot90(states, k, axes=(1,2)).copy()\n","            # next_states = np.rot90(next_states, k, axes=(1,2)).copy()\n","\n","            # i, j = actions[:, 0], actions[:, 1]\n","            # if k == 1: actions = np.column_stack((n - j, i))\n","            # if k == 2: actions = np.column_stack((n - i, n - j))\n","            # if k == 3: actions = np.column_stack((j, n - i))\n","\n","\n","            # ======== ДЛЯ КАЖДОГО ЭЛЕМЕНТА БАТЧА ОТДЕЛЬНО ========\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","\n","            # ======== УВЕЛИЧЕНИЕ X4 ========\n","            # n = states.shape[-1] - 1\n","            # i, j = actions[:, 0], actions[:, 1]\n","\n","            # states = np.concatenate([np.rot90(states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # next_states = np.concatenate([np.rot90(next_states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # actions = np.concatenate([actions,\n","            #                           np.column_stack((n - j, i)),\n","            #                           np.column_stack((n - i, n - j)),\n","            #                           np.column_stack((j, n - i))], axis=0)\n","            # rewards = np.tile(rewards, 4)\n","            # dones = np.tile(dones, 4)\n","\n","        return states, actions, rewards, next_states, dones"]},{"cell_type":"code","source":["# =========== Prioritized Replay Buffer With Augmentation ===========\n","class PrioritizedBuffer(object):\n","    def __init__(self, capacity, prob_alpha=0.6):\n","        self.prob_alpha = prob_alpha\n","        self.capacity = capacity\n","        self.buffer = []\n","        self.pos = 0\n","        self.priorities = np.zeros((capacity,), dtype=np.float32)\n","\n","    def add(self, state, action, reward, next_state, done):\n","        max_prio = self.priorities.max() if self.buffer else 1.0\n","\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append((state, action, reward, next_state, done))\n","        else:\n","            self.buffer[self.pos] = (state, action, reward, next_state, done)\n","\n","        self.priorities[self.pos] = max_prio\n","        self.pos = (self.pos + 1) % self.capacity\n","\n","    def sample(self, batch_size, beta=0.4, augmentation=False):\n","        if len(self.buffer) == self.capacity:\n","            prios = self.priorities\n","        else:\n","            prios = self.priorities[:self.pos]\n","\n","        probs  = prios ** self.prob_alpha\n","        probs /= probs.sum()\n","\n","        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n","        samples = [self.buffer[idx] for idx in indices]\n","\n","        total    = len(self.buffer)\n","        weights  = (total * probs[indices]) ** (-beta)\n","        weights /= weights.max()\n","        weights  = np.array(weights, dtype=np.float32)\n","\n","        states, actions, rewards, next_states, dones = zip(*samples)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","        return states, actions, rewards, next_states, dones, indices, weights\n","\n","    def update_priorities(self, batch_indices, batch_priorities):\n","        for idx, prio in zip(batch_indices, batch_priorities):\n","            self.priorities[idx] = prio\n","\n","    def __len__(self):\n","        return len(self.buffer)"],"metadata":{"id":"RYidASkNW5XC","executionInfo":{"status":"ok","timestamp":1718573178166,"user_tz":-180,"elapsed":7,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32ujexFHKgAU"},"source":["#Функции и гиперпараметры для обучения"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZWj7D_iuy3oT","executionInfo":{"status":"ok","timestamp":1718573178167,"user_tz":-180,"elapsed":7,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed);"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"rRFnHMHaC7um","executionInfo":{"status":"ok","timestamp":1718573178167,"user_tz":-180,"elapsed":7,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["board_size = 7\n","win_size = 5"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"T_gPKyIB504V","executionInfo":{"status":"ok","timestamp":1718576664216,"user_tz":-180,"elapsed":342,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["# Гиперпараметры метода DQN\n","\n","batch_size = 128        # 512 - много\n","total_steps = 120_000\n","\n","decay_steps = 110_000\n","init_epsilon = 1\n","final_epsilon = 0.05     # 0.02 - мало; 0.1 - мало\n","\n","loss_freq = 100\n","refresh_target_network_freq = 100    # 1000 - много, 50 - мало\n","\n","eval_freq = 500\n","n_eval_games = 100\n","\n","max_grad_norm = 50\n","\n","gamma = 0.9"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AuZM4BiVn_8X","executionInfo":{"status":"ok","timestamp":1718573181938,"user_tz":-180,"elapsed":3777,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["agent = DQNAgent(init_epsilon).to(device)\n","\n","target_network = DQNAgent(init_epsilon).to(device)\n","target_network.load_state_dict(agent.state_dict())\n","\n","optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n","exp_replay = PrioritizedBuffer(16_000) #ReplayBuffer(16_000)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718573181938,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"-ZJT-NWjTE9g","outputId":"7fa1b7b0-32c8-4060-a4e9-396624cd88da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1189633"]},"metadata":{},"execution_count":13}],"source":["sum([p.numel() for p in agent.parameters()])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cKGcoDrQCzXi","executionInfo":{"status":"ok","timestamp":1718573181938,"user_tz":-180,"elapsed":5,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["# Возвращает temporal difference loss\n","def compute_td_loss(states, actions, rewards, next_states, dones,\n","                    agent, target_network, weights=None, indices=None,    #exp_replay\n","                    gamma=0.9, device=device, prioritized=False):\n","\n","    states = torch.tensor(states, device=device, dtype=torch.float32)                # shape: [batch_size, state_dim]\n","    actions = torch.tensor(actions, device=device, dtype=torch.int64)                # shape: [batch_size]\n","    rewards = torch.tensor(rewards, device=device, dtype=torch.float32)              # shape: [batch_size]\n","    next_states = torch.tensor(next_states, device=device, dtype=torch.float32)      # shape: [batch_size, state_dim]\n","    dones = torch.tensor(dones, device=device, dtype=torch.int64)                    # shape: [batch_size]\n","\n","    predicted_qvalues = agent(states)                                                # shape: [batch_size, n_actions]\n","    predicted_next_qvalues = target_network(next_states)                             # shape: [batch_size, n_actions]\n","    predicted_qvalues_for_actions = predicted_qvalues[range(len(actions)), actions[:, 0], actions[:, 1]]  # shape: [batch_size]\n","    next_state_values = predicted_next_qvalues.view(dones.shape[0], -1).max(axis=1).values\n","    target_qvalues_for_actions = rewards - (1 - dones) * gamma * next_state_values\n","\n","    if prioritized:   #[Prioterized DQN]\n","        weights = torch.tensor(weights, device=device, dtype=torch.float32)\n","        loss = weights * (predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2\n","        prios = (loss + 1e-5).data.cpu().numpy()  # Обновление приоритетов\n","        loss = torch.mean(loss)\n","        exp_replay.update_priorities(indices, prios)\n","        return loss\n","    else:\n","        return torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)  #loss\n","\n","# Рассчитывает epsilon на текущем шаге step\n","def linear_decay(init_epsilon, final_epsilon, step, decay_steps):\n","    return max(init_epsilon - step * (init_epsilon - final_epsilon) / decay_steps, final_epsilon)"]},{"cell_type":"markdown","metadata":{"id":"e73vABV6cKH2"},"source":["# Обучение"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"IigXAGYNdoU7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718573200536,"user_tz":-180,"elapsed":18059,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}},"outputId":"9ebc8af7-bfd4-40bc-9eea-5961752cde81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"GVtRXPFnZ1ug","executionInfo":{"status":"ok","timestamp":1718573200536,"user_tz":-180,"elapsed":5,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"D4mXgvfVsN-2","executionInfo":{"status":"ok","timestamp":1718573200536,"user_tz":-180,"elapsed":4,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["PATH = f'/content/drive/MyDrive/TicTacToe_8/'\n","\n","loss = None\n","loss_values = []\n","reward_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SSNH2zNO3fVB","outputId":"73462184-5d2c-4eee-d9f7-76e8a5321722","executionInfo":{"status":"error","timestamp":1718537441803,"user_tz":-180,"elapsed":38772,"user":{"displayName":"Максим","userId":"06345938587030347437"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 0    \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 100  \t loss = 0.0014503456186503172\t eps = 0.9992\n","t = 200  \t loss = 0.0025754813104867935\t eps = 0.9984\n","t = 300  \t loss = 0.005845450796186924\t eps = 0.9976\n","t = 400  \t loss = 0.00960560329258442\t eps = 0.9968\n","t = 500  \t loss = 0.006231207400560379\t eps = 0.996\n","t = 500  \t reward = -0.98\t{'DQNAgent': 1, 'RandomPlus': 99}\n","\n","t = 600  \t loss = 0.007771224714815617\t eps = 0.9952\n","t = 700  \t loss = 0.004004349932074547\t eps = 0.9944\n","t = 800  \t loss = 0.006096098106354475\t eps = 0.9936\n","t = 900  \t loss = 0.0032341827172785997\t eps = 0.9928\n","t = 1000 \t loss = 0.004183352924883366\t eps = 0.992\n","t = 1000 \t reward = -0.84\t{'DQNAgent': 8, 'RandomPlus': 92}\n","\n","t = 1100 \t loss = 0.0025476980954408646\t eps = 0.9912\n","t = 1200 \t loss = 0.007859527133405209\t eps = 0.9904\n","t = 1300 \t loss = 0.0032840995118021965\t eps = 0.9896\n","t = 1400 \t loss = 0.002489143516868353\t eps = 0.9888\n","t = 1500 \t loss = 0.0023776970338076353\t eps = 0.988\n","t = 1500 \t reward = -0.78\t{'DQNAgent': 11, 'RandomPlus': 89}\n","\n","t = 1600 \t loss = 0.0023639672435820103\t eps = 0.9872\n","t = 1700 \t loss = 0.0037926603108644485\t eps = 0.9864\n","t = 1800 \t loss = 0.0025749458000063896\t eps = 0.9856\n","t = 1900 \t loss = 0.004088329151272774\t eps = 0.9848\n","t = 2000 \t loss = 0.0033075199462473392\t eps = 0.984\n","t = 2000 \t reward = -0.56\t{'DQNAgent': 22, 'RandomPlus': 78}\n","\n","t = 2100 \t loss = 0.005417726933956146\t eps = 0.9832\n","t = 2200 \t loss = 0.0030919737182557583\t eps = 0.9824\n","t = 2300 \t loss = 0.002739183371886611\t eps = 0.9816\n","t = 2400 \t loss = 0.0028580017387866974\t eps = 0.9808\n","t = 2500 \t loss = 0.0036841556429862976\t eps = 0.98\n","t = 2500 \t reward = -0.72\t{'DQNAgent': 14, 'RandomPlus': 86}\n","\n","t = 2600 \t loss = 0.003385819960385561\t eps = 0.9792\n","t = 2700 \t loss = 0.004759090021252632\t eps = 0.9784\n","t = 2800 \t loss = 0.002591341035440564\t eps = 0.9776\n","t = 2900 \t loss = 0.0045974054373800755\t eps = 0.9768\n","t = 3000 \t loss = 0.003665993455797434\t eps = 0.976\n","t = 3000 \t reward = -0.5\t{'DQNAgent': 25, 'RandomPlus': 75}\n","\n","t = 3100 \t loss = 0.004291248507797718\t eps = 0.9752\n","t = 3200 \t loss = 0.00492504145950079\t eps = 0.9744\n","t = 3300 \t loss = 0.0027039675042033195\t eps = 0.9736\n","t = 3400 \t loss = 0.0059020924381911755\t eps = 0.9728\n","t = 3500 \t loss = 0.003525375621393323\t eps = 0.972\n","t = 3500 \t reward = -0.72\t{'DQNAgent': 14, 'RandomPlus': 86}\n","\n","t = 3600 \t loss = 0.0026157833635807037\t eps = 0.9712\n","t = 3700 \t loss = 0.003617013106122613\t eps = 0.9704\n","t = 3800 \t loss = 0.0026929816231131554\t eps = 0.9696\n","t = 3900 \t loss = 0.003180987201631069\t eps = 0.9688\n","t = 4000 \t loss = 0.005389987491071224\t eps = 0.968\n","t = 4000 \t reward = -0.6\t{'DQNAgent': 20, 'RandomPlus': 80}\n","\n","t = 4100 \t loss = 0.0028661079704761505\t eps = 0.9672\n","t = 4200 \t loss = 0.0034939823672175407\t eps = 0.9664\n","t = 4300 \t loss = 0.003989361226558685\t eps = 0.9656\n","t = 4400 \t loss = 0.004785732366144657\t eps = 0.9648\n","t = 4500 \t loss = 0.005304879508912563\t eps = 0.964\n","t = 4500 \t reward = -0.48\t{'DQNAgent': 26, 'RandomPlus': 74}\n","\n","t = 4600 \t loss = 0.0031466027721762657\t eps = 0.9632\n","t = 4700 \t loss = 0.005194709636271\t eps = 0.9624\n","t = 4800 \t loss = 0.007500443607568741\t eps = 0.9616\n","t = 4900 \t loss = 0.003234792035073042\t eps = 0.9608\n","t = 5000 \t loss = 0.00606008805334568\t eps = 0.96\n","t = 5000 \t reward = -0.62\t{'DQNAgent': 19, 'RandomPlus': 81}\n","\n","t = 5100 \t loss = 0.002471480518579483\t eps = 0.9592\n","t = 5200 \t loss = 0.009812682867050171\t eps = 0.9584\n","t = 5300 \t loss = 0.005833740346133709\t eps = 0.9576\n","t = 5400 \t loss = 0.004549063742160797\t eps = 0.9568\n","t = 5500 \t loss = 0.004727276973426342\t eps = 0.956\n","t = 5500 \t reward = -0.72\t{'DQNAgent': 14, 'RandomPlus': 86}\n","\n","t = 5600 \t loss = 0.007288606837391853\t eps = 0.9552\n","t = 5700 \t loss = 0.003804322797805071\t eps = 0.9544\n","t = 5800 \t loss = 0.007961895316839218\t eps = 0.9536\n","t = 5900 \t loss = 0.003347445745021105\t eps = 0.9528\n","t = 6000 \t loss = 0.002632100135087967\t eps = 0.952\n","t = 6000 \t reward = -0.12\t{'DQNAgent': 44, 'RandomPlus': 56}\n","\n","t = 6100 \t loss = 0.003608560189604759\t eps = 0.9512\n","t = 6200 \t loss = 0.005288358777761459\t eps = 0.9504\n","t = 6300 \t loss = 0.0055108219385147095\t eps = 0.9496\n","t = 6400 \t loss = 0.007519755512475967\t eps = 0.9488\n","t = 6500 \t loss = 0.003693019738420844\t eps = 0.948\n","t = 6500 \t reward = -0.46\t{'DQNAgent': 27, 'RandomPlus': 73}\n","\n","t = 6600 \t loss = 0.004964546766132116\t eps = 0.9472\n","t = 6700 \t loss = 0.005004067439585924\t eps = 0.9464\n","t = 6800 \t loss = 0.011173713952302933\t eps = 0.9456\n","t = 6900 \t loss = 0.003972833044826984\t eps = 0.9448\n","t = 7000 \t loss = 0.004081253428012133\t eps = 0.944\n","t = 7000 \t reward = -0.54\t{'DQNAgent': 23, 'RandomPlus': 77}\n","\n","t = 7100 \t loss = 0.0060869259759783745\t eps = 0.9432\n","t = 7200 \t loss = 0.0084970872849226\t eps = 0.9424\n","t = 7300 \t loss = 0.004695657640695572\t eps = 0.9416\n","t = 7400 \t loss = 0.008287929929792881\t eps = 0.9408\n","t = 7500 \t loss = 0.006324428133666515\t eps = 0.94\n","t = 7500 \t reward = -0.26\t{'DQNAgent': 37, 'RandomPlus': 63}\n","\n","t = 7600 \t loss = 0.009016860276460648\t eps = 0.9392\n","t = 7700 \t loss = 0.00527641037479043\t eps = 0.9384\n","t = 7800 \t loss = 0.004755305591970682\t eps = 0.9376\n","t = 7900 \t loss = 0.009139210917055607\t eps = 0.9368\n","t = 8000 \t loss = 0.011101273819804192\t eps = 0.936\n","t = 8000 \t reward = -0.18\t{'DQNAgent': 41, 'RandomPlus': 59}\n","\n","t = 8100 \t loss = 0.005063575692474842\t eps = 0.9352\n","t = 8200 \t loss = 0.004573714919388294\t eps = 0.9344\n","t = 8300 \t loss = 0.004506557714194059\t eps = 0.9336\n","t = 8400 \t loss = 0.004555088467895985\t eps = 0.9328\n","t = 8500 \t loss = 0.007877044379711151\t eps = 0.932\n","t = 8500 \t reward = -0.4\t{'DQNAgent': 30, 'RandomPlus': 70}\n","\n","t = 8600 \t loss = 0.005932196043431759\t eps = 0.9312\n","t = 8700 \t loss = 0.006208724807947874\t eps = 0.9304\n","t = 8800 \t loss = 0.004775742068886757\t eps = 0.9296\n","t = 8900 \t loss = 0.004096752032637596\t eps = 0.9288\n","t = 9000 \t loss = 0.00526108592748642\t eps = 0.928\n","t = 9000 \t reward = -0.3\t{'DQNAgent': 35, 'RandomPlus': 65}\n","\n","t = 9100 \t loss = 0.0037029110826551914\t eps = 0.9272\n","t = 9200 \t loss = 0.003656940069049597\t eps = 0.9264\n","t = 9300 \t loss = 0.003625071607530117\t eps = 0.9256\n","t = 9400 \t loss = 0.0083770751953125\t eps = 0.9248\n","t = 9500 \t loss = 0.00601918576285243\t eps = 0.924\n","t = 9500 \t reward = -0.16\t{'DQNAgent': 42, 'RandomPlus': 58}\n","\n","t = 9600 \t loss = 0.005467819049954414\t eps = 0.9232\n","t = 9700 \t loss = 0.004559744615107775\t eps = 0.9224\n","t = 9800 \t loss = 0.00807980541139841\t eps = 0.9216\n","t = 9900 \t loss = 0.006130632478743792\t eps = 0.9208\n","t = 10000\t loss = 0.006329297553747892\t eps = 0.92\n","t = 10000\t reward = -0.38\t{'DQNAgent': 31, 'RandomPlus': 69}\n","\n","t = 10100\t loss = 0.00542063731700182\t eps = 0.9192\n","t = 10200\t loss = 0.00579398637637496\t eps = 0.9184\n","t = 10300\t loss = 0.004276911728084087\t eps = 0.9176\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-0a085125a5ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                                    agent, target_network, weights, indices, gamma, prioritized=True)\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36m_no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_no_grad_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# when the gradients do not reside in CPU memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mclip_coef_clamped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevice_grads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBCf9OmtL_6J"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_10000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_10000'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5fe00e9d-58d8-40bf-91bc-39c6a262996f","id":"X6BDukod0IVj"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 10100\t loss = 0.015143396332859993\t eps = 0.8653\n","t = 10200\t loss = 0.012356224469840527\t eps = 0.864\n","t = 10300\t loss = 0.00405209930613637\t eps = 0.8627\n","t = 10400\t loss = 0.0061295730993151665\t eps = 0.8613\n","t = 10500\t loss = 0.00525152450427413\t eps = 0.86\n","t = 10500\t reward = -0.19\t{'DQNAgent': 40, 'RandomPlus': 59}\n","\n","t = 10600\t loss = 0.004989832639694214\t eps = 0.8587\n","t = 10700\t loss = 0.00580214150249958\t eps = 0.8573\n","t = 10800\t loss = 0.005738983396440744\t eps = 0.856\n","t = 10900\t loss = 0.005302464589476585\t eps = 0.8547\n","t = 11000\t loss = 0.005145261995494366\t eps = 0.8533\n","t = 11000\t reward = -0.49\t{'DQNAgent': 25, 'RandomPlus': 74}\n","\n","t = 11100\t loss = 0.004748477600514889\t eps = 0.852\n","t = 11200\t loss = 0.003772490657866001\t eps = 0.8507\n","t = 11300\t loss = 0.0035700856242328882\t eps = 0.8493\n","t = 11400\t loss = 0.005855051800608635\t eps = 0.848\n","t = 11500\t loss = 0.0056157358922064304\t eps = 0.8467\n","t = 11500\t reward = -0.24\t{'DQNAgent': 38, 'RandomPlus': 62}\n","\n","t = 11600\t loss = 0.006583011709153652\t eps = 0.8453\n","t = 11700\t loss = 0.004800731781870127\t eps = 0.844\n","t = 11800\t loss = 0.005803442094475031\t eps = 0.8427\n","t = 11900\t loss = 0.002912885043770075\t eps = 0.8413\n","t = 12000\t loss = 0.006402302999049425\t eps = 0.84\n","t = 12000\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 12100\t loss = 0.007837404496967793\t eps = 0.8387\n","t = 12200\t loss = 0.003707657568156719\t eps = 0.8373\n","t = 12300\t loss = 0.0032561966218054295\t eps = 0.836\n","t = 12400\t loss = 0.042538028210401535\t eps = 0.8347\n","t = 12500\t loss = 0.004115862771868706\t eps = 0.8333\n","t = 12500\t reward = -0.1\t{'DQNAgent': 45, 'RandomPlus': 55}\n","\n","t = 12600\t loss = 0.006045705638825893\t eps = 0.832\n","t = 12700\t loss = 0.005185152404010296\t eps = 0.8307\n","t = 12800\t loss = 0.004519602283835411\t eps = 0.8293\n","t = 12900\t loss = 0.008429481647908688\t eps = 0.828\n","t = 13000\t loss = 0.005012755282223225\t eps = 0.8267\n","t = 13000\t reward = -0.02\t{'DQNAgent': 49, 'RandomPlus': 51}\n","\n","t = 13100\t loss = 0.004007960669696331\t eps = 0.8253\n","t = 13200\t loss = 0.006300676614046097\t eps = 0.824\n","t = 13300\t loss = 0.0030191100668162107\t eps = 0.8227\n","t = 13400\t loss = 0.005468814633786678\t eps = 0.8213\n","t = 13500\t loss = 0.004675410687923431\t eps = 0.82\n","t = 13500\t reward = -0.06\t{'DQNAgent': 47, 'RandomPlus': 53}\n","\n","t = 13600\t loss = 0.0057012648321688175\t eps = 0.8187\n","t = 13700\t loss = 0.004542606882750988\t eps = 0.8173\n","t = 13800\t loss = 0.0035191262140870094\t eps = 0.816\n","t = 13900\t loss = 0.004062694031745195\t eps = 0.8147\n","t = 14000\t loss = 0.006796767003834248\t eps = 0.8133\n","t = 14000\t reward = -0.28\t{'DQNAgent': 36, 'RandomPlus': 64}\n","\n","t = 14100\t loss = 0.007395266089588404\t eps = 0.812\n","t = 14200\t loss = 0.006136476993560791\t eps = 0.8107\n","t = 14300\t loss = 0.005840732250362635\t eps = 0.8093\n","t = 14400\t loss = 0.0037911415565758944\t eps = 0.808\n","t = 14500\t loss = 0.003129187971353531\t eps = 0.8067\n","t = 14500\t reward = 0.04\t{'DQNAgent': 52, 'RandomPlus': 48}\n","\n","t = 14600\t loss = 0.005251477472484112\t eps = 0.8053\n","t = 14700\t loss = 0.0032341782934963703\t eps = 0.804\n","t = 14800\t loss = 0.006414251402020454\t eps = 0.8027\n","t = 14900\t loss = 0.0048326184041798115\t eps = 0.8013\n","t = 15000\t loss = 0.003296859096735716\t eps = 0.8\n","t = 15000\t reward = 0.04\t{'DQNAgent': 52, 'RandomPlus': 48}\n","\n","t = 15100\t loss = 0.005401419010013342\t eps = 0.7987\n","t = 15200\t loss = 0.00458489079028368\t eps = 0.7973\n","t = 15300\t loss = 0.003810590598732233\t eps = 0.796\n","t = 15400\t loss = 0.0031050625257194042\t eps = 0.7947\n","t = 15500\t loss = 0.0036234327126294374\t eps = 0.7933\n","t = 15500\t reward = 0.02\t{'DQNAgent': 51, 'RandomPlus': 49}\n","\n","t = 15600\t loss = 0.005451647564768791\t eps = 0.792\n","t = 15700\t loss = 0.004008319228887558\t eps = 0.7907\n","t = 15800\t loss = 0.0042932117357850075\t eps = 0.7893\n","t = 15900\t loss = 0.0037873091641813517\t eps = 0.788\n","t = 16000\t loss = 0.004150811117142439\t eps = 0.7867\n","t = 16000\t reward = -0.32\t{'DQNAgent': 34, 'RandomPlus': 66}\n","\n","t = 16100\t loss = 0.0034643239341676235\t eps = 0.7853\n","t = 16200\t loss = 0.007792205084115267\t eps = 0.784\n","t = 16300\t loss = 0.0035927710123360157\t eps = 0.7827\n","t = 16400\t loss = 0.006564123556017876\t eps = 0.7813\n","t = 16500\t loss = 0.003418965032324195\t eps = 0.78\n","t = 16500\t reward = -0.46\t{'DQNAgent': 27, 'RandomPlus': 73}\n","\n","t = 16600\t loss = 0.005540957674384117\t eps = 0.7787\n","t = 16700\t loss = 0.003804776119068265\t eps = 0.7773\n","t = 16800\t loss = 0.00876710657030344\t eps = 0.776\n","t = 16900\t loss = 0.00567594263702631\t eps = 0.7747\n","t = 17000\t loss = 0.003653018269687891\t eps = 0.7733\n","t = 17000\t reward = -0.1\t{'DQNAgent': 45, 'RandomPlus': 55}\n","\n","t = 17100\t loss = 0.0080170389264822\t eps = 0.772\n","t = 17200\t loss = 0.0049749379977583885\t eps = 0.7707\n","t = 17300\t loss = 0.004546968266367912\t eps = 0.7693\n","t = 17400\t loss = 0.004404725506901741\t eps = 0.768\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(10_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5LmzhiUPHyj"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_17000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_17000'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3a35479-d34a-4bac-a18c-d57d66133989","id":"tt54ILuYPHyk"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 17100\t loss = None\t eps = 0.772\n","t = 17200\t loss = 0.013053225353360176\t eps = 0.7707\n","t = 17300\t loss = 0.0032226815819740295\t eps = 0.7693\n","t = 17400\t loss = 0.0030869494657963514\t eps = 0.768\n","t = 17500\t loss = 0.0056057944893836975\t eps = 0.7667\n","t = 17500\t reward = -0.07\t{'DQNAgent': 46, 'RandomPlus': 53}\n","\n","t = 17600\t loss = 0.003163502085953951\t eps = 0.7653\n","t = 17700\t loss = 0.005290397442877293\t eps = 0.764\n","t = 17800\t loss = 0.003680925816297531\t eps = 0.7627\n","t = 17900\t loss = 0.006656264886260033\t eps = 0.7613\n","t = 18000\t loss = 0.004775339737534523\t eps = 0.76\n","t = 18000\t reward = -0.08\t{'DQNAgent': 46, 'RandomPlus': 54}\n","\n","t = 18100\t loss = 0.005879539996385574\t eps = 0.7587\n","t = 18200\t loss = 0.008892146870493889\t eps = 0.7573\n","t = 18300\t loss = 0.004732859320938587\t eps = 0.756\n","t = 18400\t loss = 0.005579778924584389\t eps = 0.7547\n","t = 18500\t loss = 0.004977567121386528\t eps = 0.7533\n","t = 18500\t reward = -0.32\t{'DQNAgent': 34, 'RandomPlus': 66}\n","\n","t = 18600\t loss = 0.004779628477990627\t eps = 0.752\n","t = 18700\t loss = 0.00600908137857914\t eps = 0.7507\n","t = 18800\t loss = 0.01188116054981947\t eps = 0.7493\n","t = 18900\t loss = 0.0033827503211796284\t eps = 0.748\n","t = 19000\t loss = 0.008181327022612095\t eps = 0.7467\n","t = 19000\t reward = -0.12\t{'DQNAgent': 44, 'RandomPlus': 56}\n","\n","t = 19100\t loss = 0.005474020726978779\t eps = 0.7453\n","t = 19200\t loss = 0.004336089361459017\t eps = 0.744\n","t = 19300\t loss = 0.005653200671076775\t eps = 0.7427\n","t = 19400\t loss = 0.00617391150444746\t eps = 0.7413\n","t = 19500\t loss = 0.0028009230736643076\t eps = 0.74\n","t = 19500\t reward = -0.36\t{'DQNAgent': 32, 'RandomPlus': 68}\n","\n","t = 19600\t loss = 0.0051456233486533165\t eps = 0.7387\n","t = 19700\t loss = 0.005080907605588436\t eps = 0.7373\n","t = 19800\t loss = 0.005987317301332951\t eps = 0.736\n","t = 19900\t loss = 0.00473042344674468\t eps = 0.7347\n","t = 20000\t loss = 0.004742125049233437\t eps = 0.7333\n","t = 20000\t reward = -0.14\t{'DQNAgent': 43, 'RandomPlus': 57}\n","\n","t = 20100\t loss = 0.005289342254400253\t eps = 0.732\n","t = 20200\t loss = 0.008108902722597122\t eps = 0.7307\n","t = 20300\t loss = 0.008345387876033783\t eps = 0.7293\n","t = 20400\t loss = 0.004648774396628141\t eps = 0.728\n","t = 20500\t loss = 0.0038426192477345467\t eps = 0.7267\n","t = 20500\t reward = -0.31\t{'DQNAgent': 34, 'RandomPlus': 65}\n","\n","t = 20600\t loss = 0.0035211890935897827\t eps = 0.7253\n","t = 20700\t loss = 0.003680883441120386\t eps = 0.724\n","t = 20800\t loss = 0.006583438254892826\t eps = 0.7227\n","t = 20900\t loss = 0.005487419199198484\t eps = 0.7213\n","t = 21000\t loss = 0.005304954946041107\t eps = 0.72\n","t = 21000\t reward = -0.24\t{'DQNAgent': 38, 'RandomPlus': 62}\n","\n","t = 21100\t loss = 0.004407421685755253\t eps = 0.7187\n","t = 21200\t loss = 0.004865186754614115\t eps = 0.7173\n","t = 21300\t loss = 0.0033057774417102337\t eps = 0.716\n","t = 21400\t loss = 0.0035679172724485397\t eps = 0.7147\n","t = 21500\t loss = 0.004645435139536858\t eps = 0.7133\n","t = 21500\t reward = -0.2\t{'DQNAgent': 40, 'RandomPlus': 60}\n","\n","t = 21600\t loss = 0.006179982330650091\t eps = 0.712\n","t = 21700\t loss = 0.009401170536875725\t eps = 0.7107\n","t = 21800\t loss = 0.005616243463009596\t eps = 0.7093\n","t = 21900\t loss = 0.004589899443089962\t eps = 0.708\n","t = 22000\t loss = 0.004390304908156395\t eps = 0.7067\n","t = 22000\t reward = -0.31\t{'DQNAgent': 34, 'RandomPlus': 65}\n","\n","t = 22100\t loss = 0.007245069369673729\t eps = 0.7053\n","t = 22200\t loss = 0.004344172775745392\t eps = 0.704\n","t = 22300\t loss = 0.003411687910556793\t eps = 0.7027\n","t = 22400\t loss = 0.006753984838724136\t eps = 0.7013\n","t = 22500\t loss = 0.0048180874437093735\t eps = 0.7\n","t = 22500\t reward = -0.1\t{'DQNAgent': 45, 'RandomPlus': 55}\n","\n","t = 22600\t loss = 0.003564218059182167\t eps = 0.6987\n","t = 22700\t loss = 0.005464027635753155\t eps = 0.6973\n","t = 22800\t loss = 0.005698629654943943\t eps = 0.696\n","t = 22900\t loss = 0.005756491795182228\t eps = 0.6947\n","t = 23000\t loss = 0.004227131605148315\t eps = 0.6933\n","t = 23000\t reward = 0.12\t{'DQNAgent': 56, 'RandomPlus': 44}\n","\n","t = 23100\t loss = 0.004087244160473347\t eps = 0.692\n","t = 23200\t loss = 0.0058398256078362465\t eps = 0.6907\n","t = 23300\t loss = 0.0030668023973703384\t eps = 0.6893\n","t = 23400\t loss = 0.004201773554086685\t eps = 0.688\n","t = 23500\t loss = 0.003982933238148689\t eps = 0.6867\n","t = 23500\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 23600\t loss = 0.0071285320445895195\t eps = 0.6853\n","t = 23700\t loss = 0.0033695362508296967\t eps = 0.684\n","t = 23800\t loss = 0.0057305945083498955\t eps = 0.6827\n","t = 23900\t loss = 0.006340968422591686\t eps = 0.6813\n","t = 24000\t loss = 0.0041921380907297134\t eps = 0.68\n","t = 24000\t reward = -0.02\t{'DQNAgent': 49, 'RandomPlus': 51}\n","\n","t = 24100\t loss = 0.005390242673456669\t eps = 0.6787\n","t = 24200\t loss = 0.006513563916087151\t eps = 0.6773\n","t = 24300\t loss = 0.004119500517845154\t eps = 0.676\n","t = 24400\t loss = 0.00430432939901948\t eps = 0.6747\n","t = 24500\t loss = 0.0036467802710831165\t eps = 0.6733\n","t = 24500\t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 24600\t loss = 0.005022669211030006\t eps = 0.672\n","t = 24700\t loss = 0.004120564088225365\t eps = 0.6707\n","t = 24800\t loss = 0.0065340157598257065\t eps = 0.6693\n","t = 24900\t loss = 0.006301280111074448\t eps = 0.668\n","t = 25000\t loss = 0.0047354199923574924\t eps = 0.6667\n","t = 25000\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 25100\t loss = 0.004978593438863754\t eps = 0.6653\n","t = 25200\t loss = 0.004971204791218042\t eps = 0.664\n","t = 25300\t loss = 0.003357456997036934\t eps = 0.6627\n","t = 25400\t loss = 0.0032259051222354174\t eps = 0.6613\n","t = 25500\t loss = 0.003475464414805174\t eps = 0.66\n","t = 25500\t reward = -0.02\t{'DQNAgent': 49, 'RandomPlus': 51}\n","\n","t = 25600\t loss = 0.005003557540476322\t eps = 0.6587\n","t = 25700\t loss = 0.004987658001482487\t eps = 0.6573\n","t = 25800\t loss = 0.004238460212945938\t eps = 0.656\n","t = 25900\t loss = 0.004424558952450752\t eps = 0.6547\n","t = 26000\t loss = 0.004518414847552776\t eps = 0.6533\n","t = 26000\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 26100\t loss = 0.006209241226315498\t eps = 0.652\n","t = 26200\t loss = 0.004882422741502523\t eps = 0.6507\n","t = 26300\t loss = 0.004960270598530769\t eps = 0.6493\n","t = 26400\t loss = 0.004603242035955191\t eps = 0.648\n","t = 26500\t loss = 0.006168542429804802\t eps = 0.6467\n","t = 26500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 26600\t loss = 0.005089455284178257\t eps = 0.6453\n","t = 26700\t loss = 0.0037497361190617085\t eps = 0.644\n","t = 26800\t loss = 0.004609330557286739\t eps = 0.6427\n","t = 26900\t loss = 0.005191303789615631\t eps = 0.6413\n","t = 27000\t loss = 0.005160396918654442\t eps = 0.64\n","t = 27000\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 27100\t loss = 0.003522431245073676\t eps = 0.6387\n","t = 27200\t loss = 0.003474701661616564\t eps = 0.6373\n","t = 27300\t loss = 0.0047098505310714245\t eps = 0.636\n","t = 27400\t loss = 0.0031690788455307484\t eps = 0.6347\n","t = 27500\t loss = 0.005467175040394068\t eps = 0.6333\n","t = 27500\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 27600\t loss = 0.0044713690876960754\t eps = 0.632\n","t = 27700\t loss = 0.005252987612038851\t eps = 0.6307\n","t = 27800\t loss = 0.0031615695916116238\t eps = 0.6293\n","t = 27900\t loss = 0.009870938956737518\t eps = 0.628\n","t = 28000\t loss = 0.005797854159027338\t eps = 0.6267\n","t = 28000\t reward = 0.12\t{'DQNAgent': 56, 'RandomPlus': 44}\n","\n","t = 28100\t loss = 0.004180728457868099\t eps = 0.6253\n","t = 28200\t loss = 0.004172047134488821\t eps = 0.624\n","t = 28300\t loss = 0.00378437340259552\t eps = 0.6227\n","t = 28400\t loss = 0.005304461345076561\t eps = 0.6213\n","t = 28500\t loss = 0.0038327304646372795\t eps = 0.62\n","t = 28500\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 28600\t loss = 0.0032696258276700974\t eps = 0.6187\n","t = 28700\t loss = 0.004277259111404419\t eps = 0.6173\n","t = 28800\t loss = 0.003432520665228367\t eps = 0.616\n","t = 28900\t loss = 0.004348959308117628\t eps = 0.6147\n","t = 29000\t loss = 0.0037338794209063053\t eps = 0.6133\n","t = 29000\t reward = 0.14\t{'DQNAgent': 57, 'RandomPlus': 43}\n","\n","t = 29100\t loss = 0.0056831021793186665\t eps = 0.612\n","t = 29200\t loss = 0.003540493082255125\t eps = 0.6107\n","t = 29300\t loss = 0.005619233939796686\t eps = 0.6093\n","t = 29400\t loss = 0.004979359917342663\t eps = 0.608\n","t = 29500\t loss = 0.004453113302588463\t eps = 0.6067\n","t = 29500\t reward = -0.04\t{'DQNAgent': 48, 'RandomPlus': 52}\n","\n","t = 29600\t loss = 0.004798585083335638\t eps = 0.6053\n","t = 29700\t loss = 0.0029108289163559675\t eps = 0.604\n","t = 29800\t loss = 0.005823095329105854\t eps = 0.6027\n","t = 29900\t loss = 0.004835813771933317\t eps = 0.6013\n","t = 30000\t loss = 0.004698478151112795\t eps = 0.6\n","t = 30000\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 30100\t loss = 0.0035461666993796825\t eps = 0.5987\n","t = 30200\t loss = 0.004807417746633291\t eps = 0.5973\n","t = 30300\t loss = 0.005625723861157894\t eps = 0.596\n","t = 30400\t loss = 0.0034223641268908978\t eps = 0.5947\n","t = 30500\t loss = 0.00555787980556488\t eps = 0.5933\n","t = 30500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 30600\t loss = 0.004357447847723961\t eps = 0.592\n","t = 30700\t loss = 0.0037873515393584967\t eps = 0.5907\n","t = 30800\t loss = 0.00482171680778265\t eps = 0.5893\n","t = 30900\t loss = 0.004801384173333645\t eps = 0.588\n","t = 31000\t loss = 0.0038607532624155283\t eps = 0.5867\n","t = 31000\t reward = 0.2\t{'DQNAgent': 60, 'RandomPlus': 40}\n","\n","t = 31100\t loss = 0.0032974076457321644\t eps = 0.5853\n","t = 31200\t loss = 0.0032789050601422787\t eps = 0.584\n","t = 31300\t loss = 0.006771717686206102\t eps = 0.5827\n","t = 31400\t loss = 0.004026106093078852\t eps = 0.5813\n","t = 31500\t loss = 0.007410241290926933\t eps = 0.58\n","t = 31500\t reward = -0.16\t{'DQNAgent': 42, 'RandomPlus': 58}\n","\n","t = 31600\t loss = 0.003070770762860775\t eps = 0.5787\n","t = 31700\t loss = 0.0044710636138916016\t eps = 0.5773\n","t = 31800\t loss = 0.004640354309231043\t eps = 0.576\n","t = 31900\t loss = 0.0034776050597429276\t eps = 0.5747\n","t = 32000\t loss = 0.0035798714961856604\t eps = 0.5733\n","t = 32000\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 32100\t loss = 0.005619402043521404\t eps = 0.572\n","t = 32200\t loss = 0.006030591204762459\t eps = 0.5707\n","t = 32300\t loss = 0.005125593394041061\t eps = 0.5693\n","t = 32400\t loss = 0.00494256429374218\t eps = 0.568\n","t = 32500\t loss = 0.006830780301243067\t eps = 0.5667\n","t = 32500\t reward = -0.08\t{'DQNAgent': 46, 'RandomPlus': 54}\n","\n","t = 32600\t loss = 0.004460796248167753\t eps = 0.5653\n","t = 32700\t loss = 0.00626245466992259\t eps = 0.564\n","t = 32800\t loss = 0.006008273921906948\t eps = 0.5627\n","t = 32900\t loss = 0.004528790712356567\t eps = 0.5613\n","t = 33000\t loss = 0.003674143459647894\t eps = 0.56\n","t = 33000\t reward = 0.14\t{'DQNAgent': 57, 'RandomPlus': 43}\n","\n","t = 33100\t loss = 0.0034819254651665688\t eps = 0.5587\n","t = 33200\t loss = 0.00356303621083498\t eps = 0.5573\n","t = 33300\t loss = 0.004252738319337368\t eps = 0.556\n","t = 33400\t loss = 0.003377978689968586\t eps = 0.5547\n","t = 33500\t loss = 0.0031227299477905035\t eps = 0.5533\n","t = 33500\t reward = 0.24\t{'DQNAgent': 62, 'RandomPlus': 38}\n","\n","t = 33600\t loss = 0.0036542536690831184\t eps = 0.552\n","t = 33700\t loss = 0.005708128213882446\t eps = 0.5507\n","t = 33800\t loss = 0.006701153703033924\t eps = 0.5493\n","t = 33900\t loss = 0.005348778795450926\t eps = 0.548\n","t = 34000\t loss = 0.0044727623462677\t eps = 0.5467\n","t = 34000\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 34100\t loss = 0.003642497817054391\t eps = 0.5453\n","t = 34200\t loss = 0.003612127620726824\t eps = 0.544\n","t = 34300\t loss = 0.005108183715492487\t eps = 0.5427\n","t = 34400\t loss = 0.0034112255088984966\t eps = 0.5413\n","t = 34500\t loss = 0.004130610730499029\t eps = 0.54\n","t = 34500\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 34600\t loss = 0.003749227151274681\t eps = 0.5387\n","t = 34700\t loss = 0.006241661496460438\t eps = 0.5373\n","t = 34800\t loss = 0.013281220570206642\t eps = 0.536\n","t = 34900\t loss = 0.005025902763009071\t eps = 0.5347\n","t = 35000\t loss = 0.004183538258075714\t eps = 0.5333\n","t = 35000\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 35100\t loss = 0.003724236972630024\t eps = 0.532\n","t = 35200\t loss = 0.005118438042700291\t eps = 0.5307\n","t = 35300\t loss = 0.0067230635322630405\t eps = 0.5293\n","t = 35400\t loss = 0.0036911412607878447\t eps = 0.528\n","t = 35500\t loss = 0.004751621279865503\t eps = 0.5267\n","t = 35500\t reward = -0.08\t{'DQNAgent': 46, 'RandomPlus': 54}\n","\n","t = 35600\t loss = 0.0033662975765764713\t eps = 0.5253\n","t = 35700\t loss = 0.003337824484333396\t eps = 0.524\n","t = 35800\t loss = 0.004974530544131994\t eps = 0.5227\n","t = 35900\t loss = 0.0042913793586194515\t eps = 0.5213\n","t = 36000\t loss = 0.004018428269773722\t eps = 0.52\n","t = 36000\t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 36100\t loss = 0.006008915603160858\t eps = 0.5187\n","t = 36200\t loss = 0.004395248368382454\t eps = 0.5173\n","t = 36300\t loss = 0.0046892608515918255\t eps = 0.516\n","t = 36400\t loss = 0.0036066086031496525\t eps = 0.5147\n","t = 36500\t loss = 0.008356955833733082\t eps = 0.5133\n","t = 36500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 36600\t loss = 0.0035109431482851505\t eps = 0.512\n","t = 36700\t loss = 0.004848765209317207\t eps = 0.5107\n","t = 36800\t loss = 0.0029911338351666927\t eps = 0.5093\n","t = 36900\t loss = 0.0050101918168365955\t eps = 0.508\n","t = 37000\t loss = 0.004735417198389769\t eps = 0.5067\n","t = 37000\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 37100\t loss = 0.0036708866246044636\t eps = 0.5053\n","t = 37200\t loss = 0.004105098079890013\t eps = 0.504\n","t = 37300\t loss = 0.004860229324549437\t eps = 0.5027\n","t = 37400\t loss = 0.005327858030796051\t eps = 0.5013\n","t = 37500\t loss = 0.0035942550748586655\t eps = 0.5\n","t = 37500\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 37600\t loss = 0.003964637406170368\t eps = 0.4987\n","t = 37700\t loss = 0.005285271443426609\t eps = 0.4973\n","t = 37800\t loss = 0.004116467200219631\t eps = 0.496\n","t = 37900\t loss = 0.004933014512062073\t eps = 0.4947\n","t = 38000\t loss = 0.004523354582488537\t eps = 0.4933\n","t = 38000\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 38100\t loss = 0.004862081725150347\t eps = 0.492\n","t = 38200\t loss = 0.0038824514485895634\t eps = 0.4907\n","t = 38300\t loss = 0.0038928170688450336\t eps = 0.4893\n","t = 38400\t loss = 0.004778712056577206\t eps = 0.488\n","t = 38500\t loss = 0.005253729410469532\t eps = 0.4867\n","t = 38500\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 38600\t loss = 0.005292356945574284\t eps = 0.4853\n","t = 38700\t loss = 0.005630464758723974\t eps = 0.484\n","t = 38800\t loss = 0.0027058429550379515\t eps = 0.4827\n","t = 38900\t loss = 0.007398869842290878\t eps = 0.4813\n","t = 39000\t loss = 0.006763107143342495\t eps = 0.48\n","t = 39000\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 39100\t loss = 0.004599623382091522\t eps = 0.4787\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(17_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vo1i-TNLpFNU"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_39000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_39000'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dea993ca-ca19-49d5-f086-0df346cab665","id":"XLenWgOnpFNV"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 39100\t loss = None\t eps = 0.4787\n","t = 39200\t loss = 0.0037698177620768547\t eps = 0.4773\n","t = 39300\t loss = 0.0030763777904212475\t eps = 0.476\n","t = 39400\t loss = 0.001814821269363165\t eps = 0.4747\n","t = 39500\t loss = 0.003513412084430456\t eps = 0.4733\n","t = 39500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 39600\t loss = 0.0028121585492044687\t eps = 0.472\n","t = 39700\t loss = 0.008978449739515781\t eps = 0.4707\n","t = 39800\t loss = 0.0027770744636654854\t eps = 0.4693\n","t = 39900\t loss = 0.004383034072816372\t eps = 0.468\n","t = 40000\t loss = 0.003285860875621438\t eps = 0.4667\n","t = 40000\t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 40100\t loss = 0.003897226881235838\t eps = 0.4653\n","t = 40200\t loss = 0.004303330089896917\t eps = 0.464\n","t = 40300\t loss = 0.0052237012423574924\t eps = 0.4627\n","t = 40400\t loss = 0.004812898114323616\t eps = 0.4613\n","t = 40500\t loss = 0.005868859589099884\t eps = 0.46\n","t = 40500\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 40600\t loss = 0.005282066762447357\t eps = 0.4587\n","t = 40700\t loss = 0.003891750704497099\t eps = 0.4573\n","t = 40800\t loss = 0.003851438406854868\t eps = 0.456\n","t = 40900\t loss = 0.005133898463100195\t eps = 0.4547\n","t = 41000\t loss = 0.003683259477838874\t eps = 0.4533\n","t = 41000\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 41100\t loss = 0.0041572218760848045\t eps = 0.452\n","t = 41200\t loss = 0.00591383408755064\t eps = 0.4507\n","t = 41300\t loss = 0.003509399015456438\t eps = 0.4493\n","t = 41400\t loss = 0.0034799438435584307\t eps = 0.448\n","t = 41500\t loss = 0.006019843742251396\t eps = 0.4467\n","t = 41500\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 41600\t loss = 0.004131228197365999\t eps = 0.4453\n","t = 41700\t loss = 0.004973427392542362\t eps = 0.444\n","t = 41800\t loss = 0.003725398099049926\t eps = 0.4427\n","t = 41900\t loss = 0.003946129232645035\t eps = 0.4413\n","t = 42000\t loss = 0.003282388672232628\t eps = 0.44\n","t = 42000\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 42100\t loss = 0.004378798417747021\t eps = 0.4387\n","t = 42200\t loss = 0.007705883122980595\t eps = 0.4373\n","t = 42300\t loss = 0.005117393564432859\t eps = 0.436\n","t = 42400\t loss = 0.0036113280802965164\t eps = 0.4347\n","t = 42500\t loss = 0.004970897920429707\t eps = 0.4333\n","t = 42500\t reward = 0.16\t{'DQNAgent': 58, 'RandomPlus': 42}\n","\n","t = 42600\t loss = 0.005027366802096367\t eps = 0.432\n","t = 42700\t loss = 0.0052248211577534676\t eps = 0.4307\n","t = 42800\t loss = 0.004207497462630272\t eps = 0.4293\n","t = 42900\t loss = 0.004852687008678913\t eps = 0.428\n","t = 43000\t loss = 0.005310786422342062\t eps = 0.4267\n","t = 43000\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 43100\t loss = 0.0023077281657606363\t eps = 0.4253\n","t = 43200\t loss = 0.005189830437302589\t eps = 0.424\n","t = 43300\t loss = 0.005251866765320301\t eps = 0.4227\n","t = 43400\t loss = 0.008368529379367828\t eps = 0.4213\n","t = 43500\t loss = 0.0035284082405269146\t eps = 0.42\n","t = 43500\t reward = 0.24\t{'DQNAgent': 62, 'RandomPlus': 38}\n","\n","t = 43600\t loss = 0.006571594160050154\t eps = 0.4187\n","t = 43700\t loss = 0.004929971415549517\t eps = 0.4173\n","t = 43800\t loss = 0.003555144416168332\t eps = 0.416\n","t = 43900\t loss = 0.007234181743115187\t eps = 0.4147\n","t = 44000\t loss = 0.00506365392357111\t eps = 0.4133\n","t = 44000\t reward = 0.06\t{'DQNAgent': 53, 'RandomPlus': 47}\n","\n","t = 44100\t loss = 0.004724988713860512\t eps = 0.412\n","t = 44200\t loss = 0.0045443130657076836\t eps = 0.4107\n","t = 44300\t loss = 0.0058275493793189526\t eps = 0.4093\n","t = 44400\t loss = 0.004012195393443108\t eps = 0.408\n","t = 44500\t loss = 0.004718805197626352\t eps = 0.4067\n","t = 44500\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 44600\t loss = 0.00530230812728405\t eps = 0.4053\n","t = 44700\t loss = 0.003174389712512493\t eps = 0.404\n","t = 44800\t loss = 0.004535394720733166\t eps = 0.4027\n","t = 44900\t loss = 0.006417592987418175\t eps = 0.4013\n","t = 45000\t loss = 0.004799641668796539\t eps = 0.4\n","t = 45000\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 45100\t loss = 0.005100663285702467\t eps = 0.3987\n","t = 45200\t loss = 0.007661863695830107\t eps = 0.3973\n","t = 45300\t loss = 0.006174107082188129\t eps = 0.396\n","t = 45400\t loss = 0.0045729028061032295\t eps = 0.3947\n","t = 45500\t loss = 0.0046647461131215096\t eps = 0.3933\n","t = 45500\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 45600\t loss = 0.003911265172064304\t eps = 0.392\n","t = 45700\t loss = 0.004900916013866663\t eps = 0.3907\n","t = 45800\t loss = 0.004958300851285458\t eps = 0.3893\n","t = 45900\t loss = 0.005398239940404892\t eps = 0.388\n","t = 46000\t loss = 0.005853123962879181\t eps = 0.3867\n","t = 46000\t reward = 0.2\t{'DQNAgent': 60, 'RandomPlus': 40}\n","\n","t = 46100\t loss = 0.005262803751975298\t eps = 0.3853\n","t = 46200\t loss = 0.0033700393978506327\t eps = 0.384\n","t = 46300\t loss = 0.004821037407964468\t eps = 0.3827\n","t = 46400\t loss = 0.004713709466159344\t eps = 0.3813\n","t = 46500\t loss = 0.00653834966942668\t eps = 0.38\n","t = 46500\t reward = 0.26\t{'DQNAgent': 63, 'RandomPlus': 37}\n","\n","t = 46600\t loss = 0.005112224258482456\t eps = 0.3787\n","t = 46700\t loss = 0.003352829720824957\t eps = 0.3773\n","t = 46800\t loss = 0.0037550493143498898\t eps = 0.376\n","t = 46900\t loss = 0.006587544921785593\t eps = 0.3747\n","t = 47000\t loss = 0.004266100935637951\t eps = 0.3733\n","t = 47000\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 47100\t loss = 0.005628739949315786\t eps = 0.372\n","t = 47200\t loss = 0.005692079663276672\t eps = 0.3707\n","t = 47300\t loss = 0.005782539956271648\t eps = 0.3693\n","t = 47400\t loss = 0.005506602115929127\t eps = 0.368\n","t = 47500\t loss = 0.0039416104555130005\t eps = 0.3667\n","t = 47500\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 47600\t loss = 0.004852111451327801\t eps = 0.3653\n","t = 47700\t loss = 0.004068455658853054\t eps = 0.364\n","t = 47800\t loss = 0.003938743378967047\t eps = 0.3627\n","t = 47900\t loss = 0.006024676375091076\t eps = 0.3613\n","t = 48000\t loss = 0.005850168876349926\t eps = 0.36\n","t = 48000\t reward = 0.43\t{'DQNAgent': 71, 'RandomPlus': 28}\n","\n","t = 48100\t loss = 0.00493986438959837\t eps = 0.3587\n","t = 48200\t loss = 0.004903591237962246\t eps = 0.3573\n","t = 48300\t loss = 0.004173870664089918\t eps = 0.356\n","t = 48400\t loss = 0.00485591497272253\t eps = 0.3547\n","t = 48500\t loss = 0.004112645052373409\t eps = 0.3533\n","t = 48500\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 48600\t loss = 0.005013433285057545\t eps = 0.352\n","t = 48700\t loss = 0.004364998545497656\t eps = 0.3507\n","t = 48800\t loss = 0.0036557293497025967\t eps = 0.3493\n","t = 48900\t loss = 0.003913704305887222\t eps = 0.348\n","t = 49000\t loss = 0.004319543018937111\t eps = 0.3467\n","t = 49000\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 49100\t loss = 0.005103300325572491\t eps = 0.3453\n","t = 49200\t loss = 0.005104330368340015\t eps = 0.344\n","t = 49300\t loss = 0.00798974372446537\t eps = 0.3427\n","t = 49400\t loss = 0.003195094410330057\t eps = 0.3413\n","t = 49500\t loss = 0.009490386582911015\t eps = 0.34\n","t = 49500\t reward = 0.35\t{'DQNAgent': 67, 'RandomPlus': 32}\n","\n","t = 49600\t loss = 0.004058321472257376\t eps = 0.3387\n","t = 49700\t loss = 0.004396898206323385\t eps = 0.3373\n","t = 49800\t loss = 0.0042746299877762794\t eps = 0.336\n","t = 49900\t loss = 0.004490239545702934\t eps = 0.3347\n","t = 50000\t loss = 0.008055612444877625\t eps = 0.3333\n","t = 50000\t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 50100\t loss = 0.0044389949180185795\t eps = 0.332\n","t = 50200\t loss = 0.004891048651188612\t eps = 0.3307\n","t = 50300\t loss = 0.004656626842916012\t eps = 0.3293\n","t = 50400\t loss = 0.00389698869548738\t eps = 0.328\n","t = 50500\t loss = 0.004681726917624474\t eps = 0.3267\n","t = 50500\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 50600\t loss = 0.004312482662498951\t eps = 0.3253\n","t = 50700\t loss = 0.005898676812648773\t eps = 0.324\n","t = 50800\t loss = 0.004030809737741947\t eps = 0.3227\n","t = 50900\t loss = 0.007387749385088682\t eps = 0.3213\n","t = 51000\t loss = 0.005097553599625826\t eps = 0.32\n","t = 51000\t reward = 0.49\t{'DQNAgent': 74, 'RandomPlus': 25}\n","\n","t = 51100\t loss = 0.0071331895887851715\t eps = 0.3187\n","t = 51200\t loss = 0.005735810846090317\t eps = 0.3173\n","t = 51300\t loss = 0.005629051476716995\t eps = 0.316\n","t = 51400\t loss = 0.003462571185082197\t eps = 0.3147\n","t = 51500\t loss = 0.004595177248120308\t eps = 0.3133\n","t = 51500\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 51600\t loss = 0.0032288790680468082\t eps = 0.312\n","t = 51700\t loss = 0.0038020687643438578\t eps = 0.3107\n","t = 51800\t loss = 0.004193545784801245\t eps = 0.3093\n","t = 51900\t loss = 0.008316959254443645\t eps = 0.308\n","t = 52000\t loss = 0.005281185265630484\t eps = 0.3067\n","t = 52000\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 52100\t loss = 0.004758384544402361\t eps = 0.3053\n","t = 52200\t loss = 0.004000336397439241\t eps = 0.304\n","t = 52300\t loss = 0.004553554579615593\t eps = 0.3027\n","t = 52400\t loss = 0.005156788043677807\t eps = 0.3013\n","t = 52500\t loss = 0.005006646271795034\t eps = 0.3\n","t = 52500\t reward = 0.26\t{'DQNAgent': 63, 'RandomPlus': 37}\n","\n","t = 52600\t loss = 0.003975565545260906\t eps = 0.2987\n","t = 52700\t loss = 0.0034151021391153336\t eps = 0.2973\n","t = 52800\t loss = 0.0047548674046993256\t eps = 0.296\n","t = 52900\t loss = 0.004166801460087299\t eps = 0.2947\n","t = 53000\t loss = 0.005033473484218121\t eps = 0.2933\n","t = 53000\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 53100\t loss = 0.005389796569943428\t eps = 0.292\n","t = 53200\t loss = 0.002753486391156912\t eps = 0.2907\n","t = 53300\t loss = 0.004520801827311516\t eps = 0.2893\n","t = 53400\t loss = 0.004235940054059029\t eps = 0.288\n","t = 53500\t loss = 0.0030519054271280766\t eps = 0.2867\n","t = 53500\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 53600\t loss = 0.006611347664147615\t eps = 0.2853\n","t = 53700\t loss = 0.006496332120150328\t eps = 0.284\n","t = 53800\t loss = 0.005639798939228058\t eps = 0.2827\n","t = 53900\t loss = 0.004314851481467485\t eps = 0.2813\n","t = 54000\t loss = 0.0048383488319814205\t eps = 0.28\n","t = 54000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 54100\t loss = 0.003788615111261606\t eps = 0.2787\n","t = 54200\t loss = 0.004934656899422407\t eps = 0.2773\n","t = 54300\t loss = 0.002535599982365966\t eps = 0.276\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(39_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8PkJdkf8WQ5"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_54000'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_54000'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"133f7a08-2334-4a89-ef36-97cc05669e1e","id":"RXhKngcb8WQ8","executionInfo":{"status":"error","timestamp":1718561851427,"user_tz":-180,"elapsed":5440504,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 54100\t loss = None\t eps = 0.2787\n","t = 54200\t loss = 0.0031566277612000704\t eps = 0.2773\n","t = 54300\t loss = 0.0027538668364286423\t eps = 0.276\n","t = 54400\t loss = 0.005372095387428999\t eps = 0.2747\n","t = 54500\t loss = 0.0034153624437749386\t eps = 0.2733\n","t = 54500\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 54600\t loss = 0.0024666134268045425\t eps = 0.272\n","t = 54700\t loss = 0.00479389913380146\t eps = 0.2707\n","t = 54800\t loss = 0.0024015833623707294\t eps = 0.2693\n","t = 54900\t loss = 0.003967026248574257\t eps = 0.268\n","t = 55000\t loss = 0.0034500639885663986\t eps = 0.2667\n","t = 55000\t reward = 0.74\t{'DQNAgent': 87, 'RandomPlus': 13}\n","\n","t = 55100\t loss = 0.003942839335650206\t eps = 0.2653\n","t = 55200\t loss = 0.004457756876945496\t eps = 0.264\n","t = 55300\t loss = 0.0038009081035852432\t eps = 0.2627\n","t = 55400\t loss = 0.00373813696205616\t eps = 0.2613\n","t = 55500\t loss = 0.0040886541828513145\t eps = 0.26\n","t = 55500\t reward = 0.28\t{'DQNAgent': 64, 'RandomPlus': 36}\n","\n","t = 55600\t loss = 0.008327452465891838\t eps = 0.2587\n","t = 55700\t loss = 0.0028866715729236603\t eps = 0.2573\n","t = 55800\t loss = 0.0046583423390984535\t eps = 0.256\n","t = 55900\t loss = 0.0047904374077916145\t eps = 0.2547\n","t = 56000\t loss = 0.004336955025792122\t eps = 0.2533\n","t = 56000\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 56100\t loss = 0.0077352216467261314\t eps = 0.252\n","t = 56200\t loss = 0.00806469563394785\t eps = 0.2507\n","t = 56300\t loss = 0.005508063826709986\t eps = 0.2493\n","t = 56400\t loss = 0.005083720199763775\t eps = 0.248\n","t = 56500\t loss = 0.003864622674882412\t eps = 0.2467\n","t = 56500\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 56600\t loss = 0.0045827836729586124\t eps = 0.2453\n","t = 56700\t loss = 0.0035640844143927097\t eps = 0.244\n","t = 56800\t loss = 0.006424867082387209\t eps = 0.2427\n","t = 56900\t loss = 0.003978271037340164\t eps = 0.2413\n","t = 57000\t loss = 0.003353094682097435\t eps = 0.24\n","t = 57000\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 57100\t loss = 0.0027885441668331623\t eps = 0.2387\n","t = 57200\t loss = 0.003904575016349554\t eps = 0.2373\n","t = 57300\t loss = 0.004340778104960918\t eps = 0.236\n","t = 57400\t loss = 0.005133430007845163\t eps = 0.2347\n","t = 57500\t loss = 0.005478182341903448\t eps = 0.2333\n","t = 57500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 57600\t loss = 0.0035431687720119953\t eps = 0.232\n","t = 57700\t loss = 0.005753944627940655\t eps = 0.2307\n","t = 57800\t loss = 0.005770182237029076\t eps = 0.2293\n","t = 57900\t loss = 0.004883643705397844\t eps = 0.228\n","t = 58000\t loss = 0.0038916743360459805\t eps = 0.2267\n","t = 58000\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 58100\t loss = 0.004698349628597498\t eps = 0.2253\n","t = 58200\t loss = 0.0032839886844158173\t eps = 0.224\n","t = 58300\t loss = 0.005987968295812607\t eps = 0.2227\n","t = 58400\t loss = 0.003792358562350273\t eps = 0.2213\n","t = 58500\t loss = 0.002812468446791172\t eps = 0.22\n","t = 58500\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 58600\t loss = 0.005075080320239067\t eps = 0.2187\n","t = 58700\t loss = 0.003901942865923047\t eps = 0.2173\n","t = 58800\t loss = 0.003912939224392176\t eps = 0.216\n","t = 58900\t loss = 0.003699439112097025\t eps = 0.2147\n","t = 59000\t loss = 0.004928623791784048\t eps = 0.2133\n","t = 59000\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 59100\t loss = 0.004029871430248022\t eps = 0.212\n","t = 59200\t loss = 0.0027041248977184296\t eps = 0.2107\n","t = 59300\t loss = 0.002725812839344144\t eps = 0.2093\n","t = 59400\t loss = 0.004129313863813877\t eps = 0.208\n","t = 59500\t loss = 0.004226473160088062\t eps = 0.2067\n","t = 59500\t reward = 0.28\t{'DQNAgent': 64, 'RandomPlus': 36}\n","\n","t = 59600\t loss = 0.005076799541711807\t eps = 0.2053\n","t = 59700\t loss = 0.006591796875\t eps = 0.204\n","t = 59800\t loss = 0.003836917458102107\t eps = 0.2027\n","t = 59900\t loss = 0.004435466602444649\t eps = 0.2013\n","t = 60000\t loss = 0.0034026955254375935\t eps = 0.2\n","t = 60000\t reward = 0.72\t{'DQNAgent': 86, 'RandomPlus': 14}\n","\n","t = 60100\t loss = 0.004463827703148127\t eps = 0.2\n","t = 60200\t loss = 0.0030431640334427357\t eps = 0.2\n","t = 60300\t loss = 0.003326380392536521\t eps = 0.2\n","t = 60400\t loss = 0.004249009303748608\t eps = 0.2\n","t = 60500\t loss = 0.0038122879341244698\t eps = 0.2\n","t = 60500\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 60600\t loss = 0.004103483632206917\t eps = 0.2\n","t = 60700\t loss = 0.004211307968944311\t eps = 0.2\n","t = 60800\t loss = 0.004282355308532715\t eps = 0.2\n","t = 60900\t loss = 0.004904055502265692\t eps = 0.2\n","t = 61000\t loss = 0.005734371021389961\t eps = 0.2\n","t = 61000\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 61100\t loss = 0.0051948330365121365\t eps = 0.2\n","t = 61200\t loss = 0.004525318276137114\t eps = 0.2\n","t = 61300\t loss = 0.0043312604539096355\t eps = 0.2\n","t = 61400\t loss = 0.00561569444835186\t eps = 0.2\n","t = 61500\t loss = 0.005229400470852852\t eps = 0.2\n","t = 61500\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 61600\t loss = 0.00536439660936594\t eps = 0.2\n","t = 61700\t loss = 0.004073647316545248\t eps = 0.2\n","t = 61800\t loss = 0.0037413283716887236\t eps = 0.2\n","t = 61900\t loss = 0.003975727129727602\t eps = 0.2\n","t = 62000\t loss = 0.005420847795903683\t eps = 0.2\n","t = 62000\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 62100\t loss = 0.0046657295897603035\t eps = 0.2\n","t = 62200\t loss = 0.0037387674674391747\t eps = 0.2\n","t = 62300\t loss = 0.007742300629615784\t eps = 0.2\n","t = 62400\t loss = 0.004445036873221397\t eps = 0.2\n","t = 62500\t loss = 0.004312417004257441\t eps = 0.2\n","t = 62500\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 62600\t loss = 0.005337156355381012\t eps = 0.2\n","t = 62700\t loss = 0.005061870440840721\t eps = 0.2\n","t = 62800\t loss = 0.0035243877209722996\t eps = 0.2\n","t = 62900\t loss = 0.0024473865050822496\t eps = 0.2\n","t = 63000\t loss = 0.004377107135951519\t eps = 0.2\n","t = 63000\t reward = 0.21\t{'DQNAgent': 60, 'RandomPlus': 39}\n","\n","t = 63100\t loss = 0.006077217869460583\t eps = 0.2\n","t = 63200\t loss = 0.0055823782458901405\t eps = 0.2\n","t = 63300\t loss = 0.007824786007404327\t eps = 0.2\n","t = 63400\t loss = 0.003517195349559188\t eps = 0.2\n","t = 63500\t loss = 0.004470217972993851\t eps = 0.2\n","t = 63500\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 63600\t loss = 0.004763905890285969\t eps = 0.2\n","t = 63700\t loss = 0.006573015358299017\t eps = 0.2\n","t = 63800\t loss = 0.0063933138735592365\t eps = 0.2\n","t = 63900\t loss = 0.007170117925852537\t eps = 0.2\n","t = 64000\t loss = 0.004483358468860388\t eps = 0.2\n","t = 64000\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 64100\t loss = 0.004688325338065624\t eps = 0.2\n","t = 64200\t loss = 0.006310606375336647\t eps = 0.2\n","t = 64300\t loss = 0.004619474522769451\t eps = 0.2\n","t = 64400\t loss = 0.003593652043491602\t eps = 0.2\n","t = 64500\t loss = 0.005059762857854366\t eps = 0.2\n","t = 64500\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 64600\t loss = 0.004024913534522057\t eps = 0.2\n","t = 64700\t loss = 0.004343641456216574\t eps = 0.2\n","t = 64800\t loss = 0.004584027919918299\t eps = 0.2\n","t = 64900\t loss = 0.005321929696947336\t eps = 0.2\n","t = 65000\t loss = 0.0038059107027947903\t eps = 0.2\n","t = 65000\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 65100\t loss = 0.0029131725896149874\t eps = 0.2\n","t = 65200\t loss = 0.003309057094156742\t eps = 0.2\n","t = 65300\t loss = 0.003078005975112319\t eps = 0.2\n","t = 65400\t loss = 0.003553236136212945\t eps = 0.2\n","t = 65500\t loss = 0.004172767512500286\t eps = 0.2\n","t = 65500\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 65600\t loss = 0.004057841841131449\t eps = 0.2\n","t = 65700\t loss = 0.0035937512293457985\t eps = 0.2\n","t = 65800\t loss = 0.004744384437799454\t eps = 0.2\n","t = 65900\t loss = 0.004277627915143967\t eps = 0.2\n","t = 66000\t loss = 0.006733193062245846\t eps = 0.2\n","t = 66000\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 66100\t loss = 0.004426074214279652\t eps = 0.2\n","t = 66200\t loss = 0.006545922253280878\t eps = 0.2\n","t = 66300\t loss = 0.009088326245546341\t eps = 0.2\n","t = 66400\t loss = 0.005930156912654638\t eps = 0.2\n","t = 66500\t loss = 0.003670214908197522\t eps = 0.2\n","t = 66500\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 66600\t loss = 0.004700866527855396\t eps = 0.2\n","t = 66700\t loss = 0.003284862730652094\t eps = 0.2\n","t = 66800\t loss = 0.0033870115876197815\t eps = 0.2\n","t = 66900\t loss = 0.00623722281306982\t eps = 0.2\n","t = 67000\t loss = 0.0050928290002048016\t eps = 0.2\n","t = 67000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 67100\t loss = 0.0027489387430250645\t eps = 0.2\n","t = 67200\t loss = 0.005295882932841778\t eps = 0.2\n","t = 67300\t loss = 0.0036561163142323494\t eps = 0.2\n","t = 67400\t loss = 0.007335680536925793\t eps = 0.2\n","t = 67500\t loss = 0.004526532255113125\t eps = 0.2\n","t = 67500\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 67600\t loss = 0.005213495343923569\t eps = 0.2\n","t = 67700\t loss = 0.005468602757900953\t eps = 0.2\n","t = 67800\t loss = 0.004576526582241058\t eps = 0.2\n","t = 67900\t loss = 0.005130557809025049\t eps = 0.2\n","t = 68000\t loss = 0.0057279388420283794\t eps = 0.2\n","t = 68000\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 68100\t loss = 0.004714447073638439\t eps = 0.2\n","t = 68200\t loss = 0.005211665295064449\t eps = 0.2\n","t = 68300\t loss = 0.004515514709055424\t eps = 0.2\n","t = 68400\t loss = 0.0034909648820757866\t eps = 0.2\n","t = 68500\t loss = 0.005438496358692646\t eps = 0.2\n","t = 68500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 68600\t loss = 0.005083581432700157\t eps = 0.2\n","t = 68700\t loss = 0.004409605637192726\t eps = 0.2\n","t = 68800\t loss = 0.006730102933943272\t eps = 0.2\n","t = 68900\t loss = 0.0037898505106568336\t eps = 0.2\n","t = 69000\t loss = 0.0031151960138231516\t eps = 0.2\n","t = 69000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 69100\t loss = 0.005094549618661404\t eps = 0.2\n","t = 69200\t loss = 0.0063841138035058975\t eps = 0.2\n","t = 69300\t loss = 0.003734004683792591\t eps = 0.2\n","t = 69400\t loss = 0.005129210650920868\t eps = 0.2\n","t = 69500\t loss = 0.003920119255781174\t eps = 0.2\n","t = 69500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 69600\t loss = 0.004206384532153606\t eps = 0.2\n","t = 69700\t loss = 0.003637390909716487\t eps = 0.2\n","t = 69800\t loss = 0.005630333907902241\t eps = 0.2\n","t = 69900\t loss = 0.00625282246619463\t eps = 0.2\n","t = 70000\t loss = 0.004511408042162657\t eps = 0.2\n","t = 70000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 70100\t loss = 0.00509828794747591\t eps = 0.2\n","t = 70200\t loss = 0.005335518624633551\t eps = 0.2\n","t = 70300\t loss = 0.004835233557969332\t eps = 0.2\n","t = 70400\t loss = 0.005081364884972572\t eps = 0.2\n","t = 70500\t loss = 0.0036243293434381485\t eps = 0.2\n","t = 70500\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 70600\t loss = 0.0036599126178771257\t eps = 0.2\n","t = 70700\t loss = 0.0038068804424256086\t eps = 0.2\n","t = 70800\t loss = 0.004581055603921413\t eps = 0.2\n","t = 70900\t loss = 0.0033136014826595783\t eps = 0.2\n","t = 71000\t loss = 0.0035191751085221767\t eps = 0.2\n","t = 71000\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 71100\t loss = 0.005133630242198706\t eps = 0.2\n","t = 71200\t loss = 0.004342897329479456\t eps = 0.2\n","t = 71300\t loss = 0.003564144019037485\t eps = 0.2\n","t = 71400\t loss = 0.004482497461140156\t eps = 0.2\n","t = 71500\t loss = 0.004846971482038498\t eps = 0.2\n","t = 71500\t reward = 0.56\t{'DQNAgent': 78, 'RandomPlus': 22}\n","\n","t = 71600\t loss = 0.006988420616835356\t eps = 0.2\n","t = 71700\t loss = 0.006826962344348431\t eps = 0.2\n","t = 71800\t loss = 0.006202013231813908\t eps = 0.2\n","t = 71900\t loss = 0.0033928798511624336\t eps = 0.2\n","t = 72000\t loss = 0.004480713978409767\t eps = 0.2\n","t = 72000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 72100\t loss = 0.0029439411591738462\t eps = 0.2\n","t = 72200\t loss = 0.005797450430691242\t eps = 0.2\n","t = 72300\t loss = 0.003995114471763372\t eps = 0.2\n","t = 72400\t loss = 0.006108989007771015\t eps = 0.2\n","t = 72500\t loss = 0.0033185314387083054\t eps = 0.2\n","t = 72500\t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 72600\t loss = 0.005436207167804241\t eps = 0.2\n","t = 72700\t loss = 0.003489527851343155\t eps = 0.2\n","t = 72800\t loss = 0.0026469044387340546\t eps = 0.2\n","t = 72900\t loss = 0.004286781419068575\t eps = 0.2\n","t = 73000\t loss = 0.004288358613848686\t eps = 0.2\n","t = 73000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 73100\t loss = 0.004839180503040552\t eps = 0.2\n","t = 73200\t loss = 0.003456025617197156\t eps = 0.2\n","t = 73300\t loss = 0.0037904498167335987\t eps = 0.2\n","t = 73400\t loss = 0.005282605066895485\t eps = 0.2\n","t = 73500\t loss = 0.0036285570822656155\t eps = 0.2\n","t = 73500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 73600\t loss = 0.00441959360614419\t eps = 0.2\n","t = 73700\t loss = 0.006836675573140383\t eps = 0.2\n","t = 73800\t loss = 0.00562989991158247\t eps = 0.2\n","t = 73900\t loss = 0.004095409531146288\t eps = 0.2\n","t = 74000\t loss = 0.0046986062079668045\t eps = 0.2\n","t = 74000\t reward = 0.45\t{'DQNAgent': 72, 'RandomPlus': 27}\n","\n","t = 74100\t loss = 0.004386868793517351\t eps = 0.2\n","t = 74200\t loss = 0.005513342563062906\t eps = 0.2\n","t = 74300\t loss = 0.003180957864969969\t eps = 0.2\n","t = 74400\t loss = 0.004160271491855383\t eps = 0.2\n","t = 74500\t loss = 0.005792219657450914\t eps = 0.2\n","t = 74500\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 74600\t loss = 0.005944748874753714\t eps = 0.2\n","t = 74700\t loss = 0.005430414341390133\t eps = 0.2\n","t = 74800\t loss = 0.003917462192475796\t eps = 0.2\n","t = 74900\t loss = 0.005691580940037966\t eps = 0.2\n","t = 75000\t loss = 0.0038969111628830433\t eps = 0.2\n","t = 75000\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 75100\t loss = 0.005301633849740028\t eps = 0.2\n","t = 75200\t loss = 0.004020837601274252\t eps = 0.2\n","t = 75300\t loss = 0.005633514374494553\t eps = 0.2\n","t = 75400\t loss = 0.0040641529485583305\t eps = 0.2\n","t = 75500\t loss = 0.006791227031499147\t eps = 0.2\n","t = 75500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 75600\t loss = 0.004860094282776117\t eps = 0.2\n","t = 75700\t loss = 0.004595558159053326\t eps = 0.2\n","t = 75800\t loss = 0.005987495183944702\t eps = 0.2\n","t = 75900\t loss = 0.0033737262710928917\t eps = 0.2\n","t = 76000\t loss = 0.004308837465941906\t eps = 0.2\n","t = 76000\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 76100\t loss = 0.004438222385942936\t eps = 0.2\n","t = 76200\t loss = 0.006642038933932781\t eps = 0.2\n","t = 76300\t loss = 0.00492902472615242\t eps = 0.2\n","t = 76400\t loss = 0.003945075906813145\t eps = 0.2\n","t = 76500\t loss = 0.005138800945132971\t eps = 0.2\n","t = 76500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 76600\t loss = 0.004532122053205967\t eps = 0.2\n","t = 76700\t loss = 0.004593010991811752\t eps = 0.2\n","t = 76800\t loss = 0.0072974348440766335\t eps = 0.2\n","t = 76900\t loss = 0.007906037382781506\t eps = 0.2\n","t = 77000\t loss = 0.005596272647380829\t eps = 0.2\n","t = 77000\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 77100\t loss = 0.005309741944074631\t eps = 0.2\n","t = 77200\t loss = 0.00657931063324213\t eps = 0.2\n","t = 77300\t loss = 0.006246644072234631\t eps = 0.2\n","t = 77400\t loss = 0.004073999356478453\t eps = 0.2\n","t = 77500\t loss = 0.0031616766937077045\t eps = 0.2\n","t = 77500\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 77600\t loss = 0.0048175351694226265\t eps = 0.2\n","t = 77700\t loss = 0.0036949613131582737\t eps = 0.2\n","t = 77800\t loss = 0.004188090562820435\t eps = 0.2\n","t = 77900\t loss = 0.009336649440228939\t eps = 0.2\n","t = 78000\t loss = 0.005032848566770554\t eps = 0.2\n","t = 78000\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 78100\t loss = 0.0052942256443202496\t eps = 0.2\n","t = 78200\t loss = 0.007964754477143288\t eps = 0.2\n","t = 78300\t loss = 0.008247200399637222\t eps = 0.2\n","t = 78400\t loss = 0.0053747883066535\t eps = 0.2\n","t = 78500\t loss = 0.005697424523532391\t eps = 0.2\n","t = 78500\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 78600\t loss = 0.005578001961112022\t eps = 0.2\n","t = 78700\t loss = 0.00593990832567215\t eps = 0.2\n","t = 78800\t loss = 0.004799860529601574\t eps = 0.2\n","t = 78900\t loss = 0.00506520364433527\t eps = 0.2\n","t = 79000\t loss = 0.005012689158320427\t eps = 0.2\n","t = 79000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 79100\t loss = 0.006309463642537594\t eps = 0.2\n","t = 79200\t loss = 0.004502704832702875\t eps = 0.2\n","t = 79300\t loss = 0.003898479277268052\t eps = 0.2\n","t = 79400\t loss = 0.004426334984600544\t eps = 0.2\n","t = 79500\t loss = 0.007771744392812252\t eps = 0.2\n","t = 79500\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 79600\t loss = 0.0068468330428004265\t eps = 0.2\n","t = 79700\t loss = 0.0035721510648727417\t eps = 0.2\n","t = 79800\t loss = 0.0059335678815841675\t eps = 0.2\n","t = 79900\t loss = 0.0044977786019444466\t eps = 0.2\n","t = 80000\t loss = 0.005439737346023321\t eps = 0.2\n","t = 80000\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 80100\t loss = 0.005539653357118368\t eps = 0.2\n","t = 80200\t loss = 0.004558861255645752\t eps = 0.2\n","t = 80300\t loss = 0.005666307173669338\t eps = 0.2\n","t = 80400\t loss = 0.00553584611043334\t eps = 0.2\n","t = 80500\t loss = 0.004679687786847353\t eps = 0.2\n","t = 80500\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 80600\t loss = 0.004937618039548397\t eps = 0.2\n","t = 80700\t loss = 0.003703788388520479\t eps = 0.2\n","t = 80800\t loss = 0.00400290684774518\t eps = 0.2\n","t = 80900\t loss = 0.005116662941873074\t eps = 0.2\n","t = 81000\t loss = 0.004366990178823471\t eps = 0.2\n","t = 81000\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 81100\t loss = 0.005755726248025894\t eps = 0.2\n","t = 81200\t loss = 0.0046752686612308025\t eps = 0.2\n","t = 81300\t loss = 0.004916793666779995\t eps = 0.2\n","t = 81400\t loss = 0.006614042446017265\t eps = 0.2\n","t = 81500\t loss = 0.003912676591426134\t eps = 0.2\n","t = 81500\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 81600\t loss = 0.004110222682356834\t eps = 0.2\n","t = 81700\t loss = 0.005166180431842804\t eps = 0.2\n","t = 81800\t loss = 0.004474529065191746\t eps = 0.2\n","t = 81900\t loss = 0.008624696172773838\t eps = 0.2\n","t = 82000\t loss = 0.004069065675139427\t eps = 0.2\n","t = 82000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 82100\t loss = 0.006300807930529118\t eps = 0.2\n","t = 82200\t loss = 0.0047462331131100655\t eps = 0.2\n","t = 82300\t loss = 0.005411897785961628\t eps = 0.2\n","t = 82400\t loss = 0.005172048695385456\t eps = 0.2\n","t = 82500\t loss = 0.007138491608202457\t eps = 0.2\n","t = 82500\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 82600\t loss = 0.005236673168838024\t eps = 0.2\n","t = 82700\t loss = 0.003924841992557049\t eps = 0.2\n","t = 82800\t loss = 0.005215647630393505\t eps = 0.2\n","t = 82900\t loss = 0.0037164126988500357\t eps = 0.2\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-c91845d8423c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             loss = compute_td_loss(states, actions, rewards, next_states, dones,\n\u001b[0m\u001b[1;32m     29\u001b[0m                                    agent, target_network, weights, indices, gamma, prioritized=True)\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-b10a2daddbe6>\u001b[0m in \u001b[0;36mcompute_td_loss\u001b[0;34m(states, actions, rewards, next_states, dones, agent, target_network, weights, indices, gamma, device, prioritized)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpredicted_next_qvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# shape: [batch_size, n_actions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredicted_qvalues_for_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_qvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape: [batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_next_qvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtarget_qvalues_for_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_state_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(54_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"pMaIjpdCRTQl","executionInfo":{"status":"ok","timestamp":1718573208989,"user_tz":-180,"elapsed":3712,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_82500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_82500'))\n","\n","main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","source":["with open('out.txt', 'w') as f:\n","  for t in range(82_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tZU48MdRYrC","outputId":"86c2b031-7407-435b-eca3-82eec486564f","executionInfo":{"status":"ok","timestamp":1718576455096,"user_tz":-180,"elapsed":3243247,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["t = 82600\t loss = None\t eps = 0.25\n","t = 82700\t loss = 0.004096668679267168\t eps = 0.25\n","t = 82800\t loss = 0.007480150554329157\t eps = 0.25\n","t = 82900\t loss = 0.002658799523487687\t eps = 0.25\n","t = 83000\t loss = 0.005371814593672752\t eps = 0.25\n","t = 83000\t reward = 0.56\t{'DQNAgent': 78, 'RandomPlus': 22}\n","\n","t = 83100\t loss = 0.004077929072082043\t eps = 0.25\n","t = 83200\t loss = 0.004114334471523762\t eps = 0.25\n","t = 83300\t loss = 0.005193930119276047\t eps = 0.25\n","t = 83400\t loss = 0.0041450802236795425\t eps = 0.25\n","t = 83500\t loss = 0.0034748208709061146\t eps = 0.25\n","t = 83500\t reward = 0.51\t{'DQNAgent': 75, 'RandomPlus': 24}\n","\n","t = 83600\t loss = 0.003645701799541712\t eps = 0.25\n","t = 83700\t loss = 0.004883396904915571\t eps = 0.25\n","t = 83800\t loss = 0.004776002839207649\t eps = 0.25\n","t = 83900\t loss = 0.00487343966960907\t eps = 0.25\n","t = 84000\t loss = 0.005662119016051292\t eps = 0.25\n","t = 84000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 84100\t loss = 0.005373808555305004\t eps = 0.25\n","t = 84200\t loss = 0.005753441248089075\t eps = 0.25\n","t = 84300\t loss = 0.005324766971170902\t eps = 0.25\n","t = 84400\t loss = 0.006670882925391197\t eps = 0.25\n","t = 84500\t loss = 0.004012598656117916\t eps = 0.25\n","t = 84500\t reward = 0.34\t{'DQNAgent': 67, 'RandomPlus': 33}\n","\n","t = 84600\t loss = 0.005028409883379936\t eps = 0.25\n","t = 84700\t loss = 0.005130926612764597\t eps = 0.25\n","t = 84800\t loss = 0.006057889200747013\t eps = 0.25\n","t = 84900\t loss = 0.00550214946269989\t eps = 0.25\n","t = 85000\t loss = 0.006795473396778107\t eps = 0.25\n","t = 85000\t reward = 0.33\t{'DQNAgent': 66, 'RandomPlus': 33}\n","\n","t = 85100\t loss = 0.006104957778006792\t eps = 0.25\n","t = 85200\t loss = 0.004569005221128464\t eps = 0.25\n","t = 85300\t loss = 0.006921117193996906\t eps = 0.25\n","t = 85400\t loss = 0.004544067196547985\t eps = 0.25\n","t = 85500\t loss = 0.006277904380112886\t eps = 0.25\n","t = 85500\t reward = 0.28\t{'DQNAgent': 64, 'RandomPlus': 36}\n","\n","t = 85600\t loss = 0.005349189043045044\t eps = 0.25\n","t = 85700\t loss = 0.004564901348203421\t eps = 0.25\n","t = 85800\t loss = 0.005617345683276653\t eps = 0.25\n","t = 85900\t loss = 0.004217157140374184\t eps = 0.25\n","t = 86000\t loss = 0.005848386324942112\t eps = 0.25\n","t = 86000\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 86100\t loss = 0.006864259950816631\t eps = 0.25\n","t = 86200\t loss = 0.006118910387158394\t eps = 0.25\n","t = 86300\t loss = 0.0067457533441483974\t eps = 0.25\n","t = 86400\t loss = 0.014025765471160412\t eps = 0.25\n","t = 86500\t loss = 0.005725768860429525\t eps = 0.25\n","t = 86500\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 86600\t loss = 0.008733263239264488\t eps = 0.25\n","t = 86700\t loss = 0.009791254065930843\t eps = 0.25\n","t = 86800\t loss = 0.009441278874874115\t eps = 0.25\n","t = 86900\t loss = 0.006001906469464302\t eps = 0.25\n","t = 87000\t loss = 0.006559100467711687\t eps = 0.25\n","t = 87000\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 87100\t loss = 0.005187449511140585\t eps = 0.25\n","t = 87200\t loss = 0.00648212106898427\t eps = 0.25\n","t = 87300\t loss = 0.003464894834905863\t eps = 0.25\n","t = 87400\t loss = 0.006923281587660313\t eps = 0.25\n","t = 87500\t loss = 0.00821330863982439\t eps = 0.25\n","t = 87500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 87600\t loss = 0.005286224186420441\t eps = 0.25\n","t = 87700\t loss = 0.007146648596972227\t eps = 0.25\n","t = 87800\t loss = 0.004469128325581551\t eps = 0.25\n","t = 87900\t loss = 0.007668268401175737\t eps = 0.25\n","t = 88000\t loss = 0.006871156394481659\t eps = 0.25\n","t = 88000\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 88100\t loss = 0.006538953632116318\t eps = 0.25\n","t = 88200\t loss = 0.007236161734908819\t eps = 0.25\n","t = 88300\t loss = 0.0062565878033638\t eps = 0.25\n","t = 88400\t loss = 0.007231202907860279\t eps = 0.25\n","t = 88500\t loss = 0.007215079851448536\t eps = 0.25\n","t = 88500\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 88600\t loss = 0.008211195468902588\t eps = 0.25\n","t = 88700\t loss = 0.0069585517048835754\t eps = 0.25\n","t = 88800\t loss = 0.00669772969558835\t eps = 0.25\n","t = 88900\t loss = 0.006765358150005341\t eps = 0.25\n","t = 89000\t loss = 0.005482095293700695\t eps = 0.25\n","t = 89000\t reward = 0.3\t{'DQNAgent': 65, 'RandomPlus': 35}\n","\n","t = 89100\t loss = 0.004927216097712517\t eps = 0.25\n","t = 89200\t loss = 0.0070701781660318375\t eps = 0.25\n","t = 89300\t loss = 0.007779254578053951\t eps = 0.25\n","t = 89400\t loss = 0.004797973670065403\t eps = 0.25\n","t = 89500\t loss = 0.006534901913255453\t eps = 0.25\n","t = 89500\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 89600\t loss = 0.008410360664129257\t eps = 0.25\n","t = 89700\t loss = 0.007395000196993351\t eps = 0.25\n","t = 89800\t loss = 0.00759154511615634\t eps = 0.25\n","t = 89900\t loss = 0.007823842577636242\t eps = 0.25\n","t = 90000\t loss = 0.00781742949038744\t eps = 0.25\n","t = 90000\t reward = 0.36\t{'DQNAgent': 68, 'RandomPlus': 32}\n","\n","t = 90100\t loss = 0.007895970717072487\t eps = 0.25\n","t = 90200\t loss = 0.007643683347851038\t eps = 0.25\n","t = 90300\t loss = 0.005761073436588049\t eps = 0.25\n","t = 90400\t loss = 0.007027777377516031\t eps = 0.25\n","t = 90500\t loss = 0.007880400866270065\t eps = 0.25\n","t = 90500\t reward = 0.46\t{'DQNAgent': 73, 'RandomPlus': 27}\n","\n","t = 90600\t loss = 0.0072088586166501045\t eps = 0.25\n","t = 90700\t loss = 0.006999349221587181\t eps = 0.25\n","t = 90800\t loss = 0.008107239380478859\t eps = 0.25\n","t = 90900\t loss = 0.005343565717339516\t eps = 0.25\n","t = 91000\t loss = 0.0055414289236068726\t eps = 0.25\n","t = 91000\t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 91100\t loss = 0.0053515248000621796\t eps = 0.25\n","t = 91200\t loss = 0.0073301298543810844\t eps = 0.25\n","t = 91300\t loss = 0.004937028046697378\t eps = 0.25\n","t = 91400\t loss = 0.005123046226799488\t eps = 0.25\n","t = 91500\t loss = 0.005231514573097229\t eps = 0.25\n","t = 91500\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 91600\t loss = 0.004779077135026455\t eps = 0.25\n","t = 91700\t loss = 0.006852889433503151\t eps = 0.25\n","t = 91800\t loss = 0.005872376263141632\t eps = 0.25\n","t = 91900\t loss = 0.006035972386598587\t eps = 0.25\n","t = 92000\t loss = 0.005150572396814823\t eps = 0.25\n","t = 92000\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 92100\t loss = 0.004798991605639458\t eps = 0.25\n","t = 92200\t loss = 0.005990991368889809\t eps = 0.25\n","t = 92300\t loss = 0.004423304460942745\t eps = 0.25\n","t = 92400\t loss = 0.005770421586930752\t eps = 0.25\n","t = 92500\t loss = 0.007267885375767946\t eps = 0.25\n","t = 92500\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 92600\t loss = 0.008211708627641201\t eps = 0.25\n","t = 92700\t loss = 0.00595159363001585\t eps = 0.25\n","t = 92800\t loss = 0.006190539337694645\t eps = 0.25\n","t = 92900\t loss = 0.006195619702339172\t eps = 0.25\n","t = 93000\t loss = 0.006601694971323013\t eps = 0.25\n","t = 93000\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 93100\t loss = 0.008449633605778217\t eps = 0.25\n","t = 93200\t loss = 0.0053028929978609085\t eps = 0.25\n","t = 93300\t loss = 0.00658473651856184\t eps = 0.25\n","t = 93400\t loss = 0.007103500422090292\t eps = 0.25\n","t = 93500\t loss = 0.009970340877771378\t eps = 0.25\n","t = 93500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 93600\t loss = 0.006233455613255501\t eps = 0.25\n","t = 93700\t loss = 0.006228344514966011\t eps = 0.25\n","t = 93800\t loss = 0.007292968221008778\t eps = 0.25\n","t = 93900\t loss = 0.005544315092265606\t eps = 0.25\n","t = 94000\t loss = 0.006954409182071686\t eps = 0.25\n","t = 94000\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 94100\t loss = 0.005350781604647636\t eps = 0.25\n","t = 94200\t loss = 0.0046029044315218925\t eps = 0.25\n","t = 94300\t loss = 0.007286617066711187\t eps = 0.25\n","t = 94400\t loss = 0.005343124270439148\t eps = 0.25\n","t = 94500\t loss = 0.005649282597005367\t eps = 0.25\n","t = 94500\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 94600\t loss = 0.004363865591585636\t eps = 0.25\n","t = 94700\t loss = 0.0059664323925971985\t eps = 0.25\n","t = 94800\t loss = 0.0062065282836556435\t eps = 0.25\n","t = 94900\t loss = 0.010053955018520355\t eps = 0.25\n","t = 95000\t loss = 0.006551255472004414\t eps = 0.25\n","t = 95000\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 95100\t loss = 0.00727457832545042\t eps = 0.25\n","t = 95200\t loss = 0.009249365888535976\t eps = 0.25\n","t = 95300\t loss = 0.005882718600332737\t eps = 0.25\n","t = 95400\t loss = 0.006022343412041664\t eps = 0.25\n","t = 95500\t loss = 0.006319748237729073\t eps = 0.25\n","t = 95500\t reward = 0.69\t{'DQNAgent': 84, 'RandomPlus': 15}\n","\n","t = 95600\t loss = 0.010535676963627338\t eps = 0.25\n","t = 95700\t loss = 0.007802895270287991\t eps = 0.25\n","t = 95800\t loss = 0.009273909963667393\t eps = 0.25\n","t = 95900\t loss = 0.008550310507416725\t eps = 0.25\n","t = 96000\t loss = 0.00584584241732955\t eps = 0.25\n","t = 96000\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 96100\t loss = 0.005528266075998545\t eps = 0.25\n","t = 96200\t loss = 0.010934718884527683\t eps = 0.25\n","t = 96300\t loss = 0.0054177213460206985\t eps = 0.25\n","t = 96400\t loss = 0.009939868003129959\t eps = 0.25\n","t = 96500\t loss = 0.00790666788816452\t eps = 0.25\n","t = 96500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 96600\t loss = 0.006879138760268688\t eps = 0.25\n","t = 96700\t loss = 0.006884293165057898\t eps = 0.25\n","t = 96800\t loss = 0.007452716119587421\t eps = 0.25\n","t = 96900\t loss = 0.006544988602399826\t eps = 0.25\n","t = 97000\t loss = 0.010074971243739128\t eps = 0.25\n","t = 97000\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 97100\t loss = 0.007814085111021996\t eps = 0.25\n","t = 97200\t loss = 0.00679357722401619\t eps = 0.25\n","t = 97300\t loss = 0.005868437699973583\t eps = 0.25\n","t = 97400\t loss = 0.006694258190691471\t eps = 0.25\n","t = 97500\t loss = 0.007007319945842028\t eps = 0.25\n","t = 97500\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 97600\t loss = 0.006333665922284126\t eps = 0.25\n","t = 97700\t loss = 0.009431838989257812\t eps = 0.25\n","t = 97800\t loss = 0.0131351538002491\t eps = 0.25\n","t = 97900\t loss = 0.012678404338657856\t eps = 0.25\n","t = 98000\t loss = 0.00584013108164072\t eps = 0.25\n","t = 98000\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 98100\t loss = 0.0073735713958740234\t eps = 0.25\n","t = 98200\t loss = 0.007012692280113697\t eps = 0.25\n","t = 98300\t loss = 0.007144757080823183\t eps = 0.25\n","t = 98400\t loss = 0.005767687689512968\t eps = 0.25\n","t = 98500\t loss = 0.0065288664773106575\t eps = 0.25\n","t = 98500\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 98600\t loss = 0.007974018342792988\t eps = 0.25\n","t = 98700\t loss = 0.005750767886638641\t eps = 0.25\n","t = 98800\t loss = 0.0064911190420389175\t eps = 0.25\n","t = 98900\t loss = 0.007324058096855879\t eps = 0.25\n","t = 99000\t loss = 0.009463101625442505\t eps = 0.25\n","t = 99000\t reward = 0.48\t{'DQNAgent': 74, 'RandomPlus': 26}\n","\n","t = 99100\t loss = 0.007012894377112389\t eps = 0.25\n","t = 99200\t loss = 0.008720929734408855\t eps = 0.25\n","t = 99300\t loss = 0.00893997959792614\t eps = 0.25\n","t = 99400\t loss = 0.00806032121181488\t eps = 0.25\n","t = 99500\t loss = 0.006778378039598465\t eps = 0.25\n","t = 99500\t reward = 0.28\t{'DQNAgent': 64, 'RandomPlus': 36}\n","\n","t = 99600\t loss = 0.009514037519693375\t eps = 0.25\n","t = 99700\t loss = 0.007861224003136158\t eps = 0.25\n","t = 99800\t loss = 0.008248417638242245\t eps = 0.25\n","t = 99900\t loss = 0.009635630063712597\t eps = 0.25\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1718576553007,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"outputId":"68df685b-7a30-439f-daf5-75d5154dbabb","id":"iPTDgSOLMSd_"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["# Загрузка самой лучшей модели\n","agent.load_state_dict(torch.load(f'{PATH}model_95500'))"]},{"cell_type":"code","source":["with open('out.txt', 'w') as f:\n","  for t in range(100_100, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","        state_2d, turn = state\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma, prioritized=True)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5c6d2df0-e973-4a32-ff49-0379bb95d298","executionInfo":{"status":"error","timestamp":1718578436005,"user_tz":-180,"elapsed":1751390,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}},"id":"Xqr5KvLeJvhn"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["t = 100100\t loss = 0.019809503108263016\t eps = 0.1355\n","t = 100200\t loss = 0.01588462106883526\t eps = 0.1346\n","t = 100300\t loss = 0.010876724496483803\t eps = 0.1338\n","t = 100400\t loss = 0.011499712243676186\t eps = 0.1329\n","t = 100500\t loss = 0.02178739570081234\t eps = 0.132\n","t = 100500\t reward = 0.56\t{'DQNAgent': 78, 'RandomPlus': 22}\n","\n","t = 100600\t loss = 0.0064584193751215935\t eps = 0.1312\n","t = 100700\t loss = 0.00675962632521987\t eps = 0.1303\n","t = 100800\t loss = 0.008149629458785057\t eps = 0.1295\n","t = 100900\t loss = 0.0074499137699604034\t eps = 0.1286\n","t = 101000\t loss = 0.008473038673400879\t eps = 0.1277\n","t = 101000\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 101100\t loss = 0.006410880945622921\t eps = 0.1269\n","t = 101200\t loss = 0.004786661826074123\t eps = 0.126\n","t = 101300\t loss = 0.0055897957645356655\t eps = 0.1251\n","t = 101400\t loss = 0.005414832383394241\t eps = 0.1243\n","t = 101500\t loss = 0.005742618348449469\t eps = 0.1234\n","t = 101500\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 101600\t loss = 0.007727396674454212\t eps = 0.1225\n","t = 101700\t loss = 0.0053504593670368195\t eps = 0.1217\n","t = 101800\t loss = 0.004594555124640465\t eps = 0.1208\n","t = 101900\t loss = 0.007378856651484966\t eps = 0.12\n","t = 102000\t loss = 0.006735826842486858\t eps = 0.1191\n","t = 102000\t reward = 0.38\t{'DQNAgent': 69, 'RandomPlus': 31}\n","\n","t = 102100\t loss = 0.004311122000217438\t eps = 0.1182\n","t = 102200\t loss = 0.003937059547752142\t eps = 0.1174\n","t = 102300\t loss = 0.00526787806302309\t eps = 0.1165\n","t = 102400\t loss = 0.00565611757338047\t eps = 0.1156\n","t = 102500\t loss = 0.004648922011256218\t eps = 0.1148\n","t = 102500\t reward = 0.5\t{'DQNAgent': 75, 'RandomPlus': 25}\n","\n","t = 102600\t loss = 0.006532296072691679\t eps = 0.1139\n","t = 102700\t loss = 0.006227423436939716\t eps = 0.113\n","t = 102800\t loss = 0.005376741290092468\t eps = 0.1122\n","t = 102900\t loss = 0.008479908108711243\t eps = 0.1113\n","t = 103000\t loss = 0.006772307213395834\t eps = 0.1105\n","t = 103000\t reward = 0.54\t{'DQNAgent': 77, 'RandomPlus': 23}\n","\n","t = 103100\t loss = 0.006893126294016838\t eps = 0.1096\n","t = 103200\t loss = 0.004712042398750782\t eps = 0.1087\n","t = 103300\t loss = 0.005227511283010244\t eps = 0.1079\n","t = 103400\t loss = 0.007624377496540546\t eps = 0.107\n","t = 103500\t loss = 0.007034796290099621\t eps = 0.1061\n","t = 103500\t reward = 0.61\t{'DQNAgent': 80, 'RandomPlus': 19}\n","\n","t = 103600\t loss = 0.007602330297231674\t eps = 0.1053\n","t = 103700\t loss = 0.00966795813292265\t eps = 0.1044\n","t = 103800\t loss = 0.007497792597860098\t eps = 0.1035\n","t = 103900\t loss = 0.00732224527746439\t eps = 0.1027\n","t = 104000\t loss = 0.004762836266309023\t eps = 0.1018\n","t = 104000\t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 104100\t loss = 0.006747428793460131\t eps = 0.101\n","t = 104200\t loss = 0.005380549468100071\t eps = 0.1001\n","t = 104300\t loss = 0.00618011923506856\t eps = 0.0992\n","t = 104400\t loss = 0.006769437808543444\t eps = 0.0984\n","t = 104500\t loss = 0.006820310838520527\t eps = 0.0975\n","t = 104500\t reward = 0.62\t{'DQNAgent': 81, 'RandomPlus': 19}\n","\n","t = 104600\t loss = 0.006089136935770512\t eps = 0.0966\n","t = 104700\t loss = 0.004716047551482916\t eps = 0.0958\n","t = 104800\t loss = 0.006230263039469719\t eps = 0.0949\n","t = 104900\t loss = 0.005433946847915649\t eps = 0.094\n","t = 105000\t loss = 0.005841484293341637\t eps = 0.0932\n","t = 105000\t reward = 0.42\t{'DQNAgent': 71, 'RandomPlus': 29}\n","\n","t = 105100\t loss = 0.004655797034502029\t eps = 0.0923\n","t = 105200\t loss = 0.008720912039279938\t eps = 0.0915\n","t = 105300\t loss = 0.004976863972842693\t eps = 0.0906\n","t = 105400\t loss = 0.0042869700118899345\t eps = 0.0897\n","t = 105500\t loss = 0.00666823610663414\t eps = 0.0889\n","t = 105500\t reward = 0.41\t{'DQNAgent': 70, 'RandomPlus': 29}\n","\n","t = 105600\t loss = 0.005131158046424389\t eps = 0.088\n","t = 105700\t loss = 0.005505090579390526\t eps = 0.0871\n","t = 105800\t loss = 0.005736519582569599\t eps = 0.0863\n","t = 105900\t loss = 0.006504521239548922\t eps = 0.0854\n","t = 106000\t loss = 0.007081787567585707\t eps = 0.0845\n","t = 106000\t reward = 0.6\t{'DQNAgent': 80, 'RandomPlus': 20}\n","\n","t = 106100\t loss = 0.005713790655136108\t eps = 0.0837\n","t = 106200\t loss = 0.00539221428334713\t eps = 0.0828\n","t = 106300\t loss = 0.0036804445553570986\t eps = 0.082\n","t = 106400\t loss = 0.0046327849850058556\t eps = 0.0811\n","t = 106500\t loss = 0.008826818317174911\t eps = 0.0802\n","t = 106500\t reward = 0.64\t{'DQNAgent': 82, 'RandomPlus': 18}\n","\n","t = 106600\t loss = 0.008010590448975563\t eps = 0.0794\n","t = 106700\t loss = 0.005974199622869492\t eps = 0.0785\n","t = 106800\t loss = 0.0047109248116612434\t eps = 0.0776\n","t = 106900\t loss = 0.0062120528891682625\t eps = 0.0768\n","t = 107000\t loss = 0.0039022124838083982\t eps = 0.0759\n","t = 107000\t reward = 0.22\t{'DQNAgent': 61, 'RandomPlus': 39}\n","\n","t = 107100\t loss = 0.005453042685985565\t eps = 0.075\n","t = 107200\t loss = 0.0034786290489137173\t eps = 0.0742\n","t = 107300\t loss = 0.005585039034485817\t eps = 0.0733\n","t = 107400\t loss = 0.003761381609365344\t eps = 0.0725\n","t = 107500\t loss = 0.004903536289930344\t eps = 0.0716\n","t = 107500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 107600\t loss = 0.0085234884172678\t eps = 0.0707\n","t = 107700\t loss = 0.005261784419417381\t eps = 0.0699\n","t = 107800\t loss = 0.0056444997899234295\t eps = 0.069\n","t = 107900\t loss = 0.006030257325619459\t eps = 0.0681\n","t = 108000\t loss = 0.005397011060267687\t eps = 0.0673\n","t = 108000\t reward = 0.32\t{'DQNAgent': 66, 'RandomPlus': 34}\n","\n","t = 108100\t loss = 0.004811577964574099\t eps = 0.0664\n","t = 108200\t loss = 0.0058128805831074715\t eps = 0.0655\n","t = 108300\t loss = 0.006513671949505806\t eps = 0.0647\n","t = 108400\t loss = 0.004661689978092909\t eps = 0.0638\n","t = 108500\t loss = 0.006506919860839844\t eps = 0.063\n","t = 108500\t reward = 0.52\t{'DQNAgent': 76, 'RandomPlus': 24}\n","\n","t = 108600\t loss = 0.00614792387932539\t eps = 0.0621\n","t = 108700\t loss = 0.007123046088963747\t eps = 0.0612\n","t = 108800\t loss = 0.003990573808550835\t eps = 0.0604\n","t = 108900\t loss = 0.004711088724434376\t eps = 0.0595\n","t = 109000\t loss = 0.006055681966245174\t eps = 0.0586\n","t = 109000\t reward = 0.56\t{'DQNAgent': 78, 'RandomPlus': 22}\n","\n","t = 109100\t loss = 0.005231941118836403\t eps = 0.0578\n","t = 109200\t loss = 0.005411123391240835\t eps = 0.0569\n","t = 109300\t loss = 0.007220999803394079\t eps = 0.056\n","t = 109400\t loss = 0.004089674446731806\t eps = 0.0552\n","t = 109500\t loss = 0.0052308375015854836\t eps = 0.0543\n","t = 109500\t reward = 0.44\t{'DQNAgent': 72, 'RandomPlus': 28}\n","\n","t = 109600\t loss = 0.008479299023747444\t eps = 0.0535\n","t = 109700\t loss = 0.004489939194172621\t eps = 0.0526\n","t = 109800\t loss = 0.005782325752079487\t eps = 0.0517\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-156e54ff9132>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             loss = compute_td_loss(states, actions, rewards, next_states, dones,\n\u001b[0m\u001b[1;32m     29\u001b[0m                                    agent, target_network, weights, indices, gamma, prioritized=True)\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-b10a2daddbe6>\u001b[0m in \u001b[0;36mcompute_td_loss\u001b[0;34m(states, actions, rewards, next_states, dones, agent, target_network, weights, indices, gamma, device, prioritized)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# shape: [batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpredicted_qvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m                                                \u001b[0;31m# shape: [batch_size, n_actions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpredicted_next_qvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# shape: [batch_size, n_actions]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredicted_qvalues_for_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_qvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape: [batch_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-1a394c251fa7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["agent.epsilon = 0\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","eval_game.play(n_eval_games)\n","eval_game.wins"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYfXXaX6JIQy","executionInfo":{"status":"ok","timestamp":1718578478537,"user_tz":-180,"elapsed":1393,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"}},"outputId":"56776c8e-f5ed-45b7-97ce-2233bb62e000"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'DQNAgent': 65, 'RandomPlus': 35}"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"wMHCdyXqKqCk"},"source":["#Тестирование обученных моделей (инференс с маскированием)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QySv5l9i6fUs"},"outputs":[],"source":["PATH = '/content/drive/MyDrive/TicTacToe_8/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6H_9-jo_4UW"},"outputs":[],"source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(0, 70_001, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","source":["# Сравнение лучших моделей (без проигрышей)\n","models = [26500, 27000, 28000, 29000, 30000, 30500, 34500, 36500, 38500, 39500, 40000,\n","          40500, 41500, 42000, 42500, 43000, 43500, 44500, 45000, 45500, 47500,\n","          48000, 49000, 50000, 51500, 52000, 52500, 53000, 53500, 54000, 54500,\n","          55000, 55500, 56000, 57000, 59500, 60000, 60500, 61000, 61500, 62000,\n","          63500, 64000, 64500, 65000, 66000, 66500, 67500, 69000]\n","\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for model in models:\n","    agent.load_state_dict(torch.load(f'{PATH}model_{model}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(10_000)\n","    print(model, eval_game.wins)"],"metadata":{"id":"b9LIq2qJIT0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1718576553007,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"sT5QLsvSj0-2","outputId":"68df685b-7a30-439f-daf5-75d5154dbabb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["# Загрузка самой лучшей модели\n","agent.load_state_dict(torch.load(f'{PATH}model_95500', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":60917,"status":"error","timestamp":1718576616493,"user":{"displayName":"Олег Дуров","userId":"00246120506671741909"},"user_tz":-180},"id":"_bgzNN9tsPVN","outputId":"4c89c203-3e49-43a5-ba30-896ccd918a7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  .  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  .  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 4\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  X  .  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  X  O  X  .  .  .\n"," .  .  .  X  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  X  O  X  .  .  .\n"," .  .  .  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  .  .  .\n"," .  X  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  .  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  X  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","7 3\n","player 1's turn:\n"," .  .  .  .  .  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  X  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .  .  X\n"," .  .  O  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  X  .\n"," .  .  O  X  X  .  .\n"," .  .  .  O  .  .  .\n"," .  .  O  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","6 3\n","player 1's turn:\n"," .  .  .  .  .  .  X\n"," .  .  O  O  .  .  .\n"," .  .  O  X  X  .  .\n"," .  X  O  X  .  X  .\n"," .  .  O  X  X  .  .\n"," .  .  O  O  .  .  .\n"," .  .  O  .  .  .  .\n","Победа (Human)!\n","\n","player -1's turn:\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n",". . . . . . .\n","Введите ваш ход (Строка, столбец)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-44f6ae1e7b31>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHuman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-12f108871000>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, num_games, visualize)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mstate_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mcurrent_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_player\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mnext_state_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstate_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_state_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#state, action, reward, new_state, done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-4b0eda9a0e6f>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstate2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Введите ваш ход (Строка, столбец)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Клетка занята!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["agent.epsilon = 0\n","test_game = TicTacToe(agent, Human(), board_size=board_size, win_size=win_size)\n","test_game.play(4, True)\n","test_game.wins"]},{"cell_type":"markdown","metadata":{"id":"TAq9ckumpm01"},"source":["# Первый ход за крестики и значения $Q$-фунцкии в начальном состоянии"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1718562904401,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"aKjltLQC1-vk","outputId":"4eeacc16-0953-4d2c-8386-ee747857564f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 3)"]},"metadata":{},"execution_count":26}],"source":["state2d = torch.tensor(np.zeros((1, 7, 7))).to(device)\n","\n","q_values = agent(state2d).squeeze(0).detach().cpu().numpy()\n","np.unravel_index(q_values.argmax(), q_values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1718562908136,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"id":"dTKnN9UG4TJN","outputId":"23486e20-ef3e-471d-b152-18788c98364b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.0684, -0.064 , -0.0358, -0.0494, -0.0263, -0.0711, -0.0195],\n","       [-0.0457, -0.0207, -0.0132, -0.0035, -0.0091, -0.029 , -0.0438],\n","       [-0.0156, -0.0113,  0.0434,  0.0295,  0.0367, -0.0051, -0.0104],\n","       [-0.0425, -0.0255,  0.0354,  0.0539,  0.0183, -0.0157, -0.0361],\n","       [-0.0721, -0.0236,  0.0205,  0.0216,  0.0134, -0.0366, -0.0267],\n","       [-0.0979, -0.0705, -0.0431, -0.0291, -0.044 , -0.0472, -0.0386],\n","       [-0.0893, -0.0818, -0.0544, -0.0399, -0.0268, -0.0384, -0.0467]],\n","      dtype=float32)"]},"metadata":{},"execution_count":27}],"source":["q_values.round(4)"]},{"cell_type":"code","source":[],"metadata":{"id":"oQftoeFoVOU4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1wqCozfdeRJnqyq9lgTKHqqbIOJ70UoZc","timestamp":1718484277044},{"file_id":"17AdIcgMxS_7_mOiy7FUK1C5VUgC8F-8_","timestamp":1718460691857},{"file_id":"1Gr04QBn85xAghWhQrafFAC3IVYCCcrdF","timestamp":1718270221903},{"file_id":"1tYpwZfpcc8mwjf9xBvf2Qh4nBVyZDdDi","timestamp":1718209975048},{"file_id":"1srwb210ZiHsQBrRBDRQ5YvK6o5ZuV2x9","timestamp":1718193488488},{"file_id":"17BHq081ewJDS6eZRZvxiWWTUVu9adCx1","timestamp":1718173770359}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
