{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jas5z2XbgpIK"},"outputs":[],"source":["import numpy as np\n","from collections import deque\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1718803877549,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"eGa4uhXjfHDA","outputId":"1813c484-8b21-489d-cc4d-96586a28cb6b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","metadata":{"id":"Q9aoBPtbKYgm"},"source":["#Игра"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkV_S73IfMyq"},"outputs":[],"source":["# Игра крестики-нолики\n","class TicTacToe:\n","    def __init__(self, player_1, player_2, board_size=3, win_size=3):\n","        self.players = {-1: player_1,\n","                         1: player_2}\n","\n","        self.wins = {player_1.name: 0,\n","                     player_2.name: 0}\n","\n","        self.board_size=board_size\n","        self.win_size = win_size\n","        self._kernel = self._create_kernel()\n","\n","\n","    # Создает ядро свертки для расчета побед\n","    def _create_kernel(self):\n","        kernel = np.zeros((2 * self.win_size + 2, self.win_size, self.win_size))\n","        for i in range(self.win_size):\n","            kernel[i, i, :] = np.ones(self.win_size)\n","        for i in range(self.win_size, 2 * self.win_size):\n","            kernel[i, :, i - self.win_size] = np.ones(self.win_size).T\n","        kernel[2 * self.win_size] = np.eye(self.win_size)\n","        kernel[2 * self.win_size + 1] = np.fliplr(np.eye(self.win_size))\n","        return kernel\n","\n","\n","    # Проверяет победы для состояний states, в кот. ходы были совершены игроками turns, turn={-1, 1}\n","    def _test_win(self, state, turn):\n","        rows, cols, w_size = *state.shape, self.win_size\n","        expanded_states = np.lib.stride_tricks.as_strided(\n","            state,\n","            shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","            strides=(*state.strides, *state.strides),\n","            writeable=False,\n","        )\n","        feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","        return -turn * (feature_map == turn * w_size).any().astype(int)\n","\n","\n","    # Проигрывание нескольких полных эпизодов\n","    def play(self, num_games=1, visualize=False):\n","        transitions = []\n","        for t in range(num_games):\n","            next_turn = turn = -1\n","            state = (np.zeros((self.board_size, self.board_size)), turn) # Начальное состояние игры. state = (state2d, turn)\n","            if visualize:\n","                self.visualize_state(state, turn)\n","            while(next_turn != 0):\n","                state_2d, turn = state\n","                current_player = self.players[turn]\n","                action = current_player.get_action(state)\n","                next_state_2d, next_turn, reward = self.play_turn(state, action)\n","                transitions.append((turn * state_2d, action, reward, -turn * next_state_2d, next_turn == 0))   #state, action, reward, new_state, done\n","                if visualize:\n","                    self.visualize_state((next_state_2d, next_turn), turn)\n","                if next_turn == 0:\n","                    if visualize:\n","                        if (reward == 0): print('Ничья!\\n')\n","                        else: print(f'Победа ({self.players[reward * turn].name})!\\n')\n","                    if reward != 0:\n","                        self.wins[self.players[reward * turn].name] += 1\n","                    self.players = {-1: self.players[1], 1: self.players[-1]}\n","                state = next_state_2d, next_turn\n","        return transitions\n","\n","\n","    # Выполнение хода и проверка на некорректный ход (проигрышь) / выигрыш / ничью\n","    def play_turn(self, state, action): # next_state2d, next_turn, reward\n","        state2d, turn = state\n","        next_state2d = state2d.copy()\n","\n","        # Проверка корректности хода\n","        if (state2d[(action)] != 0):\n","            return next_state2d, 0, -1        # Игрок проиграл (# next_turn == 0 => Игра окончена)\n","\n","        # Совершение хода\n","        next_state2d[action] = turn\n","\n","        # Проверка победы\n","        if self._test_win(next_state2d, turn):\n","            return next_state2d, 0, 1         # Текущий игрок побеждает (next_turn == 0 => Игра окончена)\n","\n","        # Проверка ничьи\n","        if (next_state2d != 0).all():\n","            return next_state2d, 0, 0         # Ничья (next_turn == 0 => Игра окончена)\n","\n","        # Инчае, ход следующего игрока\n","        return next_state2d, -turn, 0         # next_turn == -turn => Смена хода\n","\n","\n","    # Выводит на экран состояние игры после хода игрока\n","    @staticmethod\n","    def visualize_state(next_state, turn):\n","        next_state2d, next_turn = next_state\n","        print(f\"player {turn}'s turn:\")\n","        if (next_state2d == 0).all() and turn == 0:\n","            print(\"[invalid state]\\n\\n\")\n","        else:\n","            print(str(next_state2d)\n","                  .replace(\".\", \"\")\n","                  .replace(\"[[\", \"\")\n","                  .replace(\" [\", \"\")\n","                  .replace(\"]]\", \"\")\n","                  .replace(\"]\", \"\")\n","                  .replace(\"-0\", \" .\")\n","                  .replace(\"0\", \".\")\n","                  .replace(\"-1\", \" X\")\n","                  .replace(\"1\", \"O\")\n","            )\n","\n","\n","    @staticmethod\n","    def print_transitions(transitions):\n","        states, actions, rewards, next_states, dones = zip(*transitions)\n","        for i in np.arange(len(states)):\n","            print(\"\\033[31m{}.\".format(i + 1), '\\033[30m')\n","            TicTacToe.visualize_state((next_states[i], -1), 1)\n","            print('\\naction = ', actions[i] + np.array([1, 1]), end='\\n')\n","            print('reward = ', rewards[i], end='\\n')\n","            if (dones[i]): print('Игра окончена', end='\\n\\n')\n","            else: print('Игра продолжается', end='\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"M3pr2-P0Ka5F"},"source":["#Игроки"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5rtWxp4hTVB"},"outputs":[],"source":["class Human:\n","    def __init__(self, name='Human'):\n","        self.name = name\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        print('Введите ваш ход (Строка, столбец)')\n","        row, col = map(int, input().split())\n","        while (state2d[row - 1, col - 1] != 0):\n","            print('Клетка занята!')\n","            print('Введите ваш ход (Строка, столбец)')\n","            row, col = map(int, input().split())\n","        return row - 1, col - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPVMOC0qTIlK"},"outputs":[],"source":["# Игрок Рандом с преимуществами:\n","# 1. Если есть возможность выиграть за один ход, он делает это (win = True)\n","# 2. Если у соперника есть возможность выиграть в следующем ходу, он блокирует этот ход (defense = True)\n","# 3. Если есть возможность построить четверку, он делает это (win_2 = True)\n","# 4. Если у соперника есть возможность построить четверку в следующем ходу, он блокирует этот ход (defense_2 = True)\n","# 5. Иначе, выбирает случайный ход из множества допустимых\n","class RandomPlus:\n","    def __init__(self, board_size=3, win_size=3, name='RandomPlus',\n","                 win=False, defense=False, win_2=False, defense_2=False):\n","        self.name = name\n","        self.board_size = board_size\n","        self.win_size = win_size\n","\n","        self.win = win\n","        self.defense = defense\n","\n","        self.win_2 = win_2\n","        self.defense_2 = defense_2\n","\n","        if win or defense:\n","            self._kernel = self._create_kernel(win_size)\n","\n","        if win_2 or defense_2:\n","            self._kernel_2 = self._create_kernel(win_size - 1)\n","\n","\n","    # Создает ядро свертки для расчета потенциальных побед\n","    def _create_kernel(self, win_size):\n","        kernel = np.zeros((2 * win_size + 2, win_size, win_size))\n","        for i in range(win_size):\n","            kernel[i, i, :] = np.ones(win_size)\n","        for i in range(win_size, 2 * win_size):\n","            kernel[i, :, i - win_size] = np.ones(win_size).T\n","        kernel[2 * win_size] = np.eye(win_size)\n","        kernel[2 * win_size + 1] = np.fliplr(np.eye(win_size))\n","        return kernel\n","\n","\n","    def get_action(self, state):\n","        state2d, turn = state\n","        rows, cols, w_size = *state2d.shape, self.win_size\n","\n","        if self.win or self.defense:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 1, cols - w_size + 1, w_size, w_size),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel)\n","\n","            if self.win:\n","                wins = np.array(np.where(turn * feature_map == w_size - 1))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 1))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel[K] == 1), (state2d[I: I + w_size, J: J + w_size] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        if self.win_2 or self.defense_2:\n","            expanded_states = np.lib.stride_tricks.as_strided(\n","                state2d,\n","                shape=(rows - w_size + 2, cols - w_size + 2, w_size - 1, w_size - 1),\n","                strides=(*state2d.strides, *state2d.strides),\n","                writeable=False,\n","            )\n","            feature_map = np.einsum('xyij,sij->sxy', expanded_states, self._kernel_2)\n","\n","            if self.win_2:\n","                wins = np.array(np.where(turn * feature_map == w_size - 2))\n","                if wins.shape[1] > 0:\n","                    index = np.random.randint(0, wins.shape[1])\n","                    K, I, J = wins[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","            if self.defense_2:\n","                defenses = np.array(np.where(-turn * feature_map == w_size - 2))\n","                if defenses.shape[1] > 0:\n","                    index = np.random.randint(0, defenses.shape[1])\n","                    K, I, J = defenses[:, index]\n","                    indxs = np.where(np.logical_and((self._kernel_2[K] == 1), (state2d[I: I + w_size - 1, J: J + w_size - 1] == 0)))\n","                    return tuple(np.array(indxs)[:, 0] + [I, J])\n","\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRBw9v0hmVIi"},"outputs":[],"source":["class DQNAgent(nn.Module):\n","    def __init__(self, epsilon=0, name='DQNAgent', masking=False):\n","        super().__init__()\n","\n","        self.name = name\n","        self.epsilon = epsilon\n","        self.n_channels = 3\n","        self.masking = masking    # Маскирование (ВКЛЮЧАТЬ ТОЛЬКО ПРИ ИНФЕРЕНСЕ)\n","\n","        self.network = nn.Sequential(\n","            nn.Conv2d(self.n_channels, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 128, kernel_size=(3, 3), padding='same'),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 1, kernel_size=(3, 3), padding='same')\n","        )\n","\n","    def forward(self, x):\n","        x = torch.stack([x == 1, x == -1, x == 0], axis=1).float()\n","        return self.network(x).squeeze(1)\n","\n","    def greedy_action(self, state, device=device):\n","        state2d, turn = state\n","        state_t = torch.FloatTensor(turn * state2d).unsqueeze(0).to(device)\n","        q_values = self.forward(state_t).squeeze(0).detach().cpu().numpy()\n","        if self.masking:\n","            q_values[state2d != 0] = -float(\"Inf\")\n","        return np.unravel_index(q_values.argmax(), q_values.shape)\n","\n","    def random_action(self, state):\n","        state2d, turn = state\n","        zero_idxs = np.argwhere(state2d == 0)\n","        return tuple(zero_idxs[np.random.randint(len(zero_idxs))])\n","\n","    def get_action(self, state):\n","        if random.random() < self.epsilon:\n","            action = self.random_action(state)\n","        else:\n","            action = self.greedy_action(state)\n","        return action"]},{"cell_type":"markdown","source":["# Буферы"],"metadata":{"id":"03J3GWj6P8tj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ni-Mh6jE_-Xd"},"outputs":[],"source":["# Обычный буфер\n","class ReplayBuffer(object):\n","    def __init__(self, size):\n","        self._storage = deque(maxlen=size)\n","\n","    def __len__(self):\n","        return len(self._storage)\n","\n","    def add(self, transition):\n","        self._storage.append(transition)\n","\n","    def sample(self, batch_size, augmentation=False):\n","        batch = random.sample(self._storage, batch_size)\n","        states, actions, rewards, next_states, dones = zip(*batch)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            # ======== ДЛЯ ВСЕГО БАТЧА ОДИНАКОВАЯ АУГМЕНТАЦИЯ ========\n","            # n = states.shape[-1] - 1\n","            # k = np.random.randint(0, 4)\n","            # states = np.rot90(states, k, axes=(1,2)).copy()\n","            # next_states = np.rot90(next_states, k, axes=(1,2)).copy()\n","\n","            # i, j = actions[:, 0], actions[:, 1]\n","            # if k == 1: actions = np.column_stack((n - j, i))\n","            # if k == 2: actions = np.column_stack((n - i, n - j))\n","            # if k == 3: actions = np.column_stack((j, n - i))\n","\n","\n","            # ======== ДЛЯ КАЖДОГО ЭЛЕМЕНТА БАТЧА ОТДЕЛЬНО ========\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","\n","            # ======== УВЕЛИЧЕНИЕ X4 ========\n","            # n = states.shape[-1] - 1\n","            # i, j = actions[:, 0], actions[:, 1]\n","\n","            # states = np.concatenate([np.rot90(states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # next_states = np.concatenate([np.rot90(next_states, k, axes=(1, 2)) for k in range(4)], axis=0)\n","            # actions = np.concatenate([actions,\n","            #                           np.column_stack((n - j, i)),\n","            #                           np.column_stack((n - i, n - j)),\n","            #                           np.column_stack((j, n - i))], axis=0)\n","            # rewards = np.tile(rewards, 4)\n","            # dones = np.tile(dones, 4)\n","\n","        return states, actions, rewards, next_states, dones"]},{"cell_type":"code","source":["# =========== Prioritized Replay Buffer With Augmentation ===========\n","class PrioritizedBuffer(object):\n","    def __init__(self, capacity, prob_alpha=0.6):\n","        self.prob_alpha = prob_alpha\n","        self.capacity = capacity\n","        self.buffer = []\n","        self.pos = 0\n","        self.priorities = np.zeros((capacity,), dtype=np.float32)\n","\n","    def add(self, state, action, reward, next_state, done):\n","        max_prio = self.priorities.max() if self.buffer else 1.0\n","\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append((state, action, reward, next_state, done))\n","        else:\n","            self.buffer[self.pos] = (state, action, reward, next_state, done)\n","\n","        self.priorities[self.pos] = max_prio\n","        self.pos = (self.pos + 1) % self.capacity\n","\n","    def sample(self, batch_size, beta=0.4, augmentation=False):\n","        if len(self.buffer) == self.capacity:\n","            prios = self.priorities\n","        else:\n","            prios = self.priorities[:self.pos]\n","\n","        probs  = prios ** self.prob_alpha\n","        probs /= probs.sum()\n","\n","        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n","        samples = [self.buffer[idx] for idx in indices]\n","\n","        total    = len(self.buffer)\n","        weights  = (total * probs[indices]) ** (-beta)\n","        weights /= weights.max()\n","        weights  = np.array(weights, dtype=np.float32)\n","\n","        states, actions, rewards, next_states, dones = zip(*samples)\n","        states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n","\n","        if augmentation:\n","            n = states.shape[-1] - 1\n","            k = np.random.randint(0, 4, size=batch_size)\n","\n","            mask = [None] * 4\n","            for i in range(1, 4):\n","                mask[i] = k == i\n","                states[mask[i]] = np.rot90(states[mask[i]], i, axes=(1, 2))\n","                next_states[mask[i]] = np.rot90(next_states[mask[i]], i, axes=(1, 2))\n","\n","            i, j = actions[:, 0], actions[:, 1]\n","            actions[mask[1]] = np.column_stack((n - j[mask[1]], i[mask[1]]))\n","            actions[mask[2]] = np.column_stack((n - i[mask[2]], n - j[mask[2]]))\n","            actions[mask[3]] = np.column_stack((j[mask[3]], n - i[mask[3]]))\n","\n","        return states, actions, rewards, next_states, dones, indices, weights\n","\n","    def update_priorities(self, batch_indices, batch_priorities):\n","        for idx, prio in zip(batch_indices, batch_priorities):\n","            self.priorities[idx] = prio\n","\n","    def __len__(self):\n","        return len(self.buffer)"],"metadata":{"id":"RYidASkNW5XC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32ujexFHKgAU"},"source":["#Функции и гиперпараметры для обучения"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWj7D_iuy3oT"},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRFnHMHaC7um"},"outputs":[],"source":["board_size = 5\n","win_size = 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_gPKyIB504V"},"outputs":[],"source":["# Гиперпараметры метода DQN\n","\n","batch_size = 128        # 512 - много\n","total_steps = 60_000\n","\n","decay_steps = 40_000\n","init_epsilon = 1\n","final_epsilon = 0.2     # 0.02 - мало; 0.1 - мало\n","\n","loss_freq = 100\n","refresh_target_network_freq = 100    # 1000 - много, 50 - мало\n","\n","eval_freq = 500\n","n_eval_games = 100\n","\n","max_grad_norm = 50\n","\n","gamma = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuZM4BiVn_8X"},"outputs":[],"source":["agent = DQNAgent(init_epsilon).to(device)\n","\n","target_network = DQNAgent(init_epsilon).to(device)\n","target_network.load_state_dict(agent.state_dict())\n","\n","optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n","exp_replay = PrioritizedBuffer(16_000) #ReplayBuffer(16_000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1718803884017,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"-ZJT-NWjTE9g","outputId":"a625b706-a22c-4b52-eee0-623216a6be45"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1185025"]},"metadata":{},"execution_count":13}],"source":["sum([p.numel() for p in agent.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKGcoDrQCzXi"},"outputs":[],"source":["# Возвращает temporal difference loss\n","def compute_td_loss(states, actions, rewards, next_states, dones,\n","                    agent, target_network, weights=None, indices=None,\n","                    gamma=0.9, device=device, prioritized=True):\n","\n","    states = torch.tensor(states, device=device, dtype=torch.float32)                # shape: [batch_size, state_dim]\n","    actions = torch.tensor(actions, device=device, dtype=torch.int64)                # shape: [batch_size]\n","    rewards = torch.tensor(rewards, device=device, dtype=torch.float32)              # shape: [batch_size]\n","    next_states = torch.tensor(next_states, device=device, dtype=torch.float32)      # shape: [batch_size, state_dim]\n","    dones = torch.tensor(dones, device=device, dtype=torch.int64)                    # shape: [batch_size]\n","    weights = torch.tensor(weights, device=device, dtype=torch.float32)\n","\n","    predicted_qvalues = agent(states)                                                # shape: [batch_size, n_actions]\n","    predicted_next_qvalues = target_network(next_states)                             # shape: [batch_size, n_actions]\n","    predicted_qvalues_for_actions = predicted_qvalues[range(len(actions)), actions[:, 0], actions[:, 1]]  # shape: [batch_size]\n","    next_state_values = predicted_next_qvalues.view(dones.shape[0], -1).max(axis=1).values\n","    target_qvalues_for_actions = rewards - (1 - dones) * gamma * next_state_values\n","\n","    if prioritized:\n","        loss = weights * (predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2\n","        prios = (loss + 1e-5).data.cpu().numpy()  # Обновление приоритетов [Prioterized DQN]\n","        loss = torch.mean(loss)\n","        exp_replay.update_priorities(indices, prios)\n","        return loss\n","    else:\n","        return torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)  #loss\n","\n","# Рассчитывает epsilon на текущем шаге step\n","def linear_decay(init_epsilon, final_epsilon, step, decay_steps):\n","    return max(init_epsilon - step * (init_epsilon - final_epsilon) / decay_steps, final_epsilon)"]},{"cell_type":"markdown","metadata":{"id":"e73vABV6cKH2"},"source":["# Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22069,"status":"ok","timestamp":1718803906070,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"IigXAGYNdoU7","outputId":"eaedc609-6759-4933-f93d-6c29aa1be783"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVtRXPFnZ1ug"},"outputs":[],"source":["main_random = RandomPlus(board_size, win_size, win=True)\n","game = TicTacToe(agent, main_random, board_size=board_size, win_size=win_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4mXgvfVsN-2"},"outputs":[],"source":["PATH = f'/content/drive/MyDrive/TicTacToe_11/'\n","\n","loss = None\n","loss_values = []\n","reward_values = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSNH2zNO3fVB","outputId":"e1d40be3-5048-4330-eec4-9a6cee3929e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 0    \t reward = -1.0\t{'DQNAgent': 0, 'RandomPlus': 100}\n","\n","t = 100  \t loss = 0.0013881123159080744\t eps = 0.998\n","t = 200  \t loss = 0.003986238501966\t eps = 0.996\n","t = 300  \t loss = 0.003425873816013336\t eps = 0.994\n","t = 400  \t loss = 0.007009033113718033\t eps = 0.992\n","t = 500  \t loss = 0.0031843779142946005\t eps = 0.99\n","t = 500  \t reward = -0.72\t{'DQNAgent': 14, 'RandomPlus': 86}\n","\n","t = 600  \t loss = 0.005009326618164778\t eps = 0.988\n","t = 700  \t loss = 0.005027949810028076\t eps = 0.986\n","t = 800  \t loss = 0.006607561372220516\t eps = 0.984\n","t = 900  \t loss = 0.0037566833198070526\t eps = 0.982\n","t = 1000 \t loss = 0.005147852934896946\t eps = 0.98\n","t = 1000 \t reward = -0.82\t{'DQNAgent': 9, 'RandomPlus': 91}\n","\n","t = 1100 \t loss = 0.004279031418263912\t eps = 0.978\n","t = 1200 \t loss = 0.006132327951490879\t eps = 0.976\n","t = 1300 \t loss = 0.003267318941652775\t eps = 0.974\n","t = 1400 \t loss = 0.004802246578037739\t eps = 0.972\n","t = 1500 \t loss = 0.003764278255403042\t eps = 0.97\n","t = 1500 \t reward = -0.8\t{'DQNAgent': 10, 'RandomPlus': 90}\n","\n","t = 1600 \t loss = 0.0040147388353943825\t eps = 0.968\n","t = 1700 \t loss = 0.002080756239593029\t eps = 0.966\n","t = 1800 \t loss = 0.0036802059039473534\t eps = 0.964\n","t = 1900 \t loss = 0.003591245971620083\t eps = 0.962\n","t = 2000 \t loss = 0.003120110835880041\t eps = 0.96\n","t = 2000 \t reward = -0.54\t{'DQNAgent': 23, 'RandomPlus': 77}\n","\n","t = 2100 \t loss = 0.002512920880690217\t eps = 0.958\n","t = 2200 \t loss = 0.002169070765376091\t eps = 0.956\n","t = 2300 \t loss = 0.0025531952269375324\t eps = 0.954\n","t = 2400 \t loss = 0.0022739823907613754\t eps = 0.952\n","t = 2500 \t loss = 0.00246988283470273\t eps = 0.95\n","t = 2500 \t reward = -0.72\t{'DQNAgent': 14, 'RandomPlus': 86}\n","\n","t = 2600 \t loss = 0.0023480625823140144\t eps = 0.948\n","t = 2700 \t loss = 0.0024800733663141727\t eps = 0.946\n","t = 2800 \t loss = 0.002326294081285596\t eps = 0.944\n","t = 2900 \t loss = 0.0014519840478897095\t eps = 0.942\n","t = 3000 \t loss = 0.001687152893282473\t eps = 0.94\n","t = 3000 \t reward = -0.18\t{'DQNAgent': 41, 'RandomPlus': 59}\n","\n","t = 3100 \t loss = 0.0015941598685458302\t eps = 0.938\n","t = 3200 \t loss = 0.0021717774216085672\t eps = 0.936\n","t = 3300 \t loss = 0.0022898984607309103\t eps = 0.934\n","t = 3400 \t loss = 0.0016613067127764225\t eps = 0.932\n","t = 3500 \t loss = 0.001855495385825634\t eps = 0.93\n","t = 3500 \t reward = -0.02\t{'DQNAgent': 49, 'RandomPlus': 51}\n","\n","t = 3600 \t loss = 0.002687104046344757\t eps = 0.928\n","t = 3700 \t loss = 0.0014516926603391767\t eps = 0.926\n","t = 3800 \t loss = 0.001702458830550313\t eps = 0.924\n","t = 3900 \t loss = 0.0032784375362098217\t eps = 0.922\n","t = 4000 \t loss = 0.0011786181712523103\t eps = 0.92\n","t = 4000 \t reward = -0.06\t{'DQNAgent': 47, 'RandomPlus': 53}\n","\n","t = 4100 \t loss = 0.0016415349673479795\t eps = 0.918\n","t = 4200 \t loss = 0.0017113969661295414\t eps = 0.916\n","t = 4300 \t loss = 0.0012673260644078255\t eps = 0.914\n","t = 4400 \t loss = 0.0015279250219464302\t eps = 0.912\n","t = 4500 \t loss = 0.0010346563067287207\t eps = 0.91\n","t = 4500 \t reward = 0.14\t{'DQNAgent': 57, 'RandomPlus': 43}\n","\n","t = 4600 \t loss = 0.001141546992585063\t eps = 0.908\n","t = 4700 \t loss = 0.00169988046400249\t eps = 0.906\n","t = 4800 \t loss = 0.0017111522611230612\t eps = 0.904\n","t = 4900 \t loss = 0.0011450443416833878\t eps = 0.902\n","t = 5000 \t loss = 0.0015983912162482738\t eps = 0.9\n","t = 5000 \t reward = 0.4\t{'DQNAgent': 70, 'RandomPlus': 30}\n","\n","t = 5100 \t loss = 0.0015019476413726807\t eps = 0.898\n","t = 5200 \t loss = 0.0009694159380160272\t eps = 0.896\n","t = 5300 \t loss = 0.001220221514813602\t eps = 0.894\n","t = 5400 \t loss = 0.0016688178293406963\t eps = 0.892\n","t = 5500 \t loss = 0.000992370885796845\t eps = 0.89\n","t = 5500 \t reward = 0.08\t{'DQNAgent': 54, 'RandomPlus': 46}\n","\n","t = 5600 \t loss = 0.0016012974083423615\t eps = 0.888\n","t = 5700 \t loss = 0.0008571231737732887\t eps = 0.886\n","t = 5800 \t loss = 0.0014106276212260127\t eps = 0.884\n","t = 5900 \t loss = 0.0010420826729387045\t eps = 0.882\n","t = 6000 \t loss = 0.0019422045443207026\t eps = 0.88\n","t = 6000 \t reward = 0.58\t{'DQNAgent': 79, 'RandomPlus': 21}\n","\n","t = 6100 \t loss = 0.0013921161880716681\t eps = 0.878\n","t = 6200 \t loss = 0.0013435193104669452\t eps = 0.876\n","t = 6300 \t loss = 0.0010636814404278994\t eps = 0.874\n","t = 6400 \t loss = 0.0017452251631766558\t eps = 0.872\n","t = 6500 \t loss = 0.0012554384302347898\t eps = 0.87\n","t = 6500 \t reward = 0.66\t{'DQNAgent': 83, 'RandomPlus': 17}\n","\n","t = 6600 \t loss = 0.0006805880693718791\t eps = 0.868\n","t = 6700 \t loss = 0.001045029261149466\t eps = 0.866\n","t = 6800 \t loss = 0.0010221300181001425\t eps = 0.864\n","t = 6900 \t loss = 0.0014549505431205034\t eps = 0.862\n","t = 7000 \t loss = 0.0009748864104039967\t eps = 0.86\n","t = 7000 \t reward = 0.7\t{'DQNAgent': 85, 'RandomPlus': 15}\n","\n","t = 7100 \t loss = 0.0010678782127797604\t eps = 0.858\n","t = 7200 \t loss = 0.000939609541092068\t eps = 0.856\n","t = 7300 \t loss = 0.0014171894872561097\t eps = 0.854\n","t = 7400 \t loss = 0.00038496864726766944\t eps = 0.852\n","t = 7500 \t loss = 0.0016455526929348707\t eps = 0.85\n","t = 7500 \t reward = 0.68\t{'DQNAgent': 84, 'RandomPlus': 16}\n","\n","t = 7600 \t loss = 0.0026406035758554935\t eps = 0.848\n","t = 7700 \t loss = 0.0007226304733194411\t eps = 0.846\n","t = 7800 \t loss = 0.0012399477418512106\t eps = 0.844\n","t = 7900 \t loss = 0.0014899758389219642\t eps = 0.842\n","t = 8000 \t loss = 0.0009507212089374661\t eps = 0.84\n","t = 8000 \t reward = 0.8\t{'DQNAgent': 90, 'RandomPlus': 10}\n","\n","t = 8100 \t loss = 0.0011361059732735157\t eps = 0.838\n","t = 8200 \t loss = 0.0009339068201370537\t eps = 0.836\n","t = 8300 \t loss = 0.0011586558539420366\t eps = 0.834\n","t = 8400 \t loss = 0.0012348261661827564\t eps = 0.832\n","t = 8500 \t loss = 0.0008696079603396356\t eps = 0.83\n","t = 8500 \t reward = 0.84\t{'DQNAgent': 92, 'RandomPlus': 8}\n","\n","t = 8600 \t loss = 0.0015980703756213188\t eps = 0.828\n","t = 8700 \t loss = 0.0008802737575024366\t eps = 0.826\n","t = 8800 \t loss = 0.0012219380587339401\t eps = 0.824\n","t = 8900 \t loss = 0.0010067950934171677\t eps = 0.822\n","t = 9000 \t loss = 0.0024633174762129784\t eps = 0.82\n","t = 9000 \t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 9100 \t loss = 0.0012430016649886966\t eps = 0.818\n","t = 9200 \t loss = 0.0007557307835668325\t eps = 0.816\n","t = 9300 \t loss = 0.00108499510679394\t eps = 0.814\n","t = 9400 \t loss = 0.0010519681964069605\t eps = 0.812\n","t = 9500 \t loss = 0.0011774718295782804\t eps = 0.81\n","t = 9500 \t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 9600 \t loss = 0.0007820422761142254\t eps = 0.808\n","t = 9700 \t loss = 0.0009079909650608897\t eps = 0.806\n","t = 9800 \t loss = 0.0006027559284120798\t eps = 0.804\n","t = 9900 \t loss = 0.0011048525338992476\t eps = 0.802\n","t = 10000\t loss = 0.0005995891406200826\t eps = 0.8\n","t = 10000\t reward = 0.82\t{'DQNAgent': 91, 'RandomPlus': 9}\n","\n","t = 10100\t loss = 0.0013163810363039374\t eps = 0.798\n","t = 10200\t loss = 0.0010486654937267303\t eps = 0.796\n","t = 10300\t loss = 0.001194502110593021\t eps = 0.794\n","t = 10400\t loss = 0.0007952054729685187\t eps = 0.792\n","t = 10500\t loss = 0.0005860250676050782\t eps = 0.79\n","t = 10500\t reward = 0.88\t{'DQNAgent': 93, 'RandomPlus': 5}\n","\n","t = 10600\t loss = 0.0015014857053756714\t eps = 0.788\n","t = 10700\t loss = 0.00120959198102355\t eps = 0.786\n","t = 10800\t loss = 0.000767675053793937\t eps = 0.784\n","t = 10900\t loss = 0.0018963469192385674\t eps = 0.782\n","t = 11000\t loss = 0.000986616127192974\t eps = 0.78\n","t = 11000\t reward = 0.76\t{'DQNAgent': 87, 'RandomPlus': 11}\n","\n","t = 11100\t loss = 0.0010619810782372952\t eps = 0.778\n","t = 11200\t loss = 0.0006867792690172791\t eps = 0.776\n","t = 11300\t loss = 0.0006237170309759676\t eps = 0.774\n","t = 11400\t loss = 0.0007027096580713987\t eps = 0.772\n","t = 11500\t loss = 0.0008072769269347191\t eps = 0.77\n","t = 11500\t reward = 0.75\t{'DQNAgent': 86, 'RandomPlus': 11}\n","\n","t = 11600\t loss = 0.0006559236790053546\t eps = 0.768\n","t = 11700\t loss = 0.0008819439681246877\t eps = 0.766\n","t = 11800\t loss = 0.0008390675066038966\t eps = 0.764\n","t = 11900\t loss = 0.0004784691845998168\t eps = 0.762\n","t = 12000\t loss = 0.0008313882281072438\t eps = 0.76\n","t = 12000\t reward = 0.88\t{'DQNAgent': 94, 'RandomPlus': 6}\n","\n","t = 12100\t loss = 0.0007857691962271929\t eps = 0.758\n","t = 12200\t loss = 0.0007043993100523949\t eps = 0.756\n","t = 12300\t loss = 0.0008367964765056968\t eps = 0.754\n","t = 12400\t loss = 0.00052286172285676\t eps = 0.752\n","t = 12500\t loss = 0.0009760844986885786\t eps = 0.75\n","t = 12500\t reward = 0.87\t{'DQNAgent': 93, 'RandomPlus': 6}\n","\n","t = 12600\t loss = 0.0011971802450716496\t eps = 0.748\n","t = 12700\t loss = 0.00059348507784307\t eps = 0.746\n","t = 12800\t loss = 0.0018254899187013507\t eps = 0.744\n","t = 12900\t loss = 0.0007524110842496157\t eps = 0.742\n","t = 13000\t loss = 0.0007849211106076837\t eps = 0.74\n","t = 13000\t reward = 0.83\t{'DQNAgent': 91, 'RandomPlus': 8}\n","\n","t = 13100\t loss = 0.0006459700525738299\t eps = 0.738\n","t = 13200\t loss = 0.0008628708310425282\t eps = 0.736\n","t = 13300\t loss = 0.0006597276660613716\t eps = 0.734\n","t = 13400\t loss = 0.0012588262325152755\t eps = 0.732\n","t = 13500\t loss = 0.0012014927342534065\t eps = 0.73\n","t = 13500\t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 13600\t loss = 0.0010952732991427183\t eps = 0.728\n","t = 13700\t loss = 0.0005534781375899911\t eps = 0.726\n","t = 13800\t loss = 0.0012088812654837966\t eps = 0.724\n","t = 13900\t loss = 0.0008859500521793962\t eps = 0.722\n","t = 14000\t loss = 0.0011673589469864964\t eps = 0.72\n","t = 14000\t reward = 0.87\t{'DQNAgent': 93, 'RandomPlus': 6}\n","\n","t = 14100\t loss = 0.0006510654930025339\t eps = 0.718\n","t = 14200\t loss = 0.0008357169572263956\t eps = 0.716\n","t = 14300\t loss = 0.000656098301988095\t eps = 0.714\n","t = 14400\t loss = 0.0012601080816239119\t eps = 0.712\n","t = 14500\t loss = 0.00091321743093431\t eps = 0.71\n","t = 14500\t reward = 0.89\t{'DQNAgent': 94, 'RandomPlus': 5}\n","\n","t = 14600\t loss = 0.0005599327851086855\t eps = 0.708\n","t = 14700\t loss = 0.0005849720910191536\t eps = 0.706\n","t = 14800\t loss = 0.00045408273581415415\t eps = 0.704\n","t = 14900\t loss = 0.0008847024873830378\t eps = 0.702\n","t = 15000\t loss = 0.0008306233212351799\t eps = 0.7\n","t = 15000\t reward = 0.91\t{'DQNAgent': 94, 'RandomPlus': 3}\n","\n","t = 15100\t loss = 0.0007994739571586251\t eps = 0.698\n","t = 15200\t loss = 0.0010285897878929973\t eps = 0.696\n","t = 15300\t loss = 0.0005094139487482607\t eps = 0.694\n","t = 15400\t loss = 0.0006737298099324107\t eps = 0.692\n","t = 15500\t loss = 0.0005520982667803764\t eps = 0.69\n","t = 15500\t reward = 0.93\t{'DQNAgent': 96, 'RandomPlus': 3}\n","\n","t = 15600\t loss = 0.00141329993493855\t eps = 0.688\n","t = 15700\t loss = 0.0007768227951601148\t eps = 0.686\n","t = 15800\t loss = 0.0007342682220041752\t eps = 0.684\n","t = 15900\t loss = 0.000544187321793288\t eps = 0.682\n","t = 16000\t loss = 0.0005395677872002125\t eps = 0.68\n","t = 16000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 16100\t loss = 0.0014275191351771355\t eps = 0.678\n","t = 16200\t loss = 0.001097563304938376\t eps = 0.676\n","t = 16300\t loss = 0.0008625480113551021\t eps = 0.674\n","t = 16400\t loss = 0.0006375141674652696\t eps = 0.672\n","t = 16500\t loss = 0.0006578166503459215\t eps = 0.67\n","t = 16500\t reward = 0.86\t{'DQNAgent': 92, 'RandomPlus': 6}\n","\n","t = 16600\t loss = 0.0006421137368306518\t eps = 0.668\n","t = 16700\t loss = 0.0005114718223921955\t eps = 0.666\n","t = 16800\t loss = 0.000596650643274188\t eps = 0.664\n","t = 16900\t loss = 0.0007208797615021467\t eps = 0.662\n","t = 17000\t loss = 0.0006403026636689901\t eps = 0.66\n","t = 17000\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 17100\t loss = 0.0008147865300998092\t eps = 0.658\n","t = 17200\t loss = 0.00057774200104177\t eps = 0.656\n","t = 17300\t loss = 0.0003543709754012525\t eps = 0.654\n","t = 17400\t loss = 0.001929482095874846\t eps = 0.652\n","t = 17500\t loss = 0.0005236112629063427\t eps = 0.65\n","t = 17500\t reward = 0.86\t{'DQNAgent': 93, 'RandomPlus': 7}\n","\n","t = 17600\t loss = 0.0009520688327029347\t eps = 0.648\n","t = 17700\t loss = 0.00035647855838760734\t eps = 0.646\n","t = 17800\t loss = 0.0006835267995484173\t eps = 0.644\n","t = 17900\t loss = 0.0010638192761689425\t eps = 0.642\n","t = 18000\t loss = 0.00038158101961016655\t eps = 0.64\n","t = 18000\t reward = 0.89\t{'DQNAgent': 94, 'RandomPlus': 5}\n","\n","t = 18100\t loss = 0.0012018023990094662\t eps = 0.638\n","t = 18200\t loss = 0.0007021715864539146\t eps = 0.636\n","t = 18300\t loss = 0.00036821773392148316\t eps = 0.634\n","t = 18400\t loss = 0.0007907106773927808\t eps = 0.632\n","t = 18500\t loss = 0.0004866491071879864\t eps = 0.63\n","t = 18500\t reward = 0.9\t{'DQNAgent': 93, 'RandomPlus': 3}\n","\n","t = 18600\t loss = 0.0006368050235323608\t eps = 0.628\n","t = 18700\t loss = 0.0007426595548167825\t eps = 0.626\n","t = 18800\t loss = 0.0007314805407077074\t eps = 0.624\n","t = 18900\t loss = 0.0007257622783072293\t eps = 0.622\n","t = 19000\t loss = 0.0005904759163968265\t eps = 0.62\n","t = 19000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 19100\t loss = 0.0006016463157720864\t eps = 0.618\n","t = 19200\t loss = 0.0007717482512816787\t eps = 0.616\n","t = 19300\t loss = 0.0006565426592715085\t eps = 0.614\n","t = 19400\t loss = 0.0007622267585247755\t eps = 0.612\n","t = 19500\t loss = 0.0007753008976578712\t eps = 0.61\n","t = 19500\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 19600\t loss = 0.00037882523611187935\t eps = 0.608\n","t = 19700\t loss = 0.0004723358142655343\t eps = 0.606\n","t = 19800\t loss = 0.0006071339012123644\t eps = 0.604\n","t = 19900\t loss = 0.0008884529815986753\t eps = 0.602\n","t = 20000\t loss = 0.0008366614929400384\t eps = 0.6\n","t = 20000\t reward = 0.92\t{'DQNAgent': 94, 'RandomPlus': 2}\n","\n","t = 20100\t loss = 0.0004792553372681141\t eps = 0.598\n","t = 20200\t loss = 0.0005301494966261089\t eps = 0.596\n","t = 20300\t loss = 0.0004944296670146286\t eps = 0.594\n","t = 20400\t loss = 0.0006394884549081326\t eps = 0.592\n","t = 20500\t loss = 0.000865244073793292\t eps = 0.59\n","t = 20500\t reward = 0.95\t{'DQNAgent': 96, 'RandomPlus': 1}\n","\n","t = 20600\t loss = 0.0005356419715099037\t eps = 0.588\n","t = 20700\t loss = 0.0014208543580025434\t eps = 0.586\n","t = 20800\t loss = 0.0006819219561293721\t eps = 0.584\n","t = 20900\t loss = 0.0006872470257803798\t eps = 0.582\n","t = 21000\t loss = 0.0005893477355130017\t eps = 0.58\n","t = 21000\t reward = 0.86\t{'DQNAgent': 91, 'RandomPlus': 5}\n","\n","t = 21100\t loss = 0.0008285454823635519\t eps = 0.578\n","t = 21200\t loss = 0.0007066029356792569\t eps = 0.576\n","t = 21300\t loss = 0.0004336198326200247\t eps = 0.574\n","t = 21400\t loss = 0.000662051432300359\t eps = 0.572\n","t = 21500\t loss = 0.0004937341436743736\t eps = 0.57\n","t = 21500\t reward = 0.92\t{'DQNAgent': 95, 'RandomPlus': 3}\n","\n","t = 21600\t loss = 0.0006464897887781262\t eps = 0.568\n","t = 21700\t loss = 0.0006288113072514534\t eps = 0.566\n","t = 21800\t loss = 0.0007348399376496673\t eps = 0.564\n","t = 21900\t loss = 0.00042435311479493976\t eps = 0.562\n","t = 22000\t loss = 0.0011325079249218106\t eps = 0.56\n","t = 22000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 22100\t loss = 0.00034694874193519354\t eps = 0.558\n","t = 22200\t loss = 0.000361663376679644\t eps = 0.556\n","t = 22300\t loss = 0.0012551264371722937\t eps = 0.554\n","t = 22400\t loss = 0.00036559440195560455\t eps = 0.552\n","t = 22500\t loss = 0.0005877047660760581\t eps = 0.55\n","t = 22500\t reward = 0.96\t{'DQNAgent': 98, 'RandomPlus': 2}\n","\n","t = 22600\t loss = 0.0005935802473686635\t eps = 0.548\n","t = 22700\t loss = 0.0005408501019701362\t eps = 0.546\n","t = 22800\t loss = 0.0002702205383684486\t eps = 0.544\n","t = 22900\t loss = 0.0007324069156311452\t eps = 0.542\n","t = 23000\t loss = 0.000463678763480857\t eps = 0.54\n","t = 23000\t reward = 0.94\t{'DQNAgent': 95, 'RandomPlus': 1}\n","\n","t = 23100\t loss = 0.0003605526580940932\t eps = 0.538\n","t = 23200\t loss = 0.0009434602688997984\t eps = 0.536\n","t = 23300\t loss = 0.0005776510806754231\t eps = 0.534\n","t = 23400\t loss = 0.0004435641167219728\t eps = 0.532\n","t = 23500\t loss = 0.00035636828397400677\t eps = 0.53\n","t = 23500\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 23600\t loss = 0.0005844409461133182\t eps = 0.528\n","t = 23700\t loss = 0.00037378622801043093\t eps = 0.526\n","t = 23800\t loss = 0.000654331874102354\t eps = 0.524\n","t = 23900\t loss = 0.000503688701428473\t eps = 0.522\n","t = 24000\t loss = 0.000286094902548939\t eps = 0.52\n","t = 24000\t reward = 0.95\t{'DQNAgent': 97, 'RandomPlus': 2}\n","\n","t = 24100\t loss = 0.0005255209398455918\t eps = 0.518\n","t = 24200\t loss = 0.0005490205949172378\t eps = 0.516\n","t = 24300\t loss = 0.0005219765589572489\t eps = 0.514\n","t = 24400\t loss = 0.0004432107671163976\t eps = 0.512\n","t = 24500\t loss = 0.0006093435222283006\t eps = 0.51\n","t = 24500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 24600\t loss = 0.0010367772774770856\t eps = 0.508\n","t = 24700\t loss = 0.0008842502138577402\t eps = 0.506\n","t = 24800\t loss = 0.0008139687706716359\t eps = 0.504\n","t = 24900\t loss = 0.0010313738603144884\t eps = 0.502\n","t = 25000\t loss = 0.0005095686065033078\t eps = 0.5\n","t = 25000\t reward = 0.96\t{'DQNAgent': 96, 'RandomPlus': 0}\n","\n","t = 25100\t loss = 0.000530146062374115\t eps = 0.498\n","t = 25200\t loss = 0.0005915139336138964\t eps = 0.496\n","t = 25300\t loss = 0.0005148774944245815\t eps = 0.494\n","t = 25400\t loss = 0.0003462142776697874\t eps = 0.492\n","t = 25500\t loss = 0.0004240692942403257\t eps = 0.49\n","t = 25500\t reward = 0.95\t{'DQNAgent': 97, 'RandomPlus': 2}\n","\n","t = 25600\t loss = 0.0005461195833049715\t eps = 0.488\n","t = 25700\t loss = 0.00032546796137467027\t eps = 0.486\n","t = 25800\t loss = 0.0003076815337408334\t eps = 0.484\n","t = 25900\t loss = 0.001144621055573225\t eps = 0.482\n","t = 26000\t loss = 0.00039528048364445567\t eps = 0.48\n","t = 26000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 26100\t loss = 0.0006164938095025718\t eps = 0.478\n","t = 26200\t loss = 0.00041661752038635314\t eps = 0.476\n","t = 26300\t loss = 0.00039221387123689055\t eps = 0.474\n","t = 26400\t loss = 0.0008219433948397636\t eps = 0.472\n","t = 26500\t loss = 0.0004125518898945302\t eps = 0.47\n","t = 26500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 26600\t loss = 0.0006222068332135677\t eps = 0.468\n","t = 26700\t loss = 0.0003724156995303929\t eps = 0.466\n","t = 26800\t loss = 0.0006362507119774818\t eps = 0.464\n","t = 26900\t loss = 0.0006694504991173744\t eps = 0.462\n","t = 27000\t loss = 0.00039465806912630796\t eps = 0.46\n","t = 27000\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 27100\t loss = 0.000586759764701128\t eps = 0.458\n","t = 27200\t loss = 0.00030661560595035553\t eps = 0.456\n","t = 27300\t loss = 0.0006870917859487236\t eps = 0.454\n","t = 27400\t loss = 0.0005751884309574962\t eps = 0.452\n","t = 27500\t loss = 0.0005311499699018896\t eps = 0.45\n","t = 27500\t reward = 0.93\t{'DQNAgent': 94, 'RandomPlus': 1}\n","\n","t = 27600\t loss = 0.00044006764073856175\t eps = 0.448\n","t = 27700\t loss = 0.0004846643132623285\t eps = 0.446\n","t = 27800\t loss = 0.0006997465388849378\t eps = 0.444\n","t = 27900\t loss = 0.0004074028693139553\t eps = 0.442\n","t = 28000\t loss = 0.00043370394269004464\t eps = 0.44\n","t = 28000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 28100\t loss = 0.0004580329405143857\t eps = 0.438\n","t = 28200\t loss = 0.0008635414997115731\t eps = 0.436\n","t = 28300\t loss = 0.00047740445006638765\t eps = 0.434\n","t = 28400\t loss = 0.0006863694870844483\t eps = 0.432\n","t = 28500\t loss = 0.0004012886784039438\t eps = 0.43\n","t = 28500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 28600\t loss = 0.0006030693184584379\t eps = 0.428\n","t = 28700\t loss = 0.0005129205528646708\t eps = 0.426\n","t = 28800\t loss = 0.00047926162369549274\t eps = 0.424\n","t = 28900\t loss = 0.0006236513145267963\t eps = 0.422\n","t = 29000\t loss = 0.0005232788389548659\t eps = 0.42\n","t = 29000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 29100\t loss = 0.0004148692823946476\t eps = 0.418\n","t = 29200\t loss = 0.0007397027220577002\t eps = 0.416\n","t = 29300\t loss = 0.0005183627363294363\t eps = 0.414\n","t = 29400\t loss = 0.00046252613537944853\t eps = 0.412\n","t = 29500\t loss = 0.0003143876965623349\t eps = 0.41\n","t = 29500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 29600\t loss = 0.00033951629302464426\t eps = 0.408\n","t = 29700\t loss = 0.004097384866327047\t eps = 0.406\n","t = 29800\t loss = 0.0002695333678275347\t eps = 0.404\n","t = 29900\t loss = 0.00037857890129089355\t eps = 0.402\n","t = 30000\t loss = 0.0004479288763832301\t eps = 0.4\n","t = 30000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 30100\t loss = 0.0003784515429288149\t eps = 0.398\n","t = 30200\t loss = 0.00048825444537214935\t eps = 0.396\n","t = 30300\t loss = 0.0004991827299818397\t eps = 0.394\n","t = 30400\t loss = 0.0003503341868054122\t eps = 0.392\n","t = 30500\t loss = 0.0004321046289987862\t eps = 0.39\n","t = 30500\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 30600\t loss = 0.0006873306119814515\t eps = 0.388\n","t = 30700\t loss = 0.00028070947155356407\t eps = 0.386\n","t = 30800\t loss = 0.0004327300994191319\t eps = 0.384\n","t = 30900\t loss = 0.00039711390854790807\t eps = 0.382\n","t = 31000\t loss = 0.0002741715870797634\t eps = 0.38\n","t = 31000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 31100\t loss = 0.0005550835048779845\t eps = 0.378\n","t = 31200\t loss = 0.0007691120263189077\t eps = 0.376\n","t = 31300\t loss = 0.0004278511041775346\t eps = 0.374\n","t = 31400\t loss = 0.0005051714251749218\t eps = 0.372\n","t = 31500\t loss = 0.00038052204763516784\t eps = 0.37\n","t = 31500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 31600\t loss = 0.0004563371476251632\t eps = 0.368\n","t = 31700\t loss = 0.0004178748349659145\t eps = 0.366\n","t = 31800\t loss = 0.00048336683539673686\t eps = 0.364\n","t = 31900\t loss = 0.00045165501069277525\t eps = 0.362\n","t = 32000\t loss = 0.0002345567336305976\t eps = 0.36\n","t = 32000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 32100\t loss = 0.0003576020826585591\t eps = 0.358\n","t = 32200\t loss = 0.0006250040605664253\t eps = 0.356\n","t = 32300\t loss = 0.00055599125334993\t eps = 0.354\n","t = 32400\t loss = 0.0005447630537673831\t eps = 0.352\n","t = 32500\t loss = 0.0003405919414944947\t eps = 0.35\n","t = 32500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 32600\t loss = 0.00046309258323162794\t eps = 0.348\n","t = 32700\t loss = 0.00045544386375695467\t eps = 0.346\n","t = 32800\t loss = 0.00036791866295970976\t eps = 0.344\n","t = 32900\t loss = 0.00047216328675858676\t eps = 0.342\n","t = 33000\t loss = 0.000657731550745666\t eps = 0.34\n","t = 33000\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 33100\t loss = 0.0005271722329780459\t eps = 0.338\n","t = 33200\t loss = 0.00031482649501413107\t eps = 0.336\n","t = 33300\t loss = 0.0002789922582451254\t eps = 0.334\n","t = 33400\t loss = 0.0006204151432029903\t eps = 0.332\n","t = 33500\t loss = 0.00019522615184541792\t eps = 0.33\n","t = 33500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 33600\t loss = 0.00034541895729489625\t eps = 0.328\n","t = 33700\t loss = 0.0003666413831524551\t eps = 0.326\n","t = 33800\t loss = 0.0003330521285533905\t eps = 0.324\n","t = 33900\t loss = 0.00043395126704126596\t eps = 0.322\n","t = 34000\t loss = 0.0003429323551245034\t eps = 0.32\n","t = 34000\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 34100\t loss = 0.0002914239012170583\t eps = 0.318\n","t = 34200\t loss = 0.00029579567490145564\t eps = 0.316\n","t = 34300\t loss = 0.0006023385212756693\t eps = 0.314\n","t = 34400\t loss = 0.0003035818808712065\t eps = 0.312\n","t = 34500\t loss = 0.0003657569468487054\t eps = 0.31\n","t = 34500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 34600\t loss = 0.0002677782322280109\t eps = 0.308\n","t = 34700\t loss = 0.0002869031159207225\t eps = 0.306\n","t = 34800\t loss = 0.0003013561072293669\t eps = 0.304\n","t = 34900\t loss = 0.000571190845221281\t eps = 0.302\n","t = 35000\t loss = 0.0006282567046582699\t eps = 0.3\n","t = 35000\t reward = 0.94\t{'DQNAgent': 95, 'RandomPlus': 1}\n","\n","t = 35100\t loss = 0.0002485825098119676\t eps = 0.298\n","t = 35200\t loss = 0.00025781075237318873\t eps = 0.296\n","t = 35300\t loss = 0.00036651312257163227\t eps = 0.294\n","t = 35400\t loss = 0.00015614667790941894\t eps = 0.292\n","t = 35500\t loss = 0.00035670370562002063\t eps = 0.29\n","t = 35500\t reward = 0.92\t{'DQNAgent': 94, 'RandomPlus': 2}\n","\n","t = 35600\t loss = 0.0002706611412577331\t eps = 0.288\n","t = 35700\t loss = 0.0001503303210483864\t eps = 0.286\n","t = 35800\t loss = 0.000408577878260985\t eps = 0.284\n","t = 35900\t loss = 0.00026523240376263857\t eps = 0.282\n","t = 36000\t loss = 0.00030394791974686086\t eps = 0.28\n","t = 36000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 36100\t loss = 0.0010166484862565994\t eps = 0.278\n","t = 36200\t loss = 0.0002316548489034176\t eps = 0.276\n","t = 36300\t loss = 0.0007929044077172875\t eps = 0.274\n","t = 36400\t loss = 0.00021975726122036576\t eps = 0.272\n","t = 36500\t loss = 0.003710581921041012\t eps = 0.27\n","t = 36500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 36600\t loss = 0.00036872000782750547\t eps = 0.268\n","t = 36700\t loss = 0.00027028826298192143\t eps = 0.266\n","t = 36800\t loss = 0.00020049349404871464\t eps = 0.264\n","t = 36900\t loss = 0.00029954768251627684\t eps = 0.262\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        state_2d, turn = state\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBCf9OmtL_6J"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_36500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_36500'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fde8b51-5ad7-4f54-ca63-5738711f695d","id":"6W1ctocRVc78","executionInfo":{"status":"ok","timestamp":1718801720775,"user_tz":-180,"elapsed":3861516,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 36600\t loss = None\t eps = 0.268\n","t = 36700\t loss = 0.00014099874533712864\t eps = 0.266\n","t = 36800\t loss = 0.00020060810493305326\t eps = 0.264\n","t = 36900\t loss = 0.00020682072499766946\t eps = 0.262\n","t = 37000\t loss = 0.00027246488025411963\t eps = 0.26\n","t = 37000\t reward = 0.96\t{'DQNAgent': 96, 'RandomPlus': 0}\n","\n","t = 37100\t loss = 0.00031232365290634334\t eps = 0.258\n","t = 37200\t loss = 0.0001755008997861296\t eps = 0.256\n","t = 37300\t loss = 0.00019002807675860822\t eps = 0.254\n","t = 37400\t loss = 0.0001777427241904661\t eps = 0.252\n","t = 37500\t loss = 0.0006124767241999507\t eps = 0.25\n","t = 37500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 37600\t loss = 0.00021436184761114419\t eps = 0.248\n","t = 37700\t loss = 0.00015682837693020701\t eps = 0.246\n","t = 37800\t loss = 0.00020844966638833284\t eps = 0.244\n","t = 37900\t loss = 0.00013681976997759193\t eps = 0.242\n","t = 38000\t loss = 0.00015053477545734495\t eps = 0.24\n","t = 38000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 38100\t loss = 0.00020895790657959878\t eps = 0.238\n","t = 38200\t loss = 0.0003205568646080792\t eps = 0.236\n","t = 38300\t loss = 0.00024788323207758367\t eps = 0.234\n","t = 38400\t loss = 0.0002148150815628469\t eps = 0.232\n","t = 38500\t loss = 0.0003602955548558384\t eps = 0.23\n","t = 38500\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 38600\t loss = 0.0007607416482642293\t eps = 0.228\n","t = 38700\t loss = 0.0001735007099341601\t eps = 0.226\n","t = 38800\t loss = 0.0002461565600242466\t eps = 0.224\n","t = 38900\t loss = 0.0001764624466886744\t eps = 0.222\n","t = 39000\t loss = 0.00013707345351576805\t eps = 0.22\n","t = 39000\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 39100\t loss = 0.0001745515182847157\t eps = 0.218\n","t = 39200\t loss = 0.00019605258421506733\t eps = 0.216\n","t = 39300\t loss = 0.00018584333884064108\t eps = 0.214\n","t = 39400\t loss = 0.00026430541765876114\t eps = 0.212\n","t = 39500\t loss = 0.00024032461806200445\t eps = 0.21\n","t = 39500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 39600\t loss = 0.00024371675681322813\t eps = 0.208\n","t = 39700\t loss = 0.0004071785951964557\t eps = 0.206\n","t = 39800\t loss = 0.0004969917936250567\t eps = 0.204\n","t = 39900\t loss = 0.000129928084788844\t eps = 0.202\n","t = 40000\t loss = 0.0001501683727838099\t eps = 0.2\n","t = 40000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 40100\t loss = 0.00014556827954947948\t eps = 0.2\n","t = 40200\t loss = 0.0003947933146264404\t eps = 0.2\n","t = 40300\t loss = 0.00018964015180245042\t eps = 0.2\n","t = 40400\t loss = 0.0003126409137621522\t eps = 0.2\n","t = 40500\t loss = 0.0002695484727155417\t eps = 0.2\n","t = 40500\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 40600\t loss = 0.000179704453330487\t eps = 0.2\n","t = 40700\t loss = 0.0002818210341501981\t eps = 0.2\n","t = 40800\t loss = 0.00019379027071408927\t eps = 0.2\n","t = 40900\t loss = 0.00036098924465477467\t eps = 0.2\n","t = 41000\t loss = 0.00024777569342404604\t eps = 0.2\n","t = 41000\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 41100\t loss = 0.00015071104280650616\t eps = 0.2\n","t = 41200\t loss = 0.00017572392243891954\t eps = 0.2\n","t = 41300\t loss = 0.0002124990278389305\t eps = 0.2\n","t = 41400\t loss = 0.0009590163826942444\t eps = 0.2\n","t = 41500\t loss = 0.0001560505188535899\t eps = 0.2\n","t = 41500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 41600\t loss = 0.00021709791326429695\t eps = 0.2\n","t = 41700\t loss = 0.00016891048289835453\t eps = 0.2\n","t = 41800\t loss = 0.000292840413749218\t eps = 0.2\n","t = 41900\t loss = 0.00029051280580461025\t eps = 0.2\n","t = 42000\t loss = 0.00012325792340561748\t eps = 0.2\n","t = 42000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 42100\t loss = 0.0007171367178671062\t eps = 0.2\n","t = 42200\t loss = 0.00018375643412582576\t eps = 0.2\n","t = 42300\t loss = 0.00025778799317777157\t eps = 0.2\n","t = 42400\t loss = 0.0001944927789736539\t eps = 0.2\n","t = 42500\t loss = 0.00023149738262873143\t eps = 0.2\n","t = 42500\t reward = 0.94\t{'DQNAgent': 94, 'RandomPlus': 0}\n","\n","t = 42600\t loss = 0.00026270232046954334\t eps = 0.2\n","t = 42700\t loss = 0.0002815837215166539\t eps = 0.2\n","t = 42800\t loss = 0.00015651839203201234\t eps = 0.2\n","t = 42900\t loss = 0.00014788328553549945\t eps = 0.2\n","t = 43000\t loss = 0.0006561956251971424\t eps = 0.2\n","t = 43000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 43100\t loss = 0.0001404520880896598\t eps = 0.2\n","t = 43200\t loss = 0.00011964434816036373\t eps = 0.2\n","t = 43300\t loss = 0.00011558116966625676\t eps = 0.2\n","t = 43400\t loss = 0.00026828344562090933\t eps = 0.2\n","t = 43500\t loss = 0.000483599811559543\t eps = 0.2\n","t = 43500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 43600\t loss = 0.0002570778888184577\t eps = 0.2\n","t = 43700\t loss = 0.0006297506624832749\t eps = 0.2\n","t = 43800\t loss = 0.0001918300404213369\t eps = 0.2\n","t = 43900\t loss = 0.00028431531973183155\t eps = 0.2\n","t = 44000\t loss = 9.905410843202844e-05\t eps = 0.2\n","t = 44000\t reward = 0.95\t{'DQNAgent': 95, 'RandomPlus': 0}\n","\n","t = 44100\t loss = 0.00019316964608151466\t eps = 0.2\n","t = 44200\t loss = 0.00015902491577435285\t eps = 0.2\n","t = 44300\t loss = 0.00015888466441538185\t eps = 0.2\n","t = 44400\t loss = 0.00018166241352446377\t eps = 0.2\n","t = 44500\t loss = 0.00015604158397763968\t eps = 0.2\n","t = 44500\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 44600\t loss = 0.00015911116497591138\t eps = 0.2\n","t = 44700\t loss = 0.00042766722617670894\t eps = 0.2\n","t = 44800\t loss = 0.00014874336193315685\t eps = 0.2\n","t = 44900\t loss = 0.00013952302106190473\t eps = 0.2\n","t = 45000\t loss = 0.00031934582511894405\t eps = 0.2\n","t = 45000\t reward = 0.95\t{'DQNAgent': 96, 'RandomPlus': 1}\n","\n","t = 45100\t loss = 0.0001778651203494519\t eps = 0.2\n","t = 45200\t loss = 0.0002496253582648933\t eps = 0.2\n","t = 45300\t loss = 0.00018850891501642764\t eps = 0.2\n","t = 45400\t loss = 0.00015912482922431082\t eps = 0.2\n","t = 45500\t loss = 0.000778958376031369\t eps = 0.2\n","t = 45500\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 45600\t loss = 0.0006771526532247663\t eps = 0.2\n","t = 45700\t loss = 0.0002687935484573245\t eps = 0.2\n","t = 45800\t loss = 0.0003978656022809446\t eps = 0.2\n","t = 45900\t loss = 0.00015140828327275813\t eps = 0.2\n","t = 46000\t loss = 0.0003710324235726148\t eps = 0.2\n","t = 46000\t reward = 0.94\t{'DQNAgent': 94, 'RandomPlus': 0}\n","\n","t = 46100\t loss = 0.00027505159960128367\t eps = 0.2\n","t = 46200\t loss = 0.0001756583369569853\t eps = 0.2\n","t = 46300\t loss = 0.000288390030618757\t eps = 0.2\n","t = 46400\t loss = 0.00014651833043899387\t eps = 0.2\n","t = 46500\t loss = 0.00014991984062362462\t eps = 0.2\n","t = 46500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 46600\t loss = 0.0002955746604129672\t eps = 0.2\n","t = 46700\t loss = 0.00016386846255045384\t eps = 0.2\n","t = 46800\t loss = 0.0003960569738410413\t eps = 0.2\n","t = 46900\t loss = 0.0005934337386861444\t eps = 0.2\n","t = 47000\t loss = 0.00019275890372227877\t eps = 0.2\n","t = 47000\t reward = 0.93\t{'DQNAgent': 95, 'RandomPlus': 2}\n","\n","t = 47100\t loss = 0.00025592499878257513\t eps = 0.2\n","t = 47200\t loss = 0.00014091518823988736\t eps = 0.2\n","t = 47300\t loss = 0.0002229892706964165\t eps = 0.2\n","t = 47400\t loss = 0.00017939346435014158\t eps = 0.2\n","t = 47500\t loss = 0.0002694439026527107\t eps = 0.2\n","t = 47500\t reward = 1.0\t{'DQNAgent': 100, 'RandomPlus': 0}\n","\n","t = 47600\t loss = 0.0003600147319957614\t eps = 0.2\n","t = 47700\t loss = 0.00022035646543372422\t eps = 0.2\n","t = 47800\t loss = 0.00015163820353336632\t eps = 0.2\n","t = 47900\t loss = 0.00013561852392740548\t eps = 0.2\n","t = 48000\t loss = 0.00017662796017248183\t eps = 0.2\n","t = 48000\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 48100\t loss = 0.00017040033708326519\t eps = 0.2\n","t = 48200\t loss = 0.00023846214753575623\t eps = 0.2\n","t = 48300\t loss = 0.00024102599127218127\t eps = 0.2\n","t = 48400\t loss = 0.00015941649326123297\t eps = 0.2\n","t = 48500\t loss = 0.00015417233225889504\t eps = 0.2\n","t = 48500\t reward = 0.97\t{'DQNAgent': 98, 'RandomPlus': 1}\n","\n","t = 48600\t loss = 0.00019151608285028487\t eps = 0.2\n","t = 48700\t loss = 0.00019293885270599276\t eps = 0.2\n","t = 48800\t loss = 0.000247377494815737\t eps = 0.2\n","t = 48900\t loss = 0.00017322150233667344\t eps = 0.2\n","t = 49000\t loss = 0.0009893830865621567\t eps = 0.2\n","t = 49000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 49100\t loss = 0.00020261459576431662\t eps = 0.2\n","t = 49200\t loss = 0.0001999943924602121\t eps = 0.2\n","t = 49300\t loss = 0.0005755131132900715\t eps = 0.2\n","t = 49400\t loss = 0.0003755676734726876\t eps = 0.2\n","t = 49500\t loss = 0.0003189811250194907\t eps = 0.2\n","t = 49500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 49600\t loss = 0.00017555565864313394\t eps = 0.2\n","t = 49700\t loss = 0.00018354668281972408\t eps = 0.2\n","t = 49800\t loss = 0.00019017874728888273\t eps = 0.2\n","t = 49900\t loss = 0.00019394169794395566\t eps = 0.2\n","t = 50000\t loss = 0.0001142924083978869\t eps = 0.2\n","t = 50000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 50100\t loss = 0.00021646017557941377\t eps = 0.2\n","t = 50200\t loss = 0.00016548275016248226\t eps = 0.2\n","t = 50300\t loss = 0.00013501173816621304\t eps = 0.2\n","t = 50400\t loss = 0.0001228387700393796\t eps = 0.2\n","t = 50500\t loss = 0.00010481302160769701\t eps = 0.2\n","t = 50500\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 50600\t loss = 0.0002185082994401455\t eps = 0.2\n","t = 50700\t loss = 0.0001652698847465217\t eps = 0.2\n","t = 50800\t loss = 0.00015882731531746686\t eps = 0.2\n","t = 50900\t loss = 0.00022637905203737319\t eps = 0.2\n","t = 51000\t loss = 0.00025806474150158465\t eps = 0.2\n","t = 51000\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 51100\t loss = 0.00021880766144022346\t eps = 0.2\n","t = 51200\t loss = 0.0007079705828800797\t eps = 0.2\n","t = 51300\t loss = 0.0003501015598885715\t eps = 0.2\n","t = 51400\t loss = 0.0003459869185462594\t eps = 0.2\n","t = 51500\t loss = 0.0003568868851289153\t eps = 0.2\n","t = 51500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 51600\t loss = 0.00012325258285272866\t eps = 0.2\n","t = 51700\t loss = 0.00015295448247343302\t eps = 0.2\n","t = 51800\t loss = 0.00016961338405963033\t eps = 0.2\n","t = 51900\t loss = 0.00016699907428119332\t eps = 0.2\n","t = 52000\t loss = 0.00029201561119407415\t eps = 0.2\n","t = 52000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 52100\t loss = 0.0001392729755025357\t eps = 0.2\n","t = 52200\t loss = 0.0004062902880832553\t eps = 0.2\n","t = 52300\t loss = 0.00019066149252466857\t eps = 0.2\n","t = 52400\t loss = 0.0003801234415732324\t eps = 0.2\n","t = 52500\t loss = 0.00014391855802387\t eps = 0.2\n","t = 52500\t reward = 0.94\t{'DQNAgent': 95, 'RandomPlus': 1}\n","\n","t = 52600\t loss = 0.00019341967708896846\t eps = 0.2\n","t = 52700\t loss = 0.0005179492873139679\t eps = 0.2\n","t = 52800\t loss = 0.00018987189105246216\t eps = 0.2\n","t = 52900\t loss = 0.00015283242100849748\t eps = 0.2\n","t = 53000\t loss = 0.0001346701756119728\t eps = 0.2\n","t = 53000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 53100\t loss = 0.00022512514260597527\t eps = 0.2\n","t = 53200\t loss = 0.00017096153169404715\t eps = 0.2\n","t = 53300\t loss = 0.0005867143627256155\t eps = 0.2\n","t = 53400\t loss = 0.0001623284915694967\t eps = 0.2\n","t = 53500\t loss = 0.00013904371007811278\t eps = 0.2\n","t = 53500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 53600\t loss = 0.0004053361772093922\t eps = 0.2\n","t = 53700\t loss = 0.00014215811097528785\t eps = 0.2\n","t = 53800\t loss = 0.00010530516738072038\t eps = 0.2\n","t = 53900\t loss = 0.00018318468937650323\t eps = 0.2\n","t = 54000\t loss = 0.00013083076919429004\t eps = 0.2\n","t = 54000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 54100\t loss = 0.0006097493460401893\t eps = 0.2\n","t = 54200\t loss = 0.00023952298215590417\t eps = 0.2\n","t = 54300\t loss = 0.00016868661623448133\t eps = 0.2\n","t = 54400\t loss = 0.0002569090574979782\t eps = 0.2\n","t = 54500\t loss = 0.0001361754402751103\t eps = 0.2\n","t = 54500\t reward = 0.94\t{'DQNAgent': 95, 'RandomPlus': 1}\n","\n","t = 54600\t loss = 0.00014657058636657894\t eps = 0.2\n","t = 54700\t loss = 0.0002143243618775159\t eps = 0.2\n","t = 54800\t loss = 0.00042003009002655745\t eps = 0.2\n","t = 54900\t loss = 0.00013429022510536015\t eps = 0.2\n","t = 55000\t loss = 0.000317515543429181\t eps = 0.2\n","t = 55000\t reward = 0.92\t{'DQNAgent': 94, 'RandomPlus': 2}\n","\n","t = 55100\t loss = 0.0002236859581898898\t eps = 0.2\n","t = 55200\t loss = 0.00015004367742221802\t eps = 0.2\n","t = 55300\t loss = 0.0002173215470975265\t eps = 0.2\n","t = 55400\t loss = 0.0001170256728073582\t eps = 0.2\n","t = 55500\t loss = 0.00031341324211098254\t eps = 0.2\n","t = 55500\t reward = 0.96\t{'DQNAgent': 96, 'RandomPlus': 0}\n","\n","t = 55600\t loss = 0.00033061602152884007\t eps = 0.2\n","t = 55700\t loss = 0.00021689006825909019\t eps = 0.2\n","t = 55800\t loss = 0.0005691919941455126\t eps = 0.2\n","t = 55900\t loss = 0.00019242509733885527\t eps = 0.2\n","t = 56000\t loss = 0.00019220460671931505\t eps = 0.2\n","t = 56000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 56100\t loss = 0.00026059121591970325\t eps = 0.2\n","t = 56200\t loss = 0.0001813691051211208\t eps = 0.2\n","t = 56300\t loss = 0.0002951950009446591\t eps = 0.2\n","t = 56400\t loss = 0.0002870307071134448\t eps = 0.2\n","t = 56500\t loss = 0.00019891993724741042\t eps = 0.2\n","t = 56500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 56600\t loss = 0.0004441658384166658\t eps = 0.2\n","t = 56700\t loss = 0.00014041832764633\t eps = 0.2\n","t = 56800\t loss = 0.0001384301285725087\t eps = 0.2\n","t = 56900\t loss = 0.00020196697732899338\t eps = 0.2\n","t = 57000\t loss = 0.0002686553925741464\t eps = 0.2\n","t = 57000\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n","t = 57100\t loss = 0.00018188156536780298\t eps = 0.2\n","t = 57200\t loss = 0.00032584875589236617\t eps = 0.2\n","t = 57300\t loss = 0.00018459992134012282\t eps = 0.2\n","t = 57400\t loss = 0.0002941737766377628\t eps = 0.2\n","t = 57500\t loss = 0.0006194686866365373\t eps = 0.2\n","t = 57500\t reward = 0.96\t{'DQNAgent': 97, 'RandomPlus': 1}\n","\n","t = 57600\t loss = 0.0007831656257621944\t eps = 0.2\n","t = 57700\t loss = 0.0001436080492567271\t eps = 0.2\n","t = 57800\t loss = 0.00023737861192785203\t eps = 0.2\n","t = 57900\t loss = 0.0001639731490286067\t eps = 0.2\n","t = 58000\t loss = 0.00016426024376414716\t eps = 0.2\n","t = 58000\t reward = 0.97\t{'DQNAgent': 97, 'RandomPlus': 0}\n","\n","t = 58100\t loss = 0.0001688256161287427\t eps = 0.2\n","t = 58200\t loss = 0.00025643734261393547\t eps = 0.2\n","t = 58300\t loss = 0.00036957234260626137\t eps = 0.2\n","t = 58400\t loss = 0.00014041164831724018\t eps = 0.2\n","t = 58500\t loss = 0.00023414305178448558\t eps = 0.2\n","t = 58500\t reward = 0.98\t{'DQNAgent': 99, 'RandomPlus': 1}\n","\n","t = 58600\t loss = 0.00022480246843770146\t eps = 0.2\n","t = 58700\t loss = 0.0001708209456410259\t eps = 0.2\n","t = 58800\t loss = 0.00020410784054547548\t eps = 0.2\n","t = 58900\t loss = 0.0005654731648974121\t eps = 0.2\n","t = 59000\t loss = 0.0002257795858895406\t eps = 0.2\n","t = 59000\t reward = 0.89\t{'DQNAgent': 93, 'RandomPlus': 4}\n","\n","t = 59100\t loss = 0.00022495616576634347\t eps = 0.2\n","t = 59200\t loss = 0.0002762179938144982\t eps = 0.2\n","t = 59300\t loss = 0.0006586688105016947\t eps = 0.2\n","t = 59400\t loss = 0.00013618843513540924\t eps = 0.2\n","t = 59500\t loss = 0.00017233807011507452\t eps = 0.2\n","t = 59500\t reward = 0.94\t{'DQNAgent': 95, 'RandomPlus': 1}\n","\n","t = 59600\t loss = 0.000247693998971954\t eps = 0.2\n","t = 59700\t loss = 0.00019714818336069584\t eps = 0.2\n","t = 59800\t loss = 0.00018657444161362946\t eps = 0.2\n","t = 59900\t loss = 0.00023593864170834422\t eps = 0.2\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(36_600, total_steps):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        state_2d, turn = state\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","# Гиперпараметры метода DQN\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twMGUEzOpQ91"},"outputs":[],"source":["agent.load_state_dict(torch.load(f'{PATH}model_59500'))\n","optimizer.load_state_dict(torch.load(f'{PATH}opt_59500'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1669f4dc-d116-460e-dbda-ac9b7c516829","id":"QT8I4ag8pQ-E"},"outputs":[{"output_type":"stream","name":"stdout","text":["t = 59600\t loss = 0.003960108384490013\t eps = 0.2\n","t = 59700\t loss = 0.0003764395078178495\t eps = 0.2\n","t = 59800\t loss = 0.0003657957713585347\t eps = 0.2\n","t = 59900\t loss = 0.00025083834771066904\t eps = 0.2\n","t = 60000\t loss = 0.0002798822824843228\t eps = 0.2\n","t = 60000\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 60100\t loss = 0.00019810502999462187\t eps = 0.2\n","t = 60200\t loss = 0.0002592834644019604\t eps = 0.2\n","t = 60300\t loss = 0.00017909894813783467\t eps = 0.2\n","t = 60400\t loss = 0.00028372794622555375\t eps = 0.2\n","t = 60500\t loss = 0.0005165296024642885\t eps = 0.2\n","t = 60500\t reward = 0.99\t{'DQNAgent': 99, 'RandomPlus': 0}\n","\n","t = 60600\t loss = 0.00026640715077519417\t eps = 0.2\n","t = 60700\t loss = 0.00020307810336817056\t eps = 0.2\n","t = 60800\t loss = 0.00018918971181847155\t eps = 0.2\n","t = 60900\t loss = 0.00012081737077096477\t eps = 0.2\n","t = 61000\t loss = 0.0001024806551868096\t eps = 0.2\n","t = 61000\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 61100\t loss = 0.00020484747074078768\t eps = 0.2\n","t = 61200\t loss = 0.0002532019279897213\t eps = 0.2\n","t = 61300\t loss = 0.0002004792622756213\t eps = 0.2\n","t = 61400\t loss = 0.0002108928165398538\t eps = 0.2\n","t = 61500\t loss = 0.0004002425412181765\t eps = 0.2\n","t = 61500\t reward = 0.94\t{'DQNAgent': 96, 'RandomPlus': 2}\n","\n","t = 61600\t loss = 0.00016929006960708648\t eps = 0.2\n","t = 61700\t loss = 0.0004367642686702311\t eps = 0.2\n","t = 61800\t loss = 0.0004143090336583555\t eps = 0.2\n","t = 61900\t loss = 0.00018081664165947586\t eps = 0.2\n","t = 62000\t loss = 0.00018790835747495294\t eps = 0.2\n","t = 62000\t reward = 0.96\t{'DQNAgent': 96, 'RandomPlus': 0}\n","\n","t = 62100\t loss = 0.00017887487774714828\t eps = 0.2\n","t = 62200\t loss = 0.0002577922714408487\t eps = 0.2\n","t = 62300\t loss = 0.0001500291982665658\t eps = 0.2\n","t = 62400\t loss = 0.00019534774764906615\t eps = 0.2\n","t = 62500\t loss = 0.0003989562392234802\t eps = 0.2\n","t = 62500\t reward = 0.72\t{'DQNAgent': 82, 'RandomPlus': 10}\n","\n","t = 62600\t loss = 0.00020596926333382726\t eps = 0.2\n","t = 62700\t loss = 8.033894118852913e-05\t eps = 0.2\n","t = 62800\t loss = 0.00019475939916446805\t eps = 0.2\n","t = 62900\t loss = 0.0007464921218343079\t eps = 0.2\n","t = 63000\t loss = 0.00018278647621627897\t eps = 0.2\n","t = 63000\t reward = 0.96\t{'DQNAgent': 96, 'RandomPlus': 0}\n","\n","t = 63100\t loss = 0.000212738144909963\t eps = 0.2\n","t = 63200\t loss = 0.0004917002515867352\t eps = 0.2\n","t = 63300\t loss = 0.00015900198195595294\t eps = 0.2\n","t = 63400\t loss = 8.924788562580943e-05\t eps = 0.2\n","t = 63500\t loss = 9.48301749303937e-05\t eps = 0.2\n","t = 63500\t reward = 0.98\t{'DQNAgent': 98, 'RandomPlus': 0}\n","\n"]}],"source":["with open('out.txt', 'w') as f:\n","  for t in range(59_600, 80_000):\n","    print(f't = {t}. Ход {game.players[-1].name}', file=f)\n","\n","    state = (np.zeros((board_size, board_size)), -1) # Начальное состояние игры. state = (state_2d, turn)\n","    turn = next_turn = -1\n","\n","    while(next_turn != 0):\n","        current_player = game.players[turn]\n","        if current_player.name == 'DQNAgent':\n","            agent.epsilon = linear_decay(init_epsilon, final_epsilon, t, decay_steps)\n","\n","        action = agent.get_action(state)\n","        print(action, file=f)\n","        next_state_2d, next_turn, reward = game.play_turn(state, action)\n","\n","        if next_turn == 0:\n","            if (reward == 0): print('Ничья!\\n', file=f)\n","            else: print(f'Победа ({game.players[reward * turn].name})!\\n', file=f)\n","            game.players = {-1: game.players[1], 1: game.players[-1]}\n","\n","        state_2d, turn = state\n","        exp_replay.add(turn * state_2d, action, reward, next_turn * next_state_2d, next_turn == 0) #state, action, reward, new_state, done\n","\n","        # Обучение на минибатче\n","        if len(exp_replay) >= batch_size:\n","            states, actions, rewards, next_states, dones, indices, weights = exp_replay.sample(batch_size, augmentation=True)\n","            loss = compute_td_loss(states, actions, rewards, next_states, dones,\n","                                   agent, target_network, weights, indices, gamma)\n","            loss.backward()\n","            grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        state = next_state_2d, next_turn\n","\n","    # Каждые refresh_target_network_freq обновляются веса target сети\n","    if t % refresh_target_network_freq == 0:\n","        target_network.load_state_dict(agent.state_dict())\n","\n","    # Вывод лосса  с заданной частотой\n","    if t % loss_freq == 0 and t > 0:\n","        loss_values.append(loss)\n","        print(f\"t = {str(t):5}\\t loss = {loss}\\t eps = {round(agent.epsilon, 4)}\")\n","\n","    # Вывод награды с заданной частотой\n","    if t % eval_freq == 0:\n","        agent.epsilon = 0\n","        eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","        eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","        eval_game.play(n_eval_games)\n","        mean_reward = (eval_game.wins['DQNAgent'] - eval_game.wins['RandomPlus']) / n_eval_games\n","        reward_values.append(mean_reward)\n","        print(f\"t = {str(t):5}\\t reward = {round(mean_reward, 4)}\\t{eval_game.wins}\\n\")\n","\n","        torch.save(agent.state_dict(), PATH + f'model_{t}')\n","        torch.save(optimizer.state_dict(), PATH + f'opt_{t}')\n","\n","# Гиперпараметры метода DQN\n","torch.save(agent.state_dict(), PATH + f'model_{t}')\n","torch.save(optimizer.state_dict(), PATH + f'opt_{t}')"]},{"cell_type":"markdown","metadata":{"id":"wMHCdyXqKqCk"},"source":["#Тестирование обученных моделей (инференс с маскированием)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QySv5l9i6fUs"},"outputs":[],"source":["PATH = '/content/drive/MyDrive/TicTacToe_11/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":984699,"status":"ok","timestamp":1718795960516,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"},"user_tz":-180},"outputId":"3c9cc938-9151-45e0-9e29-62617ed01a3d","id":"c6H_9-jo_4UW"},"outputs":[{"output_type":"stream","name":"stdout","text":["16000 {'DQNAgent': 955, 'RandomPlus': 11}\n","16500 {'DQNAgent': 955, 'RandomPlus': 5}\n","17000 {'DQNAgent': 976, 'RandomPlus': 5}\n","17500 {'DQNAgent': 975, 'RandomPlus': 6}\n","18000 {'DQNAgent': 962, 'RandomPlus': 6}\n","18500 {'DQNAgent': 954, 'RandomPlus': 5}\n","19000 {'DQNAgent': 952, 'RandomPlus': 2}\n","19500 {'DQNAgent': 968, 'RandomPlus': 4}\n","20000 {'DQNAgent': 970, 'RandomPlus': 4}\n","20500 {'DQNAgent': 972, 'RandomPlus': 5}\n","21000 {'DQNAgent': 960, 'RandomPlus': 4}\n","21500 {'DQNAgent': 952, 'RandomPlus': 6}\n","22000 {'DQNAgent': 953, 'RandomPlus': 5}\n","22500 {'DQNAgent': 960, 'RandomPlus': 6}\n","23000 {'DQNAgent': 983, 'RandomPlus': 1}\n","23500 {'DQNAgent': 964, 'RandomPlus': 7}\n","24000 {'DQNAgent': 971, 'RandomPlus': 5}\n","24500 {'DQNAgent': 964, 'RandomPlus': 5}\n","25000 {'DQNAgent': 972, 'RandomPlus': 10}\n","25500 {'DQNAgent': 975, 'RandomPlus': 5}\n","26000 {'DQNAgent': 971, 'RandomPlus': 5}\n","26500 {'DQNAgent': 971, 'RandomPlus': 3}\n","27000 {'DQNAgent': 969, 'RandomPlus': 6}\n","27500 {'DQNAgent': 956, 'RandomPlus': 3}\n","28000 {'DQNAgent': 981, 'RandomPlus': 3}\n","28500 {'DQNAgent': 980, 'RandomPlus': 1}\n","29000 {'DQNAgent': 976, 'RandomPlus': 3}\n","29500 {'DQNAgent': 975, 'RandomPlus': 6}\n","30000 {'DQNAgent': 971, 'RandomPlus': 5}\n","30500 {'DQNAgent': 978, 'RandomPlus': 4}\n","31000 {'DQNAgent': 975, 'RandomPlus': 5}\n","31500 {'DQNAgent': 981, 'RandomPlus': 2}\n","32000 {'DQNAgent': 964, 'RandomPlus': 7}\n","32500 {'DQNAgent': 985, 'RandomPlus': 4}\n","33000 {'DQNAgent': 986, 'RandomPlus': 3}\n","33500 {'DQNAgent': 982, 'RandomPlus': 0}\n","34000 {'DQNAgent': 981, 'RandomPlus': 3}\n","34500 {'DQNAgent': 980, 'RandomPlus': 0}\n","35000 {'DQNAgent': 973, 'RandomPlus': 5}\n","35500 {'DQNAgent': 958, 'RandomPlus': 14}\n","36000 {'DQNAgent': 965, 'RandomPlus': 15}\n","36500 {'DQNAgent': 981, 'RandomPlus': 4}\n"]}],"source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(16_000, 37000, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(37_000, 70500, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}'))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"M1kiNaQ1kkhw","executionInfo":{"status":"error","timestamp":1718802134853,"user_tz":-180,"elapsed":305161,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"}},"outputId":"fa956bb5-4f54-4ecf-ef99-9a37116e578f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["37000 {'DQNAgent': 970, 'RandomPlus': 3}\n","37500 {'DQNAgent': 976, 'RandomPlus': 7}\n","38000 {'DQNAgent': 968, 'RandomPlus': 8}\n","38500 {'DQNAgent': 974, 'RandomPlus': 6}\n","39000 {'DQNAgent': 966, 'RandomPlus': 4}\n","39500 {'DQNAgent': 963, 'RandomPlus': 6}\n","40000 {'DQNAgent': 979, 'RandomPlus': 3}\n","40500 {'DQNAgent': 978, 'RandomPlus': 3}\n","41000 {'DQNAgent': 980, 'RandomPlus': 0}\n","41500 {'DQNAgent': 967, 'RandomPlus': 13}\n","42000 {'DQNAgent': 978, 'RandomPlus': 3}\n","42500 {'DQNAgent': 978, 'RandomPlus': 1}\n","43000 {'DQNAgent': 984, 'RandomPlus': 1}\n","43500 {'DQNAgent': 979, 'RandomPlus': 8}\n","44000 {'DQNAgent': 980, 'RandomPlus': 2}\n","44500 {'DQNAgent': 972, 'RandomPlus': 2}\n","45000 {'DQNAgent': 955, 'RandomPlus': 7}\n","45500 {'DQNAgent': 980, 'RandomPlus': 0}\n","46000 {'DQNAgent': 977, 'RandomPlus': 2}\n","46500 {'DQNAgent': 975, 'RandomPlus': 4}\n","47000 {'DQNAgent': 980, 'RandomPlus': 2}\n","47500 {'DQNAgent': 976, 'RandomPlus': 3}\n","48000 {'DQNAgent': 981, 'RandomPlus': 4}\n","48500 {'DQNAgent': 966, 'RandomPlus': 8}\n","49000 {'DQNAgent': 965, 'RandomPlus': 19}\n","49500 {'DQNAgent': 979, 'RandomPlus': 1}\n","50000 {'DQNAgent': 973, 'RandomPlus': 4}\n","50500 {'DQNAgent': 981, 'RandomPlus': 5}\n","51000 {'DQNAgent': 955, 'RandomPlus': 7}\n","51500 {'DQNAgent': 968, 'RandomPlus': 3}\n","52000 {'DQNAgent': 974, 'RandomPlus': 2}\n","52500 {'DQNAgent': 973, 'RandomPlus': 5}\n","53000 {'DQNAgent': 980, 'RandomPlus': 3}\n","53500 {'DQNAgent': 968, 'RandomPlus': 1}\n","54000 {'DQNAgent': 981, 'RandomPlus': 3}\n","54500 {'DQNAgent': 972, 'RandomPlus': 4}\n","55000 {'DQNAgent': 980, 'RandomPlus': 4}\n","55500 {'DQNAgent': 974, 'RandomPlus': 5}\n","56000 {'DQNAgent': 972, 'RandomPlus': 1}\n","56500 {'DQNAgent': 980, 'RandomPlus': 1}\n","57000 {'DQNAgent': 980, 'RandomPlus': 0}\n","57500 {'DQNAgent': 976, 'RandomPlus': 3}\n","58000 {'DQNAgent': 980, 'RandomPlus': 3}\n","58500 {'DQNAgent': 979, 'RandomPlus': 0}\n","59000 {'DQNAgent': 955, 'RandomPlus': 4}\n","59500 {'DQNAgent': 943, 'RandomPlus': 3}\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/TicTacToe_11/model_60000'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-fcb181c6a6ee>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m37_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{PATH}model_{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0meval_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0meval_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/TicTacToe_11/model_60000'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":177701,"status":"ok","timestamp":1718804088609,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"outputId":"f897905e-7b79-439e-9415-a60c3293e974","id":"3zyMFpgEsev3"},"outputs":[{"output_type":"stream","name":"stdout","text":["60000 {'DQNAgent': 976, 'RandomPlus': 3}\n","60500 {'DQNAgent': 970, 'RandomPlus': 3}\n","61000 {'DQNAgent': 947, 'RandomPlus': 10}\n","61500 {'DQNAgent': 955, 'RandomPlus': 13}\n","62000 {'DQNAgent': 943, 'RandomPlus': 4}\n","62500 {'DQNAgent': 873, 'RandomPlus': 67}\n","63000 {'DQNAgent': 952, 'RandomPlus': 9}\n","63500 {'DQNAgent': 978, 'RandomPlus': 3}\n"]}],"source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True, win_2=True, defense_2=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for i in range(60_000, 64000, 500):\n","    agent.load_state_dict(torch.load(f'{PATH}model_{i}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(1000)\n","    print(f'{i:5}', eval_game.wins)"]},{"cell_type":"code","source":["# Сравнение лучших моделей (без проигрышей)\n","models = [41000, 45500, 57000, 58500]\n","\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for model in models:\n","    agent.load_state_dict(torch.load(f'{PATH}model_{model}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(10_000)\n","    print(model, eval_game.wins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQoaVRwPmQoT","executionInfo":{"status":"ok","timestamp":1718802607052,"user_tz":-180,"elapsed":260726,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"}},"outputId":"872c3e17-c7cf-415d-f039-94d78c1efd59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["41000 {'DQNAgent': 9738, 'RandomPlus': 37}\n","45500 {'DQNAgent': 9803, 'RandomPlus': 13}\n","57000 {'DQNAgent': 9801, 'RandomPlus': 13}\n","58500 {'DQNAgent': 9786, 'RandomPlus': 11}\n"]}]},{"cell_type":"code","source":["# Сравнение лучших моделей (без проигрышей)\n","models = [23000, 28500, 33500, 34500]\n","\n","agent.epsilon = 0\n","agent.masking = True\n","\n","for model in models:\n","    agent.load_state_dict(torch.load(f'{PATH}model_{model}', map_location=torch.device('cpu')))\n","    eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","    eval_game.play(10_000)\n","    print(model, eval_game.wins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9LIq2qJIT0u","executionInfo":{"status":"ok","timestamp":1718797321860,"user_tz":-180,"elapsed":881887,"user":{"displayName":"Тимошкин Максим Олегович","userId":"04366778654056187449"}},"outputId":"a5b638fc-605a-417b-b711-a877bbdf98da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23000 {'DQNAgent': 9697, 'RandomPlus': 50}\n","28500 {'DQNAgent': 9745, 'RandomPlus': 24}\n","33500 {'DQNAgent': 9799, 'RandomPlus': 14}\n","34500 {'DQNAgent': 9801, 'RandomPlus': 17}\n"]}]},{"cell_type":"code","source":["# Сравнение обученных моделей\n","eval_random = RandomPlus(board_size, win_size, win=True, defense=True)\n","agent.epsilon = 0\n","agent.masking = True\n","\n","model = 58500\n","agent.load_state_dict(torch.load(f'{PATH}model_{model}'))\n","eval_game = TicTacToe(agent, eval_random, board_size=board_size, win_size=win_size)\n","eval_game.play(10_000)\n","print(model, eval_game.wins)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEJ7QGAro2ya","executionInfo":{"status":"ok","timestamp":1718803039811,"user_tz":-180,"elapsed":51477,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"}},"outputId":"604b1f5d-19fc-4481-a9c4-c58fed42297a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["58500 {'DQNAgent': 9969, 'RandomPlus': 1}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1718802670574,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"},"user_tz":-180},"id":"sT5QLsvSj0-2","outputId":"cb91069d-dfab-4f0e-f3f0-7ceb127580e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}],"source":["# Загрузка самой лучшей модели\n","agent.load_state_dict(torch.load(f'{PATH}model_58500'))#, map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bgzNN9tsPVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718802883768,"user_tz":-180,"elapsed":209264,"user":{"displayName":"ВОТИНЦЕВ АЛЕКСЕЙ КОНСТАНТИНОВИЧ","userId":"16300045363631252076"}},"outputId":"05d84b03-f685-4114-e76a-3b464ea0a805"},"outputs":[{"output_type":"stream","name":"stdout","text":["player -1's turn:\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n","player -1's turn:\n"," .  .  .  .  .\n"," .  .  .  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 2\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  .  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .\n"," .  O  .  .  .\n"," .  X  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 4\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  .  .  .\n"," .  X  X  O  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .\n"," .  O  X  .  .\n"," .  X  X  O  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  X  .  .\n"," .  X  X  O  .\n"," .  .  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," .  .  .  .  .\n"," .  O  X  .  .\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 4\n","player 1's turn:\n"," .  .  .  O  .\n"," .  O  X  .  .\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," .  .  .  O  .\n"," .  O  X  .  X\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 3\n","player 1's turn:\n"," .  .  O  O  .\n"," .  O  X  .  X\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," .  .  O  O  X\n"," .  O  X  .  X\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 1\n","player 1's turn:\n"," O  .  O  O  X\n"," .  O  X  .  X\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  X  O  O  X\n"," .  O  X  .  X\n"," .  X  X  O  .\n"," X  .  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player 1's turn:\n"," O  X  O  O  X\n"," .  O  X  .  X\n"," .  X  X  O  O\n"," X  .  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  X  O  O  X\n"," .  O  X  .  X\n"," .  X  X  O  O\n"," X  X  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","player 1's turn:\n"," O  X  O  O  X\n"," .  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  X  O  O  X\n"," .  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 2\n","player 1's turn:\n"," O  X  O  O  X\n"," .  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," .  O  .  .  .\n","player -1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," .  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player 1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," .  O  O  .  .\n","player -1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," .  O  O  .  X\n","Введите ваш ход (Строка, столбец)\n","5 1\n","player 1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," O  O  O  .  X\n","player -1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  .\n"," O  O  O  X  X\n","Введите ваш ход (Строка, столбец)\n","4 5\n","player 1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," .  X  X  O  O\n"," X  X  O  X  O\n"," O  O  O  X  X\n","player -1's turn:\n"," O  X  O  O  X\n"," X  O  X  O  X\n"," X  X  X  O  O\n"," X  X  O  X  O\n"," O  O  O  X  X\n","Ничья!\n","\n","player -1's turn:\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n","Введите ваш ход (Строка, столбец)\n","3 3\n","player -1's turn:\n"," .  .  .  .  .\n"," .  .  .  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .\n"," .  .  .  O  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 2\n","player -1's turn:\n"," .  .  .  .  .\n"," .  .  .  O  .\n"," .  .  X  .  .\n"," .  X  .  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  .  O  .\n"," .  .  X  .  .\n"," .  X  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 3\n","player -1's turn:\n"," .  .  .  .  .\n"," .  O  X  O  .\n"," .  .  X  .  .\n"," .  X  .  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  X  O  .\n"," .  .  X  .  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 4\n","player -1's turn:\n"," .  .  .  .  .\n"," .  O  X  O  .\n"," .  .  X  X  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  .  .  .  .\n"," .  O  X  O  .\n"," .  O  X  X  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 3\n","player -1's turn:\n"," .  .  X  .  .\n"," .  O  X  O  .\n"," .  O  X  X  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  O  X  .  .\n"," .  O  X  O  .\n"," .  O  X  X  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 1\n","player -1's turn:\n"," .  O  X  .  .\n"," X  O  X  O  .\n"," .  O  X  X  .\n"," .  X  O  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," .  O  X  .  .\n"," X  O  X  O  .\n"," .  O  X  X  .\n"," .  X  O  .  O\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 1\n","player -1's turn:\n"," .  O  X  .  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," .  X  O  .  O\n"," .  .  .  .  .\n","player 1's turn:\n"," .  O  X  .  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  .  O\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 2\n","player -1's turn:\n"," .  O  X  .  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  .  O\n"," .  X  .  .  .\n","player 1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  .  O\n"," .  X  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player -1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  .  O\n"," .  X  X  .  .\n","player 1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  .  O\n"," .  X  X  O  .\n","Введите ваш ход (Строка, столбец)\n","4 4\n","player -1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  X  O\n"," .  X  X  O  .\n","player 1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  .\n"," O  X  O  X  O\n"," .  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","3 5\n","player -1's turn:\n"," .  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  X\n"," O  X  O  X  O\n"," .  X  X  O  O\n","player 1's turn:\n"," O  O  X  O  .\n"," X  O  X  O  .\n"," X  O  X  X  X\n"," O  X  O  X  O\n"," .  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","2 5\n","player -1's turn:\n"," O  O  X  O  .\n"," X  O  X  O  X\n"," X  O  X  X  X\n"," O  X  O  X  O\n"," .  X  X  O  O\n","player 1's turn:\n"," O  O  X  O  O\n"," X  O  X  O  X\n"," X  O  X  X  X\n"," O  X  O  X  O\n"," .  X  X  O  O\n","Введите ваш ход (Строка, столбец)\n","5 1\n","player -1's turn:\n"," O  O  X  O  O\n"," X  O  X  O  X\n"," X  O  X  X  X\n"," O  X  O  X  O\n"," X  X  X  O  O\n","Ничья!\n","\n","player -1's turn:\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n","player -1's turn:\n"," .  .  .  .  .\n"," .  .  .  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 1\n","player 1's turn:\n"," O  .  .  .  .\n"," .  .  .  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 2\n","player 1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," .  .  X  .  .\n"," .  O  .  .  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," .  .  X  X  .\n"," .  O  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 4\n","player 1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," .  .  X  X  .\n"," .  O  .  O  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," .  X  X  X  .\n"," .  O  .  O  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 1\n","player 1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," O  X  X  X  .\n"," .  O  .  O  .\n"," .  .  .  .  .\n","player -1's turn:\n"," O  .  .  .  .\n"," .  .  .  X  .\n"," O  X  X  X  X\n"," .  O  .  O  .\n"," .  .  .  .  .\n","Победа (DQNAgent)!\n","\n","player -1's turn:\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n",". . . . .\n","Введите ваш ход (Строка, столбец)\n","1 1\n","player -1's turn:\n"," X  .  .  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  .  .  .  .\n"," .  .  O  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 2\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  .  .  .\n"," .  .  O  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  .  .\n"," .  .  O  .  .\n"," .  .  .  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 3\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  O  .  .\n"," .  .  O  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  .  .\n"," .  O  O  .  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 4\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  O  .  .\n"," .  O  O  X  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  .\n"," .  O  O  X  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n","Введите ваш ход (Строка, столбец)\n","2 4\n","Клетка занята!\n","Введите ваш ход (Строка, столбец)\n","2 5\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," .  .  X  .  .\n"," .  .  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," .  .  X  .  .\n"," .  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 2\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," .  X  X  .  .\n"," .  O  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," .  X  X  .  O\n"," .  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","4 4\n","player -1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," .  X  X  X  O\n"," .  O  .  .  .\n","player 1's turn:\n"," X  .  .  .  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," O  X  X  X  O\n"," .  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 4\n","player -1's turn:\n"," X  .  .  X  .\n"," .  X  O  O  X\n"," .  O  O  X  .\n"," O  X  X  X  O\n"," .  O  .  .  .\n","player 1's turn:\n"," X  .  .  X  .\n"," O  X  O  O  X\n"," .  O  O  X  .\n"," O  X  X  X  O\n"," .  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","5 1\n","player -1's turn:\n"," X  .  .  X  .\n"," O  X  O  O  X\n"," .  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  .\n","player 1's turn:\n"," X  O  .  X  .\n"," O  X  O  O  X\n"," .  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","3 1\n","player -1's turn:\n"," X  O  .  X  .\n"," O  X  O  O  X\n"," X  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  .\n","player 1's turn:\n"," X  O  .  X  O\n"," O  X  O  O  X\n"," X  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  .\n","Введите ваш ход (Строка, столбец)\n","1 3\n","player -1's turn:\n"," X  O  X  X  O\n"," O  X  O  O  X\n"," X  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  .\n","player 1's turn:\n"," X  O  X  X  O\n"," O  X  O  O  X\n"," X  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  .  O\n","Введите ваш ход (Строка, столбец)\n","5 4\n","player -1's turn:\n"," X  O  X  X  O\n"," O  X  O  O  X\n"," X  O  O  X  .\n"," O  X  X  X  O\n"," X  O  .  X  O\n","player 1's turn:\n"," X  O  X  X  O\n"," O  X  O  O  X\n"," X  O  O  X  O\n"," O  X  X  X  O\n"," X  O  .  X  O\n","Введите ваш ход (Строка, столбец)\n","5 3\n","player -1's turn:\n"," X  O  X  X  O\n"," O  X  O  O  X\n"," X  O  O  X  O\n"," O  X  X  X  O\n"," X  O  X  X  O\n","Ничья!\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'DQNAgent': 1, 'Human': 0}"]},"metadata":{},"execution_count":23}],"source":["agent.epsilon = 0\n","test_game = TicTacToe(agent, Human(), board_size=board_size, win_size=win_size)\n","test_game.play(4, True)\n","test_game.wins"]},{"cell_type":"markdown","metadata":{"id":"TAq9ckumpm01"},"source":["# Первый ход за крестики и значения $Q$-фунцкии в начальном состоянии"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518,"status":"ok","timestamp":1718476086297,"user":{"displayName":"Ольга Тимошкина","userId":"04482327087685269416"},"user_tz":-180},"id":"aKjltLQC1-vk","outputId":"e74e8cba-1793-4124-a439-ac7afef42e3c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 2)"]},"metadata":{},"execution_count":28}],"source":["state2d = torch.tensor(np.array(\n","    [[[0, 0, 0, 0, 0],\n","      [0, 0, 0, 0, 0],\n","      [0, 0, 0, 0, 0],\n","      [0, 0, 0, 0, 0],\n","      [0, 0, 0, 0, 0]]]\n",")).to(device)\n","\n","q_values = agent(state2d).squeeze(0).detach().cpu().numpy()\n","np.unravel_index(q_values.argmax(), q_values.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1718476110416,"user":{"displayName":"Ольга Тимошкина","userId":"04482327087685269416"},"user_tz":-180},"id":"dTKnN9UG4TJN","outputId":"c3ce001e-e7b8-4aaf-d16c-41bce4833259"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.0404,  0.0055, -0.0263,  0.0159, -0.0434],\n","       [ 0.0161,  0.    ,  0.0052,  0.0096,  0.0094],\n","       [-0.0336,  0.0246,  0.0311,  0.0127, -0.0406],\n","       [ 0.0197,  0.0064,  0.0235,  0.0066,  0.0127],\n","       [-0.0295, -0.0043, -0.0313,  0.0035, -0.0543]], dtype=float32)"]},"metadata":{},"execution_count":32}],"source":["q_values.round(4)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1wqCozfdeRJnqyq9lgTKHqqbIOJ70UoZc","timestamp":1718788514225},{"file_id":"17AdIcgMxS_7_mOiy7FUK1C5VUgC8F-8_","timestamp":1718460691857},{"file_id":"1Gr04QBn85xAghWhQrafFAC3IVYCCcrdF","timestamp":1718270221903},{"file_id":"1tYpwZfpcc8mwjf9xBvf2Qh4nBVyZDdDi","timestamp":1718209975048},{"file_id":"1srwb210ZiHsQBrRBDRQ5YvK6o5ZuV2x9","timestamp":1718193488488},{"file_id":"17BHq081ewJDS6eZRZvxiWWTUVu9adCx1","timestamp":1718173770359}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
